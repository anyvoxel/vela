{"domain":"jackvanlightly","path":"https://jack-vanlightly.com/blog/2025/11/19/have-your-iceberg-cubed-not-sorted-meet-qbeast-the-otree-spatial-index","title":"Have your Iceberg Cubed, Not Sorted: Meet Qbeast, the OTree Spatial Index","summary":"**摘要：**\n\n本文介紹了 Qbeast 提出的 **OTree 多維索引技術**，對開放式數據湖表格式（如 Apache Iceberg 與 Delta Lake）的資料佈局進行革新。傳統索引以讀取優化為主，且多採用分區與排序來實現資料局部性，但存在分區過細、資料傾斜、分布漂移等問題。\n\nOTree 將索引角色轉變為**動態空間結構**，透過將資料映射至多維空間（如價格與評分），並以自適應超立方體（hypercube）方式劃分空間：  \n- 每個立方體代表一個資料區域，根據資料密度自動分裂（如 2×2×2 分割），密集區生成更細粒度的子立方體。  \n- 立方體編號（cube ID）隱含其空間位置與範圍，形成輕量級樹狀結構（OTree），僅需數百 KB 至數 MB 元數據。  \n\n關鍵創新在於：\n1. **索引決定寫入布局**：寫入時根據 OTree 布局存放資料，確保資料始終接近最佳聚集狀態，避免「漂移」問題。\n2. **與現有格式無縫整合**：不修改 Iceberg/Delta 的核心元數據，僅通過專用文件（如 Puffin、Delta Log 標籤）儲存 OTree，查詢引擎完全無感。\n3. **提升讀寫效率**：保持原有列統計與 Bloom filter 優化，同時因資料空間局部性增強，大幅改善多維範圍查詢效能。\n\n總結：OTree 是介於傳統 B-tree 與純粹分區排序之間的進階方案——兼具全局視角與輕量高效，實現「自我修正」的動態資料佈局，是數據湖倉未來的重要演進方向。","published_at":"2025-11-19T00:00:00Z"}
{"domain":"brendangregg","path":"https://www.brendangregg.com//blog/2025-11-22/intel-is-listening.html","title":"Intel is listening, don't waste your shot","summary":"**摘要：**\n\n英特尔新CEO黎巴·谭（Lip-Bu Tan）强调，客户应“直言不讳”地提供严苛反馈，认为这才是最有价值的。作者曾作为外部顾问长期向英特尔提供建议，虽未正式入职，却因贡献被视作“准院士”候选人，深感客户在技术合作中可发挥巨大影响力。\n\n文中总结了在与硬件厂商（尤其是英特尔）会议中有效传递关键反馈的10条实战建议：\n- 会前充分准备，研究议程与参会人背景；\n- 警惕知识产权风险，避免无保护性反馈；\n- 确保反馈被完整记录于会议纪要，拒绝模糊化；\n- 聚焦技术性、建设性批评，避免情绪化语言；\n- 明确记录参会人员与时间；\n- 质疑资源分配合理性，用行业标准对比；\n- 拒绝为新员工免费授课；\n- 多问“你有查过Google吗？”以识别低效提问；\n- 对持续浪费时间的人员或项目要求“禁入”会议；\n- 定期审视参会者是否真正具备决策或技术能力；\n- 抵制群体压力，敢于说出真实评价；\n- 主动要求后续进展更新，确保反馈落地；\n- 每年争取与高管层（如ELT或CEO）直接对话，并邮件留存记录。\n\n作者坦言，从“客户”转为“内部人”后更理解：真正有效的反馈需要极大勇气与坚持。而对客户而言，敢于说真话不仅是责任，更是推动技术进步的关键力量。","published_at":"2025-11-22T00:00:00Z"}
{"domain":"brendangregg","path":"https://www.brendangregg.com//blog/2025-11-17/third-stage-engineering.html","title":"Third Stage Engineering","summary":"该博客提出一个“三阶段火箭”模型，用以解释计算机硬件在实际生产环境中性能的真正来源：**硬件（HW）、软件（SW）和调优（Tuning）**。三者缺一不可，只有协同作用才能实现最优性能。\n\n- **第一阶段（硬件）**：基础性能，但仅靠硬件无法体现真实应用表现。\n- **第二阶段（软件）**：如使用英特尔优化的TensorFlow扩展等专用软件，可显著提升性能。\n- **第三阶段（调优，即“第三阶段工程”）**：包括人员、培训、工具与调优能力，是实现极致性能的关键，需深入理解软硬件原理并进行系统性优化。\n\n作者指出，当前大量性能对比仅关注硬件，忽略了软件与调优的巨大影响，导致结果失真。真正的性能评估应先选最佳软件，再进行系统调优，并对所有硬件方案同样对待。\n\n**核心观点**：高性能不是硬件单方面的功劳，而是软硬协同+深度调优的结果。企业应重视“第三阶段工程”，避免只看硬件的片面评价。  \n**推荐读者**：技术决策者、系统架构师、性能优化工程师。","published_at":"2025-11-17T00:00:00Z"}
{"domain":"brendangregg","path":"https://www.brendangregg.com//blog/2025-08-04/when-to-hire-a-computer-performance-engineering-team-2025-part1.html","title":"When to Hire a Computer Performance Engineering Team (2025) part 1 of 2","summary":"**性能工程团队的价值与建设指南（摘要）**\n\n本文由资深性能工程专家撰写，系统阐述了非硬件厂商型科技企业为何应组建性能工程团队，以及如何评估其投资回报（ROI）、职能定位和招聘策略。\n\n---\n\n### **核心论点**\n组建性能工程团队可带来显著的**基础设施成本节约**（年均5–10%）、**延迟降低**、**系统可扩展性与可靠性提升**及**开发效率加速**。对于年后台端计算支出超100万美元的企业，该团队能通过深度优化实现“**成本减半**”的早期成果，长期来看具有极高的复合价值。\n\n---\n\n### **关键收益**\n1. **成本节约**  \n   - 年均目标：5–10% 成本下降，5年后累计可达28%以上（复利效应）。  \n   - 实现路径：  \n     - 2% 来自直接调优；  \n     - 3% 源于赋能开发者/运维团队使用自研可观测工具；  \n     - 3% 源于推动供应商产品替代（如新云实例、运行时、编译器等）。  \n   - 举例：某公司通过性能团队将每用户成本降低8%，节省500万美元/年。\n\n2. **延迟优化**  \n   - 不仅关注平均延迟，更聚焦99百分位及异常延迟（如每5分钟一次的后台任务引发抖动）。  \n   - 工具组合：eBPF、分布式追踪、内核级分析、自定义诊断工具。\n\n3. **可扩展性与可靠性**  \n   - 识别并解决瓶颈（如曾发现存储系统实际瓶颈是CPU互连而非磁盘）。  \n   - 避免雪崩式故障，保障服务在峰值负载下稳定运行。\n\n4. **加速工程进程**  \n   - 外部性能问题（如库、内核、硬件）由性能团队兜底，让开发专注核心代码。  \n   - 通过一小时会议避免数月错误方向投入（如曾阻止一个“十倍性能提升”的无效框架迁移项目）。  \n   - 提供加速工具（如火焰图、AI辅助分析），缩短问题发现周期。\n\n---\n\n### **性能工程师的核心职责**\n- 测试/调试/调优软硬件新产品（云实例、JVM、GC算法、硬件加速器等）。\n- 开发内部可观测性工具（如基于eBPF的自研监控平台）。\n- 深度分析性能瓶颈与延迟异常。\n- 优化系统参数（sysctl、网络队列、JVM选项等）。\n- 与开发团队协作，在早期阶段识别不可扩展设计。\n- 构建新技术原型（如io_uring、eBPF加速器）。\n- 直接修复关键代码缺陷（如内核或数据库性能补丁）。\n- 参与容量规划与采购决策，防止被商业工具“割韭菜”。\n- 推动知识共享，打破团队间性能认知壁垒。\n\n\u003e ✅ 关键区别：**性能测试 ≠ 性能工程** —— 后者需深入分析“为何未达预期”，而不仅是跑个基准。\n\n---\n\n### **何时组建 \u0026 如何定编？**\n- **启动门槛**：年基础设施支出 \u003e $1M，即应考虑设立首位专职人员。\n- **扩编建议**：\n  - 每新增 $10M–$20M 支出，增配1名性能工程师；\n  - 建议保持 3:1 初级/高级比例；\n  - 若已存在专注性能的高级开发或SRE，应计入现有资源。\n- **预算参考**：性能团队薪资支出应等于或超过可观测性工具采购费用（如每年100万美金监控费，可匹配100万美金团队预算）。\n- **特殊时机**：当增长导致延迟飙升或系统不可靠时，正是投资性能团队的最佳窗口。\n\n\u003e ⚠️ 注意：团队规模会随复杂度上升而递减边际效益，但整体仍具成本效益，通常不超过150人。\n\n---\n\n### **全球现状与趋势**\n- 全球范围内，明确称“性能工程师”的非厂商从业者不足1,000人；\n- 硬件/软件/云厂商中相关岗位超1万人；\n- 实际从事性能工作的技术人员超过10万（含开发者、SRE等角色）；\n- 多家头部企业（如Netflix、Meta、Pinterest、Uber、Stripe）已有公开案例。\n\n---\n\n### **总结**\n性能工程不是锦上添花，而是**支撑规模化增长的关键能力**。它以小博大，持续创造复合价值。  \n建议企业根据支出规模、技术复杂度和增长压力，尽早建立中心化性能团队，或通过培训/顾问方式逐步构建能力。\n\n\u003e 下期预告：职位描述模板、招聘技巧、无团队情况下的替代方案。\n\n---  \n**适合人群**：年均后端支出超百万美元的科技公司、金融、电信、AI等领域企业决策者与架构师。","published_at":"2025-08-04T00:00:00Z"}
{"domain":"brendangregg","path":"https://www.brendangregg.com//blog/2025-05-22/3-years-of-extremely-remote-work.html","title":"3 Years of Extremely Remote Work","summary":"**摘要：**\n\n作者在過去三年中，因遠端工作於美國公司（Intel），每兩週參加一次凌晨1至6點的會議，並配合7點上班，生活節奏極為特殊。總計參與77場深夜會議（共102小時），常需在凌晨2-3點開會後，清晨6:30起床，睡眠嚴重受限。儘管如此，作者仍保持高效，並分享多項實用經驗：\n\n- **量化與透明化**：主動記錄深夜會議次數，用數據說明負擔，減少他人誤解。\n- **避免抱怨**：不提及疲勞，防止被用來反對遠端工作政策。\n- **自我激勵**：每日記錄成果，週度總結，維持動力。\n- **溝通誤解**：遠端工作者常被誤認為「睡著」而非「時間衝突」，需明確說明。\n- **會議管理**：提醒取消臨時會議、釐清錄影規則，避免無謂驚醒。\n- **健康代價**：長期熬夜導致胃部不適，可能與咖啡攝取有關。\n- **優勢與挑戰**：遠端工作雖有「眼不見心不念」的職涯發展風險，但實際效率高（如僅1天病假/年），且成功案例眾多（如Linux開發、AI火焰圖等）。\n\n作者強調，遠端工作者往往比外界想像更願意配合時差，但其付出常被忽視。他呼籲企業重新評估遠端政策，避免基於偏見做出決策，並希望更多人理解遠端工作的真實面貌——不是度假，而是嚴謹、犧牲與責任的結合。","published_at":"2025-05-22T00:00:00Z"}
{"domain":"davidxiang","path":"https://davidxiang.com/2024/02/04/s3-express-one/","title":"S3 Express One, Value-Less LSM Trees, ShardStore","summary":"**S3 Express One Zone 2024 深度解析：性能与架构的革命**\n\n**核心观点**  \n亚马逊推出 **S3 Express One Zone**，标志着 S3 从“高耐用性存储”向“极致低延迟高性能存储”的演进，是云原生应用（尤其是 AI/ML、实时数据处理）的关键基础设施突破。\n\n---\n\n### 🔑 关键亮点\n\n1. **单可用区（AZ）部署**  \n   - 数据不再跨区域冗余，仅存于单个可用区，牺牲部分容灾能力换取更低延迟。\n   - 写入与读取可实现 **跨 AZ 的物理距离优化**（如60英里内），显著降低网络延迟。\n\n2. **超大规模吞吐量（百万级 RPS）**  \n   - 无需手动分片或调整前缀，即可获得 **数十万次/秒** 的请求处理能力。\n   - 原因在于亚马逊全球万亿级负载已实现“平滑分布”，消除了传统热点问题，可采用更简单的统一分区策略。\n\n3. **基于 SSD 与新型存储架构（ShardStore）**  \n   - 首次实现 **单毫秒级访问延迟**，依赖新型硬件（SSD）和软件架构革新。\n   - 核心技术为 **“无值 LSM 树”（Value-Less LSM Tree）**：\n     - 将键值对分离：树中仅存储指向数据块的指针，而非实际数据。\n     - 显著降低写放大，提升随机读性能。\n     - 适配 SSD 高并发随机读特性，支持多线程并行访问。\n\n4. **全新存储管理机制（ShardStore）**  \n   - 使用 Rust 编写，专为高性能设计。\n   - 数据被拆分为“**碎片（shards）→ 块（chunks）→ 扩展（extents）**”三级结构。\n   - 空间回收通过“轻量级垃圾回收”完成，非传统合并压缩，避免写放大。\n   - 无需 WAL 日志仍保证崩溃一致性，依赖高效元数据管理。\n\n---\n\n### 🚀 实际影响与启示\n\n- **对开发者**：可直接使用高性能存储，无需复杂分片设计；适合实时分析、高频交易、AI 推理等场景。\n- **对架构师**：需重新思考计算资源部署策略——必须显式绑定至目标可用区，同时自研容灾方案。\n- **对云厂商**：展示“超大规模 → 架构简化”的正向循环：规模越大，越能支撑简单高效的系统设计。\n\n---\n\n### 📌 总结\n\n\u003e **S3 正从“云上硬盘”进化为“互联网级高性能持久化引擎”**。  \n\u003e 通过 **单可用区、百万级吞吐、SSD+ShardStore 架构**，S3 Express One Zone 将成为未来低延迟应用的核心基石。  \n\u003e 这不仅是存储服务的升级，更是底层软硬件协同创新的典范。\n\n✅ **推荐人群**：云原生架构师、高并发系统开发者、AI 平台工程师、关注基础设施演进的技术决策者。","published_at":"2024-02-04T00:00:00Z"}
{"domain":"brendangregg","path":"https://www.brendangregg.com//blog/2025-05-01/doom-gpu-flame-graphs.html","title":"Doom GPU Flame Graphs","summary":"**AI火焰图开源并支持Intel Battlemage GPU，实现全栈性能分析**\n\n- **核心亮点**：英特尔开源了基于eBPF和eustalls的**AI火焰图工具链（iaprof）**，首次实现**跨CPU/GPU的毫秒级全栈性能剖析**，支持实时生成**GPU火焰图与火焰范围图（FlameScope）**，显著提升游戏性能调优效率。\n  \n- **关键技术**：\n  - 通过**火焰范围图**可视化1秒内采样密度，颜色深浅反映负载波动，支持按时间区间筛选生成精准火焰图。\n  - 新增**GPU火焰图**，可区分渲染瓶颈（如墙体41.4%、后处理35.7%）、着色器编译、帧调度等，结合CPU调用栈定位性能瓶颈。\n  - 支持**Intel Battlemage GPU**，适用于非AI场景（如GZDoom游戏），并可通过自定义地图和资源限制放大性能问题。\n\n- **使用门槛高但前景广阔**：\n  - 需要Linux系统+根权限，内核≥6.15（Battlemage）或5.15（Max系列），且需启用特定eustall/eudebug接口。\n  - 所有被分析程序及库必须启用**帧指针**（frame pointers），部分发行版（如Ubuntu 24.04）已默认支持。\n  - 安装复杂，类似“玩《毁灭战士》噩梦难度”，但未来将逐步简化。\n\n- **实践案例**：以GZDoom为例，通过对比CPU与GPU火焰范围图，发现GPU空闲期对应CPU密集型着色器编译，进而定位到关键性能瓶颈。\n\n- **工具使用**：\n  ```bash\n  git clone --recursive https://github.com/intel/iaprof\n  make deps \u0026\u0026 make\n  sudo iaprof record \u003e profile.txt\n  cat profile.txt | iaprof flame \u003e flame.svg\n  ```\n\n- **未来方向**：扩展硬件支持、降低5%以下性能开销、推动集成至`perf`工具链。目前仅限Intel平台，但已为生态铺路。\n\n- **适用人群**：游戏开发者、图形驱动工程师、性能优化专家。对性能调优有深度需求者值得尝试。\n\n\u003e ✅ **总结**：AI火焰图现已成为跨栈、高精度、交互式性能分析利器，虽部署复杂，但为解决真实世界性能问题提供了前所未有的可视化洞察力。","published_at":"2025-05-01T00:00:00Z"}
{"domain":"brendangregg","path":"https://www.brendangregg.com//blog/2024-10-29/ai-flame-graphs.html","title":"AI Flame Graphs","summary":"**AI火焰图：降低AI算力成本的可视化利器**\n\n英特尔推出**AI火焰图**（AI Flame Graphs），一种全新性能分析工具，旨在帮助开发者直观识别和优化AI工作负载中的资源瓶颈。该工具基于作者此前发明的CPU火焰图理念，将硬件（如GPU/AI加速器）与软件栈融合可视化，通过颜色区分代码层级：绿色为加速器指令，青色为源码，红色/黄色/橙色为触发执行的CPU路径。\n\n- **核心价值**：通过识别高耗时、高停顿（stall）的代码路径（如矩阵乘法未优化版本占72%停顿），可显著降低算力消耗。若全行业实现类似优化，预计到2030年可使美国电力消耗减少超10%。\n- **技术亮点**：采用低开销的eBPF软件探针 + 英特尔EU停顿采样硬件机制，无需重启或注入额外代码，支持“即插即用”式生产环境分析。\n- **适用场景**：已在英特尔Tiber AI云平台预览发布，支持Intel数据中心GPU Max系列，已成功应用于PyTorch等主流框架（如Llama 2模型推理），并具备搜索功能（如查找`sbid`依赖瓶颈）。\n- **挑战与前景**：当前仍面临堆栈解析、符号化、跨框架兼容性等问题，部分环境需重新编译或启用帧指针；但目标是像CPU火焰图一样成为日常开发工具——易用、无感、全面。\n- **未来展望**：作者坚信，若能推广至全行业，有望实现10%以上性能提升，甚至更高。类似技术可能催生新创业公司，但必须坚持“低开销、易用、生产安全”的原则，否则可能阻碍采纳。\n\n\u003e ✅ **推荐人群**：AI工程师、系统架构师、高性能计算开发者、关注可持续计算的团队  \n\u003e 🔗 **获取方式**：通过英特尔服务渠道申请访问[Tiber AI云](https://www.intel.com/content/www/us/en/developer/tools/devcloud/services.html)中的预览版\n\n**结语**：这不仅是一次性能工具革新，更是推动绿色AI的关键一步。正如作者所言：“你们正在拯救地球。”","published_at":"2024-10-29T00:00:00Z"}
{"domain":"emptysqua","path":"https://emptysqua.re/blog/first-time-vibecoding/","title":"This Senior Staff Engineer Vibe-Coded for the First Time, What Happened Next Will Shock You","summary":"**总结：**\n\n作者分享了两次使用AI辅助编程的经历，揭示了“振动式编程”（vibecoding）——即信任AI自主完成任务，而非手动干预——的核心技巧。  \n\n**核心观点**：  \n- **AI编程是一种新技能**，关键不在于写代码，而在于如何与AI协作。  \n- 初次尝试时，作者试图控制每一行代码，结果陷入反复修改、调试和错误循环，效率反而更低。  \n- 第二次改用更强大的模型（Claude Sonnet 4.5）并赋予其自主权，仅提供高层次目标，让AI自行规划、编码、测试、修复，最终成功构建出一个能分析目标、任务和时间数据的“AI教练”应用。  \n\n**关键洞察**：  \n- 避免过度审查代码风格或强制添加注释，这会干扰AI发挥；  \n- 允许AI自主运行命令、查阅文档、诊断错误，可大幅提升效率；  \n- 模型选择至关重要（如Claude优于GPT-5 mini）；  \n- 仍需介入处理特定API问题，但可通过自然交互引导AI解决；  \n- 硬件支持（如超宽屏显示器）也影响体验。  \n\n**启示**：  \n技术革命并非立刻见效，需要适应与练习。正如当年Rails和TextMate颠覆开发方式一样，如今的AI编程潜力巨大，但只有放下控制欲、学会“放飞”，才能真正释放效率红利。  \n\n**适合人群**：开发者、技术研究者、对高效工作流感兴趣的实践者。","published_at":"2025-11-19T00:00:00Z"}
{"domain":"davidxiang","path":"https://davidxiang.com/2022/12/22/raising-the-alarm/","title":"Raising The Alarm","summary":"当一个项目明显走向失败时，你是否曾默默担忧却选择沉默？这篇文章探讨了工程师在发现项目失控时如何负责任地发声。\n\n**核心观点**：即使无法改变结果，主动提出质疑本身就是一种成熟与担当。真正的价值不在于项目是否被叫停，而在于你是否敢于以专业态度表达担忧。\n\n**关键要点**：\n- **何时发声**：当项目涉及重大架构、部署或开发变革，且存在目标不切实际、进度停滞、负责人防御性强、与公司战略脱节等情况时。\n- **为何发声**：不仅是为组织止损，更是锻炼自身领导力与职业责任感。哪怕未被采纳，行动本身已具意义。\n- **如何发声**（关键）：避免直接对抗，采用间接策略——先与直属经理沟通，清晰说明风险与影响；若无回应，联合其他有相同疑虑的同事形成共识；再寻求中立高阶人士（如无关项目的资深工程师）背书，扩大影响力。\n- **预期结果**：理想情况是项目被叫停，但更常见的是项目失败后才被终止。无论结果如何，**勇于发声的行为本身就是成功**。\n\n**总结**：  \n技术决策不应只由权威主导。当你觉察到潜在危机，别因畏惧而沉默。通过理性沟通、团结共识、借力高层，你不仅能推动改进，更是在践行高级工程师应有的责任与勇气。最终，重要的是你“做了什么”，而非“是否成功”。","published_at":"2022-12-22T00:00:00Z"}
{"domain":"brendangregg","path":"https://www.brendangregg.com//blog/2024-07-22/no-more-blue-fridays.html","title":"No More Blue Fridays","summary":"**摘要：**\n\n2024年7月19日，全球大规模蓝屏故障由CrowdStrike的Windows安全更新引发，暴露了内核级驱动程序更新的高风险。该事件凸显了传统内核编程的脆弱性——错误代码可直接导致系统崩溃。\n\n未来，**eBPF**（扩展伯克利数据包过滤器）将成为解决此问题的关键技术。eBPF是一种安全的内核执行环境，通过软件验证器确保代码安全性，防止系统崩溃。其原理类似浏览器中的沙箱运行JavaScript，即使程序有缺陷，也仅限于资源消耗，不会引发系统宕机。\n\n目前Linux已广泛使用eBPF，且被谷歌、Meta、Cisco等公司用于安全监控与网络优化。微软也已推出Windows版eBPF支持，未来将使Windows安全软件也能获得相同的安全保障。\n\n尽管eBPF本身仍有管理代码漏洞（如曾引发内核恐慌），但其统一修复机制可惠及所有用户，提升整体系统稳定性。\n\n建议企业要求供应商采用eBPF作为安全软件部署标准，推动从“高危内核驱动”向“安全沙箱化”演进。结合灰度发布、韧性工程等实践，可从根本上避免类似全球性中断。\n\n\u003e **核心观点**：未来系统不再因软件更新崩溃，关键在于用eBPF替代危险的内核模块。  \n\u003e **适用人群**：企业IT决策者、安全工程师、系统架构师。","published_at":"2024-07-22T00:00:00Z"}
{"domain":"brendangregg","path":"https://www.brendangregg.com//blog/2024-03-24/linux-crisis-tools.html","title":"Linux Crisis Tools","summary":"**摘要：**\n\n本文推荐在生产环境的Linux服务器上预先安装一套“危机诊断工具”，以应对性能故障导致的宕机或严重延迟。这些工具可快速获取系统状态、资源使用、网络与磁盘I/O、CPU性能等关键指标，避免在紧急情况下因无法安装工具而延误排查。\n\n**核心工具清单（基于Ubuntu）：**\n- `procps`：`top`, `uptime`, `vmstat` 等基础监控\n- `sysstat`：`iostat`, `sar`, `mpstat` 等性能统计\n- `iproute2`：`ip`, `ss`, `nstat` 网络诊断\n- `numactl`：NUMA架构分析\n- `tcpdump`：网络抓包\n- `linux-tools-*`：`perf`, `turbostat` 性能剖析\n- `bcc` / `bpfcc-tools`：eBPF高级追踪工具（如 `biosnoop`, `tcptop`, `ext4slower`）\n- `bpftrace`：轻量级eBPF脚本执行\n- `trace-cmd`：Ftrace命令行接口\n- `nicstat`, `ethtool`, `iptables`, `cpuid`, `msr-tools` 等硬件与网络细节工具\n\n**关键洞察：**\n- 事前预装工具是高效应急的关键。实际案例显示，在故障期间安装软件可能因网络、权限、防火墙、文件系统只读等问题失败，耗时数分钟甚至数十分钟。\n- eBPF工具（bcc/bpftrace）功能强大且运行高效，虽有重叠但互补；未来将向更轻量的 `libbpf-tools` 迁移。\n- 工具包总体体积小，对云实例启动时间影响微乎其微，远低于调试信息包（如1GB debuginfo）带来的问题。\n\n**建议：**\n- 所有生产服务器应默认包含此工具集，尤其在高可用/金融/电商等场景。\n- 推动发行版厂商将这些工具纳入企业版Linux镜像，让所有团队“开箱即用”。\n- 可搭配 `gdb` 等调试工具一并预装。\n\n**总结：**  \n提前部署“危机工具链”是保障系统可观测性与恢复效率的核心实践。越早准备，越能在故障发生时快速定位问题，减少业务损失。","published_at":"2024-03-24T00:00:00Z"}
{"domain":"brooker","path":"https://brooker.co.za/blog/2025/11/20/what-now.html","title":"What Now? Handling Errors in Large Systems","summary":"**总结：**\n\n本文探讨大型系统中错误处理的核心原则，以 Cloudflare 2025 年 11 月故障的 postmortem 为引子，聚焦于 Rust 中 `unwrap()` 的使用争议。作者指出，错误处理不是局部决策，而是系统的全局属性，需结合系统架构、故障相关性与可恢复性综合判断。\n\n**核心观点：**\n1. **失败是否相关？**  \n   独立故障（如内存损坏）可安全崩溃；若故障可能共现（如用户恶意输入），应避免崩溃，改用降级或拒绝服务。\n   \n2. **能否在更高层处理？**  \n   传统架构依赖自动重启（如 AWS Auto Scaling）；细粒度架构（如 Lambda、Erlang）允许高频崩溃，因上层能接管。\n\n3. **能否有意义地继续运行？**  \n   配置可回退至旧版本并告警；但数据库复制记录若无法解析，则必须停止，否则将导致状态不一致和数据污染。\n\n**关键结论：**\n- 错误处理必须从系统设计之初就考虑，而非事后补救。\n- 采用“爆炸半径缩减”策略（如分片、区域隔离、shuffle sharding）可限制故障影响范围，提升整体韧性。\n- 语言选择（如 Rust vs C）影响错误可见性与安全性：Rust 显式暴露错误路径，减少隐性错误传播。\n\n**适用人群：** 系统架构师、后端工程师、运维与 DevOps 团队。","published_at":"0001-01-01T00:00:00Z"}
{"domain":"brendangregg","path":"https://www.brendangregg.com//blog/2024-03-17/the-return-of-the-frame-pointers.html","title":"The Return of the Frame Pointers","summary":"**摘要：**\n\n本文由 Brendan Gregg 深入探讨了现代系统中因缺失**帧指针（frame pointers）**导致的性能分析工具（如火焰图、perf）失效问题。尽管编译器自2004年起默认移除帧指针以提升性能，但此举严重破坏了调试与剖析能力，尤其在系统级工具（如 eBPF、off-CPU 火焰图）中表现明显。\n\n关键问题在于：  \n- 无帧指针时，堆栈回溯在 libc 层中断，导致大量调用栈丢失（如示例中左侧“[unknown]”区域），造成火焰图不完整。  \n- 偶尔随机数据可能指向有效地址，引发虚假堆栈或无限循环，进一步误导分析。\n\n作者指出，虽然帧指针带来约1%~10%的性能开销（极端情况为微基准测试），但其带来的可观测性收益远超成本——曾帮助发现5%至500%的性能瓶颈。因此，**开启帧指针是企业级系统优化的必要前提**。\n\n值得庆幸的是，**Fedora 和 Ubuntu 已宣布在新版本中默认启用帧指针**，标志着这一长期存在的技术债终于被修复。此外，Arch Linux 也正在推进此变更。\n\n未来方向包括更先进的堆栈回溯技术：  \n- **ORC**（内核轻量级回溯）已用于替代帧指针；  \n- **SFrames** 正在推动用户空间堆栈追踪；  \n- **影子栈（Shadow Stack）** 可能结合安全与调试功能。\n\n结论：  \n\u003e **帧指针不应再被默认禁用。**  \n\u003e 今天，性能收益和可观测性的需求已远超当年的优化动机。  \n\u003e 开启帧指针是迈向更好性能工程的一步，也为下一代剖析技术铺路。\n\n**推荐人群**：系统工程师、性能调优专家、DevOps、Linux 发行版开发者。","published_at":"2024-03-17T00:00:00Z"}
{"domain":"cloudflareblog","path":"https://blog.cloudflare.com/18-november-2025-outage/","title":"Cloudflare outage on November 18, 2025","summary":"**事件概要：2025年11月18日Cloudflare大规模服务中断**\n\n**核心问题**：  \n2025年11月18日11:20 UTC，Cloudflare因一次数据库权限变更引发的配置文件异常，导致全球核心网络服务中断。该故障并非由攻击引起，而是由于一个用于生成“机器人管理”特征文件的ClickHouse查询在权限更新后返回了重复列数据，使文件大小翻倍。该异常文件被分发至全网节点，触发核心代理系统（FL）内存限制崩溃，引发大量5xx错误。\n\n**关键原因**：\n- **技术根源**：数据库权限升级后，查询`system.columns`不再仅返回`default`库信息，意外包含`r0`库的重复元数据。\n- **设计缺陷**：机器人管理模块预设仅支持200个特征，实际文件超过此阈值，触发未处理的运行时恐慌（panic），导致服务崩溃。\n- **传播机制**：该配置每5分钟自动更新并推送到全网，初期波动性误判为攻击行为。\n\n**影响范围**：\n- 核心CDN与安全服务：用户访问网站出现500错误。\n- Turnstile验证码服务：无法加载，导致登录失败。\n- Workers KV：高延迟和500错误，依赖其服务的系统受影响。\n- Cloudflare Access：认证全面失败，但已有会话不受影响。\n- 控制台仪表盘：因依赖Turnstile和Workers KV，部分时段不可用。\n- 邮件安全：部分反垃圾检测能力下降，但无重大客户影响。\n\n**恢复过程**：\n- 13:05：通过绕过核心代理缓解Workers KV与Access影响。\n- 14:24：停止新配置文件生成。\n- 14:30：部署旧版安全配置文件，主服务恢复。\n- 17:06：所有系统恢复正常。\n\n**后续改进措施**：\n1. 强化对内部配置文件的输入验证，类比用户输入防护。\n2. 增加全局功能开关，快速关闭危险功能。\n3. 防止错误报告（如核心转储）耗尽系统资源。\n4. 全面审查核心代理各模块的异常处理机制。\n\n**总结**：  \n这是自2019年以来最严重的一次中断，暴露了系统在配置自动化、边界检查和容错机制上的不足。Cloudflare团队已公开致歉，并启动全面加固计划，目标是杜绝此类事件再次发生。","published_at":"2025-11-18T00:00:00Z"}
{"domain":"googlepubs","path":"https://research.google/pubs/mmmuse-an-mmwave-based-motion-resilient-universal-speech-enhancement-system/","title":"mmMUSE: An mmWave-based Motion-resilient Universal Speech Enhancement System","summary":"本文提出了一种基于毫米波（mmWave）与音频融合的抗运动干扰通用语音增强系统 mmMUSE，旨在提升语音感知在复杂环境下的性能。传统麦克风在嘈杂环境中表现受限，而毫米波虽能捕捉语音信号，却易受人体运动干扰，导致信号分散和失真。为此，研究团队设计了基于多普勒效应的运动鲁棒性语音提取方法，并引入“语音-噪声比”（Vocal-Noise-Ratio）指标实现实时语音活动检测，显著提升信噪比（SISDR）3.81 dB。系统采用两阶段复数域网络：第一阶段通过注意力机制融合多模态信息，第二阶段利用时频掩码校正语音幅度与相位，有效抑制噪声。在46名参与者的数据集上，mmMUSE相比现有最优模型平均提升SISDR 3.12 dB，尤其在强噪声、剧烈运动、多人说话及遮挡物等极端场景下分别提升16.51–18.95 dB。真实场景测试（如跑步、公共场所、驾驶）中，词错误率（WER）始终低于10%，验证了其卓越的实用性和鲁棒性。该系统为智能语音交互提供了高精度、高适应性的新方案。","published_at":"0001-01-01T00:00:00Z"}
{"domain":"brooker","path":"https://brooker.co.za/blog/2025/11/18/consistency.html","title":"Why Strong Consistency?","summary":"**总结：为什么需要强一致性？**\n\n本文指出，**最终一致性（eventual consistency）虽能提升读扩展能力，但给开发者带来严重困扰**，尤其在数据库读写分离架构中。作者以 AWS 早期使用 MySQL 复制的经验为例，说明操作复杂、逻辑脆弱的问题长期存在。\n\n### 核心论点：\n1. **对应用开发者而言**：  \n   - 读请求可能因路由到未同步的只读副本而“查不到刚创建的数据”，导致代码需轮询重试，增加延迟、复杂性和潜在死循环。\n   - 即使使用“等待资源就绪”逻辑，仍可能因后续读请求被路由至不同副本而失败（缺乏单调读保证）。\n\n2. **对服务构建者而言**：  \n   - 清理类操作（如删除附件）若涉及多个读-改-写步骤，易因数据不一致导致部分失败或遗漏。\n   - 必须强制将关键读请求发往主库，削弱了读副本的可扩展性。\n\n3. **对系统设计而言**：  \n   - 读-修改-写事务在最终一致性下难以安全使用副本，必须依赖主库，限制了横向扩展能力。\n\n### 解决方案：Aurora DSQL 的强一致性读\n- 所有读操作均**强一致**，无论是否参与事务。\n- 通过时间戳机制（`τ_start`）确保读取的是事务开始时刻的一致视图。\n- 查询处理器向副本请求“某个时间点之前的数据”，若副本尚未接收所有更新则阻塞等待，直到数据完整。\n- 支持跨可用区读扩展，同时保持一致性。\n\n### 结论：\n\u003e 强一致性并非“分布式系统专家”的专属需求，而是**中小规模应用也应优先考虑的核心特性**。  \n\u003e Aurora DSQL 的设计目标正是**让开发者无需处理一致性问题**，从而简化开发、提升可靠性与可扩展性。\n\n\u003e ⚠️ 最终一致性仍有适用场景（如容忍延迟的非关键数据），但不应成为默认选择——尤其在高可用、API 服务等场景中。","published_at":"0001-01-01T00:00:00Z"}
{"domain":"emptysqua","path":"https://emptysqua.re/blog/aerial-silks-2/","title":"Aerial Silks in the Gunks, part 2","summary":"2025年10月6日，舞者Kelsey Roman在纽约州“石谷”（Gunks）的西特拉普斯悬崖上，于日落与月升之际表演空中丝巾舞蹈。摄影师在静态绳索上使用闪光灯拍摄，采用大岩壁安全吊带、吊椅提升舒适度，并用已停产的Peak Design配件将相机固定于安全带上。现场由攀岩向导Dustin Portzline负责安全保护并拍摄幕后花絮。整组作品融合了极限运动、艺术表演与自然景观，展现人与岩石之间的动态美学。","published_at":"2025-10-07T00:00:00Z"}
{"domain":"brendangregg","path":"https://www.brendangregg.com//blog/2024-03-10/ebpf-documentary.html","title":"eBPF Documentary","summary":"eBPF 被比作“将 JavaScript 嵌入 Linux 内核”的革命性技术，其发展历程充满策略与创新。这部2023年发布的纪录片通过采访2014年核心开发者（包括作者），还原了 eBPF 从概念到被合并进 Linux 内核的艰辛历程，展现了背后数百人协作的幕后努力。影片记录了早期关键对话，如 Alexei Starovoitov 在 Netflix 的演讲如何激发团队信心，也揭示了“若补丁能合并”这一关键悬念。如今 eBPF 已广泛应用于生产环境，支持可观测性、安全、网络等场景，并在 Windows 上取得进展。尽管已发展十年，仍处于早期阶段，生态工具完善，是深入参与的好时机。片中致敬众多贡献者，并祝贺 eBPF 领先企业 Isovalent 被思科收购。","published_at":"2024-03-10T00:00:00Z"}
{"domain":"brendangregg","path":"https://www.brendangregg.com//blog/2023-04-28/ebpf-security-issues.html","title":"eBPF Observability Tools Are Not Security Tools","summary":"eBPF 观测工具虽强大，但直接用于安全监控如同“把汽车开进海里指望它漂浮”——工具设计目标是低开销以保障生产环境性能，而非安全完整性。这类工具常因系统过载而丢包（如 tcpdump），或被攻击者利用时间竞争漏洞（TOCTOU）、特殊字符等手段绕过检测，导致安全监控出现盲区。尽管这些缺陷早已存在，但因其本质为“汽车”而非“船只”，并非真正“故障”，因此未被修复。\n\n若强行将观测工具改造为安全产品，需增加额外探针、调整事件处理逻辑，反而牺牲了 eBPF 最核心的优势——低开销。更严重的是，这会降低可维护性，且难以满足审计非否认性要求（如事件必须完整记录，不可丢失）。\n\n真正的安全监控工具应从设计之初就考虑安全需求：使用 LSM 钩子、支持可配置的事件丢弃策略、采用插件架构、优化日志性能等。作者强调，仅靠脚本组合现有工具无法构建可靠安全系统，建议开发者聘请具备渗透测试经验的安全工程师参与设计。\n\n尽管 2017 年已有初步探索（与 Netflix 工程师合作），并证明 eBPF 在性能上远优于 auditd，但至今仍缺乏成熟的开源安全工具。当前如 Tetragon 等项目已出现，但作者未作推荐。总之：**不要用观测工具做安全监控，要用安全思维重新设计工具。**","published_at":"2023-04-28T00:00:00Z"}
{"domain":"googleblog","path":"https://developers.googleblog.com/en/build-with-google-antigravity-our-new-agentic-development-platform/","title":"Build with Google Antigravity, our new agentic development platform","summary":"**谷歌推出“反重力”开发平台：迈向智能代理式编程新时代**\n\n谷歌正式发布 **Google Antigravity**——一款面向未来的**代理驱动型开发平台**，旨在帮助开发者从编写代码转向**任务级协作与调度**。它不仅是一个AI增强的代码编辑器，更是一个支持多代理并行工作的智能开发中枢。\n\n### 核心亮点：\n- **双界面设计**：  \n  - **编辑器视图**：保留传统交互体验，支持智能补全与内联命令，适合精细编码。  \n  - **管理器界面（Manager Surface）**：专为代理设计的异步工作空间，可创建、调度和监控多个代理协同完成复杂任务。\n\n- **三大实用场景**：\n  1. **端到端任务自动化**：代理可自主完成“写功能 → 终端运行 → 浏览器测试”的全流程，无需人工干预。\n  2. **可视化UI迭代**：代理自动修改代码并生成截图、操作录屏等**成果物（Artifacts）**，便于快速审查与验证。\n  3. **后台长期任务托管**：如复现问题、生成测试用例、修复漏洞等，可交由代理异步执行，释放开发者注意力。\n\n- **以成果物代替日志**：  \n  代理不输出冗长的操作记录，而是生成**可读性强的成果物**（如计划清单、截图、视频），支持直接评论反馈，实现高效闭环。\n\n- **灵活开放**：  \n  支持 macOS / Windows / Linux，兼容 Gemini 3 Pro、Claude Sonnet 4.5、GPT-OSS 多模型，提供高额度调用限制，个人用户免费使用。\n\n\u003e ✅ **适合人群**：希望提升效率、减少上下文切换的开发者、团队和技术领导者。  \n\u003e 🔗 下载地址：[antigravity.google/download](http://goo.gle/AGY)\n\n**总结**：Antigravity 不只是工具升级，更是开发范式的跃迁——让代理成为你的“数字同事”，让你专注于更高阶的任务设计与决策。","published_at":"2025-11-20T00:00:00Z"}
{"domain":"brendangregg","path":"https://www.brendangregg.com//blog/2023-03-01/computer-performance-future-2022.html","title":"USENIX SREcon APAC 2022: Computing Performance: What's on the Horizon","summary":"**总结：**\n\n在USENIX SREcon22 APAC大会上，作者发表了题为“计算机性能的未来”的主旨演讲，基于其《系统性能（第二版）》的更新内容，回顾了近年关键技术进展并展望未来趋势。演讲涵盖内存、存储、CPU架构、网络与定制化硬件等方向，重点包括：HBM、CXL、DDR5/6、ZNS SSD、eBPF、FPGA、AI专用芯片（如Cerebras）、IPU、以及云原生虚拟化（如Nitro、Cloud Hypervisor）等。\n\n作者对CXL持保留态度，认为其虽能扩展内存容量和带宽，但增加延迟跳数可能带来性能代价，目前尚无明确“杀手级”应用场景。他强调当前水平扩展已能满足多数场景，大容量内存并非普遍刚需。\n\n演讲还分享了个人成长历程：从澳大利亚偏远地区的初级系统管理员起步，通过阅读技术资料、参与社区，最终实现赴美参会并成为演讲者，如今更在亚太地区担任大会开幕演讲人，感慨这是职业生涯的圆梦时刻。\n\n最后，作者宣布担任SREcon 2023 APAC程序联合主席，呼吁投稿，会议将于2023年6月在新加坡举行，投稿截止时间为3月2日。\n\n**核心要点：**\n- 技术趋势聚焦于异构计算、高带宽内存（HBM/CXL）、低延迟优化、定制芯片与软件定义基础设施。\n- 对新技术保持审慎乐观，强调实际性能收益与成本权衡。\n- 强调开源社区（如USENIX）对技术发展的关键作用。\n- 鼓励从业者积极参与技术交流与贡献。","published_at":"2023-03-01T00:00:00Z"}
{"domain":"brendangregg","path":"https://www.brendangregg.com//blog/2023-02-17/srecon-apac-2023.html","title":"USENIX SREcon APAC 2023: CFP","summary":"**摘要：**\n\nUSENIX SREcon APAC 2023 征稿截止日期为3月2日，会议将于6月14–16日在新加坡举行，由作者与澳洲同行Jamie Wilkinson共同担任程序主席。会议欢迎来自亚太地区、各类规模公司及不同技术背景（如SRE、运维、安全、数据库、性能工程等）的从业者投稿，尤其鼓励分享生产环境中的真实案例，包括失败教训、复杂问题与未解决挑战。  \n\n重点征集深入的技术内容：系统内部机制、高级工具与方法、可复用的解决方案（无论成功或失败）。特别重视新声音与多元视角，强调包容性，欢迎所有背景和技术角色参与。  \n\n作为原LISA会议精神的延续，SREcon已成为系统工程领域顶尖交流平台。建议未参会者参考2022年大会资料（含讲义与视频）了解内容风格。  \n\n**推荐人群**：有实战经验的工程师、技术负责人、系统架构师、故障复盘者，尤其是亚太区技术从业者。","published_at":"2023-02-17T00:00:00Z"}
{"domain":"davidxiang","path":"https://davidxiang.com/2022/07/30/software-project-planning/","title":"Software Project Planning","summary":"软件项目规划极其困难，每个阶段（设计、开发、测试、发布）都可能出问题。对于资深工程师、技术负责人和工程经理而言，关键在于把握三大核心挑战：\n\n1. **期望管理**：设定的时间和目标是否合理？  \n2. **团队对齐**：领导层是否真正支持并协同推进该项目？  \n3. **可行性评估**：在现有资源下，项目能否高质量完成？\n\n面对复杂项目，持续审视这三点可显著提升成功率。","published_at":"2022-07-30T00:00:00Z"}
{"domain":"emptysqua","path":"https://emptysqua.re/blog/the-eternaut/","title":"Versions of The Eternaut","summary":"《永恒流浪者》（The Eternaut）是阿根廷漫画家赫克托·赫尔曼·奥斯特埃尔德与画家弗朗西斯科·索拉诺·洛佩斯于1950年代创作的科幻经典，背景设定在1950年代的布宜诺斯艾利斯。故事讲述普通家庭男性胡安在一场突如其来的外星入侵中，与家人和朋友依靠自制防护服在毒雪覆盖的废墟中求生，最终因误触外星飞船按钮而被抛入无尽时空，永世漂泊寻找妻女。\n\n作品深受当时阿根廷政治动荡影响——尤其是1955年对庇隆支持者集会的轰炸事件。原作以“保卫家园”的英雄主义为核心，将外星入侵隐喻为军事独裁、帝国主义或压迫力量，展现中产阶级自由主义者的抵抗精神。然而，1969年重启版由奥斯特埃尔德与艺术家阿尔贝托·布雷西亚合作，风格剧变：画面如迷幻梦境，叙事充满怀疑与暴力，军队腐败、人性扭曲，北方盟友背叛南方，反映阿根廷进入“肮脏战争”时期的绝望。\n\n尽管1969版因激进的政治立场与实验性艺术遭冷遇，但其思想深度得以延续。2015年与2020年英文重印推动了全球关注，也启发了Netflix 2024年推出的同名剧集。剧集保留原作核心——封闭空间中的生存、身份迷失与集体心理，但将时间移至当代，融合新冠疫情后的现实体验，强化了社会分裂与科技依赖等新议题。虽然部分科学细节被简化（如毒雪逻辑模糊），但整体更具时代共鸣。\n\n总结：  \n- **核心主题**：外星入侵作为政治压迫与社会崩溃的隐喻，贯穿阿根廷历史创伤。  \n- **关键演变**：从1950年代的乐观抵抗，到1969年的悲观怀疑，再到当代剧集的复杂人性刻画。  \n- **现实映照**：疫情、信息战、技术失控等现代危机，使原作精神在今天焕发新生。  \n- **推荐人群**：科幻爱好者、政治寓言读者、后疫情时代反思者。","published_at":"2025-10-07T00:00:00Z"}
{"domain":"brendangregg","path":"https://www.brendangregg.com//blog/2022-05-02/brendan-at-intel.html","title":"Brendan@Intel.com","summary":"**摘要：**\n\nBrendan Gregg 加入英特尔，担任英特尔院士，致力于从应用程序到硬件的全栈性能分析与优化，重点聚焦云计算。他将推动eBPF等开源技术在跨平台（包括Windows）的应用，并参与Intel DevCloud等项目。他看好英特尔在新处理器（如Sapphire Rapids）、美国本土建厂及技术领导力（如Pat Gelsinger和Greg Lavender的回归）带来的变革机遇。他梦想将计算机性能分析系统化、科学化，实现对任何系统、工作负载和硬件的全面可观测性。尽管过去长期作为个体贡献者，如今他将组建团队、培养人才，并继续深耕开源生态。他与英特尔长期合作（尤其在Netflix期间），认可其专业、可靠的技术文化。未来将继续助力Netflix及其他云平台性能提升，推动全球计算效率进步。","published_at":"2022-05-02T00:00:00Z"}
{"domain":"brendangregg","path":"https://www.brendangregg.com//blog/2022-04-15/netflix-farewell-1.html","title":"Netflix End of Series 1","summary":"作者在Netflix工作近十年，从2014年加入以来，深度参与并推动了云原生性能分析技术的发展。面对当时缺乏生产环境可用的性能工具（如混合模式火焰图、eBPF动态追踪、PMCs等），他主动迎难而上，主导开发了多项关键技术：  \n- 推动Java混合模式火焰图落地，实现JVM性能可视化；  \n- 率先在生产环境中应用eBPF进行可观测性分析，奠定现代云监控基础；  \n- 联合AWS推动EC2上PMCs（性能监控计数器）启用，并开发配套工具；  \n- 开发FlameScope用于分析系统性能波动，提升故障排查效率。\n\n这些成果不仅为Netflix节省了巨额成本，也催生了整个可观测性产业生态。他还长期支持各团队解决性能问题，参与SRE应急响应、内部培训与跨部门协作，工作范围涵盖云工程、CDN（FreeBSD+NGINX）、微服务架构等多个领域。\n\n尽管对Netflix充满感激，且视其为职业生涯中最重要的平台，但他决定接受一个外部的新机会。文中强调：离职并非因公司问题，而是出于个人发展考量，并承诺将持续在此博客分享新工作进展。最后感谢了同事、社区与读者的支持，尤其提到两本著作《Systems Performance 2nd Ed》和《BPF Performance Tools》将继续为行业提供价值。","published_at":"2022-04-15T00:00:00Z"}
{"domain":"brendangregg","path":"https://www.brendangregg.com//blog/2022-04-09/tensorflow-library-performance.html","title":"TensorFlow Library Performance","summary":"**摘要：**\n\n本文分享了一次在 Netflix 使用 TensorFlow 时发现的性能问题排查过程。工程师 Vadim 通过分析 CPU 火焰图，发现一个异常的橙色调用栈（占 10% CPU 时间），根源在于频繁的页面故障（page faults）。尽管进程已运行数小时，内存应已完全映射，但仍持续发生页错误。\n\n进一步追踪发现，问题源于 `madvise()` 调用 `MADV_DONTNEED` 标志，导致内核释放了本应保留的物理内存映射，随后又因访问触发页故障重新加载，形成“无效优化”循环。该行为由 jemalloc 内存分配器触发。\n\n解决方案是将内存分配器从 jemalloc 切换为 glibc，问题立即解决，性能提升约 3%（原期望 10%）。此案例揭示了内存管理中“过早优化”的陷阱：看似节省资源的操作，实则因频繁页故障造成显著性能损耗。  \n\n**关键启示：**\n- 高频页故障可能隐藏在非预期位置。\n- `madvise(MADV_DONTNEED)` 若误用会引发性能灾难。\n- 工具链（如 eBPF、火焰图）对深度性能诊断至关重要。\n- 选择合适的内存分配器影响系统整体效率。\n\n**适合读者：** 系统性能调优工程师、机器学习部署开发者、内核与内存管理研究者。","published_at":"2022-04-09T00:00:00Z"}
{"domain":"brendangregg","path":"https://www.brendangregg.com//blog/2022-03-19/why-dont-you-use.html","title":"Why Don't You Use ...","summary":"**总结：**\n\n科技公司不采用某项技术，通常并非因为不了解或轻视，而是基于多方面深思熟虑的内部评估。常见原因包括：性能差、成本高、缺乏开源、文档不足、社区薄弱、安全补丁滞后、存在严重缺陷、法律条款不合规、团队缺乏领域专长、已有内部解决方案足够好、技术已过时、或开发者认为其前景堪忧（甚至在保密协议下）。\n\n这些理由中，许多涉及商业机密、内部评估细节或复杂技术判断，难以公开说明。公司更愿意解释“为何使用某技术”，而非“为何不使用”。若强行回应，可能因信息不全而被质疑，反而损害声誉。\n\n值得注意的是，真正出于“非此即彼”心态、傲慢或政治因素导致的技术决策极少，尤其在大型技术公司中，多数选择背后都有合理依据。\n\n**实用建议：**\n- 不要假设公司忽视某技术，他们很可能早已评估过。\n- 与其追问“为什么不使用？”，不如问：“你们是否了解这项技术？”、“它声称的优势是否可信？”——这类问题更容易获得真实回答。\n- 真正理解原因，唯一可靠方式是加入公司并接触相关团队。\n\n\u003e 技术选型的背后，往往是权衡与现实，而非无知或偏见。","published_at":"2022-03-19T00:00:00Z"}
{"domain":"emptysqua","path":"https://emptysqua.re/blog/chris-ridicullissima/","title":"Ridicullissima","summary":"2025年9月28日，作者在纽约州古恩克斯山脉拍摄好友克里斯攀登经典线路“Ridicullissima”（5.10d）。为获取独特视角，受攀岩教练Dustin Portzline建议，作者尝试将绳索一端固定于百英尺外的地面，通过两个Gri Gri调节两段绳长来悬停于空中。尽管操作笨拙且需大量练习，但双点连接有效防止了旋转。照片展现了攀岩过程与创意摄影的结合，幕后图也揭示了布线细节。适合对攀岩摄影与技术探索感兴趣的读者。","published_at":"2025-09-29T00:00:00Z"}
{"domain":"googleblog","path":"https://developers.googleblog.com/en/building-production-ai-on-google-cloud-tpus-with-jax/","title":"Building production AI on Google Cloud TPUs with JAX","summary":"**JAX AI Stack 概览总结**\n\nJAX 已成为构建前沿基础模型的核心框架，被 Anthropic、xAI、Apple 等领先公司广泛采用。Google 推出 **JAX AI Stack** —— 一个模块化、高性能的端到端机器学习平台，专为大规模 AI 开发设计。\n\n**核心架构理念：**\n- **模块化与松耦合**：各组件专注单一任务，支持灵活组合，便于快速迭代与创新。\n- **抽象连续性**：兼顾高阶自动化与底层精细控制，适应不同开发需求。\n\n**核心四组件（`jax-ai-stack`）：**\n1. **JAX**：基于函数式编程的加速器数组计算基础。\n2. **Flax**：提供类面向对象的神经网络接口，兼容主流框架风格。\n3. **Optax**：可组合的优化器库，支持梯度裁剪、累积等复杂策略。\n4. **Orbax**：支持异步分布式检查点，保障超大规模训练容错性。\n\n**扩展生态：**\n- **基础设施层**：XLA 编译器实现全程序优化；Pathways 实现跨数万芯片的统一运行时调度。\n- **极致性能工具**：Pallas 支持自定义硬件内核；Tokamax 提供 FlashAttention 等高性能预置内核；Qwix 实现无侵入式量化（如 QLoRA）；Grain 保证数据流水线可复现。\n- **生产部署能力**：MaxText / MaxDiffusion 为大模型训练提供高效率起点；Tunix 支持高效后训练（如 LoRA、DPO）；vLLM 用于通用推理部署。\n\n**实际成效：**\n- Kakao：LLM 吞吐提升 2.7 倍，成本优化显著。\n- Lightricks：突破视频扩散模型规模瓶颈，实现线性扩展。\n- Escalante：AI 蛋白质设计性能提升 3.65 倍/美元。\n\n**资源入口：**\n- 技术报告：[https://docs.cloud.google.com/tpu/docs/jax-ai-stack](https://docs.cloud.google.com/tpu/docs/jax-ai-stack)\n- 快速上手：[https://jaxstack.ai](https://jaxstack.ai)\n\n**适合人群**：研究人员、工程师、开发者，尤其关注大规模模型训练、高性能推理与生产落地者。","published_at":"2025-11-19T00:00:00Z"}
{"domain":"brendangregg","path":"https://www.brendangregg.com//blog/2021-09-26/the-speed-of-time.html","title":"The Speed of Time","summary":"**总结：**\n\n本文讲述了一个2014年Netflix从CentOS迁移到Ubuntu时遇到的性能问题：Cassandra数据库写延迟上升30%，CPU使用率显著增加。通过排查发现，问题根源在于`os::javaTimeMillis()`调用消耗了高达32%的CPU时间，而该函数底层依赖`gettimeofday(2)`系统调用。\n\n关键发现：\n- 在Ubuntu Xen虚拟机上，`gettimeofday`调用异常缓慢（约0.68μs），远高于CentOS的0.13μs（慢5倍）。\n- 原因是默认使用了较慢的`xen`时钟源（pvclock），而非更快的`tsc`（时间戳计数器）。\n- 通过微基准测试（microbenchmark）验证：将时钟源切换为`tsc`后，性能提升超过20倍，写延迟下降43%，甚至优于CentOS。\n\n启示：\n- **“时间”本身可能成为性能瓶颈**，尤其在虚拟化环境中。\n- **简单实验（如微基准测试）往往比复杂工具更有效**，作者强调“观察 + 实验”的双轨方法。\n- 最终推动了Netflix和AWS对`tsc`时钟源的广泛采用，并被纳入官方推荐。\n\n**实践建议：**\n- 在EC2 Xen实例上优先使用`tsc`时钟源。\n- 遇到可疑性能问题时，可编写极简微基准测试快速验证。\n- 技术决策应结合实测数据，而非仅依赖理论或默认配置。\n\n\u003e ✅ 核心思想：**有时最简单的实验，能揭开最深的性能谜题。**","published_at":"2021-09-26T00:00:00Z"}
{"domain":"brendangregg","path":"https://www.brendangregg.com//blog/2021-09-06/zfs-is-mysteriously-eating-my-cpu.html","title":"ZFS Is Mysteriously Eating My CPU","summary":"**摘要：**\n\n某微服务团队报告称，ZFS 文件系统占用了超过30%的CPU。作者通过监控工具发现系统态CPU高达38%，火焰图显示`arc_reclaim_thread`和`spl_kmem_cache_reap_now()`是主要消耗者，指向ZFS。然而，团队坚称未使用ZFS，且`df`、`mount`、`zfs list`均无输出，`arcstats`统计也全为零，表明ZFS从未被实际使用。\n\n深入分析代码后发现：即使未启用ZFS，其ARC缓存机制仍会因检测到低内存而触发回收逻辑，并尝试从零大小的多列表中“随机”选择一个进行清理。该过程调用高开销的**加密级随机数生成器**（`get_random_bytes`），导致无意义的CPU浪费。\n\n问题根源在于：**无用的随机选择逻辑在空缓存场景下仍执行昂贵操作**。作者提交了[ZFS Issue #6531]，后续修复通过提前退出非使用状态下的回收流程解决。此案例揭示了性能陷阱——即使功能未启用，低效代码仍可造成显著资源浪费。\n\n**关键洞察：**\n- 问题不在配置或使用，而在**未使用的功能中存在高成本逻辑**。\n- 随机数生成在无意义场景下成为性能瓶颈。\n- 原始假设（“必须在用才耗CPU”）误导判断，需依赖深度剖析。\n\n**适用人群：** 系统工程师、性能调优专家、内核开发者。","published_at":"2021-09-06T00:00:00Z"}
{"domain":"cloudflareblog","path":"https://blog.cloudflare.com/replicate-joins-cloudflare/","title":"Replicate is joining Cloudflare","summary":"**摘要：**\n\nCloudflare 宣布收购 AI 模型部署平台 Replicate，双方将深度融合其技术与生态。此次整合旨在打造全球领先的“AI 云”平台，让开发者能更轻松地构建和部署全栈 AI 应用。\n\n**核心亮点：**\n- **无缝延续服务**：现有 Replicate 用户不受影响，将获得 Cloudflare 全球网络带来的更高性能与可靠性。\n- **扩展模型能力**：Workers AI 将接入 Replicate 超过 5 万款开源及商业模型（如 GPT-5、Claude Sonnet），并支持自定义模型部署与微调。\n- **强化开发体验**：通过集成 Cog 工具链，实现模型打包标准化；结合 Cloudflare 服务器无服务器推理、向量数据库（Vectorize）、对象存储（R2）等，构建端到端的 AI 工作流。\n- **统一控制平台**：新推出的 **AI Gateway** 提供统一可观测性、流量管理、成本分析与 A/B 测试能力，覆盖所有模型运行环境。\n- **社区升级**：Replicate 的开放创新社区将借助 Cloudflare 网络加速，成为全球首选的 AI 模型探索与实验平台。\n\n**目标受众：**  \n开发者、AI 创业者、企业技术团队。特别适合希望快速部署、运行和规模化生成式 AI 应用的用户。\n\n**一句话总结：**  \n从“跑模型”到“建应用”，这次整合将让开发者在单一平台上，以最低成本、最高效率，实现从模型探索到生产落地的全链路突破。","published_at":"2025-11-17T00:00:00Z"}
{"domain":"brendangregg","path":"https://www.brendangregg.com//blog/2021-08-30/high-rate-of-paging.html","title":"Analyzing a High Rate of Paging","summary":"该博客记录了一个微服务在处理大文件上传时性能严重下降的诊断案例。问题表现为100GB文件上传耗时数小时，而40GB文件仅需几分钟。通过一系列Linux性能工具分析，最终定位到根本原因是**页面缓存（page cache）被“击穿”**。\n\n关键发现如下：\n- **高页错误率（paging）**：监控系统显示大文件上传时页错误（pageins）激增。\n- **iostat** 显示磁盘读取延迟高（r_await约33ms），且队列深度大，表明大量等待磁盘I/O。\n- **biolatency** 和 **bitesize** 表明I/O大小正常，无设备异常。\n- **free** 显示系统内存64GB，其中48GB用于缓冲/页面缓存，剩余可用内存仅349MB。\n- **cachestat** 是关键工具，揭示100GB文件上传时缓存命中率仅为6.5%-74%，远低于理想水平（应\u003e90%），说明数据无法完全驻留内存，频繁从磁盘读取。\n- 对比测试32GB文件时，缓存命中率达100%，磁盘I/O极低，验证了“文件大小超出缓存容量”是主因。\n\n**结论与建议**：\n- 100GB文件超出48GB页面缓存容量，导致频繁页错误和磁盘读取，拖慢上传速度。\n- 解决方案：升级至更大内存实例，或优化代码（如分块处理、减少全量重读）。\n- 工具价值：`cachestat`（基于Ftrace/eBPF）在本次诊断中起决定性作用，但仍是实验性工具。作者呼吁内核层面原生支持页面缓存统计，以解决其高开销和维护难题。\n\n**适用人群**：系统工程师、SRE、云平台开发者，尤其关注大规模文件处理性能调优者。","published_at":"2021-08-30T00:00:00Z"}
{"domain":"davidxiang","path":"https://davidxiang.com/2022/04/25/art-or-science/","title":"Art or Science?","summary":"**摘要：**\n\n本文探讨了“艺术”与“科学”在软件开发及职场中的辩证关系。核心观点：**所有工作都处于艺术与科学的连续谱上，而非非此即彼**。\n\n- **艺术**体现在难以量化的领域：如团队对齐（共识）、跨职能合作（伙伴关系）、教练式辅导。这些依赖人际理解、情境判断和经验积累，需灵活应变，体现人性与创造力。\n- **科学**则体现在可重复、可验证的流程中：如编码（强调可维护性、可扩展性）、运维（从混乱到标准化的演进）、绩效反馈（目标明确、结果导向）。\n\n关键洞察：\n- 高阶科学（如资深工程师的实践）常“看似艺术”，因已内化为直觉；\n- 真正有效的领导力在于平衡：用科学建立框架，以艺术驾驭人与关系；\n- 管理者应以科学方式处理绩效与晋升，但持续投入艺术性的辅导与支持。\n\n**适用人群**：软件工程师、技术管理者、团队领导者。  \n**核心启示**：不要执着于“艺术”或“科学”的标签，而要根据情境灵活运用两者，才能找到高效且可持续的解决方案。","published_at":"2022-04-25T00:00:00Z"}
{"domain":"emptysqua","path":"https://emptysqua.re/blog/npzc-eye-opening/","title":"Eye Opening Ceremony at the New Paltz Zen Center","summary":"2025年9月27日，新帕尔茨禅中心（New Paltz Zen Center）正式升格为禅寺，举行开眼仪式。住持乔安老师为殿内文殊菩萨像开光，母寺“村禅堂”住持亦到场赐福。这一里程碑标志着该社区在禅修传承与实践上的重要进展，凝聚了多年努力与集体信念。仪式通过多张照片记录，展现了庄严而温暖的时刻。","published_at":"2025-09-28T00:00:00Z"}
{"domain":"brendangregg","path":"https://www.brendangregg.com//blog/2021-08-27/slack-crashes-secret-stderr.html","title":"Slack's Secret STDERR Messages","summary":"**总结：**\n\n作者在Ubuntu上使用Snap安装的Slack频繁无故崩溃，尤其在锁屏/解锁时。通过一系列调试手段，最终定位到根本原因是Slack尝试加载缺失的GDK-PixBuf PNG图像加载器库（`libpixbufloader-png.so`），该文件存在于新版本路径 `/snap/slack/44/...`，但程序仍试图从旧路径 `/snap/slack/42/...` 加载，导致失败并引发崩溃。\n\n关键发现：\n- 崩溃前最后输出为 `Gtk:ERROR: ... Failed to load ... libpixbufloader-png.so`，来自 `stderr`，未记录在日志中。\n- 使用 `shellsnoop` 工具捕获了这一错误信息。\n- 问题根源是Snap包构建时路径引用不一致，旧版本路径（42）已失效。\n\n**解决方案：**\n创建符号链接将当前版本（44）指向旧路径（42）：\n```bash\nln -s current 42\n```\n此操作使Slack能正确找到所需共享库，问题解决。\n\n**调试过程亮点：**\n- 使用 `exitsnoop`、`perf trace` 和 `signals.bt` 确认是 SIGABRT 信号触发崩溃。\n- `opensnoop` 可提前发现文件打开失败，但作者未及时使用。\n- 最终靠 `shellsnoop` 捕获被重定向至 `/dev/null` 的错误输出。\n\n**适用人群：** 使用Snap版Slack且遇到类似无响应或崩溃问题的Linux用户。  \n**建议：** 优先检查 `stderr` 输出，善用 `shellsnoop`、`opensnoop` 等eBPF工具进行快速诊断。","published_at":"2021-08-27T00:00:00Z"}
{"domain":"brendangregg","path":"https://www.brendangregg.com//blog/2021-07-05/computing-performance-on-the-horizon.html","title":"USENIX LISA2021 Computing Performance: On the Horizon","summary":"本文由性能工程师Brendan Gregg分享其在系统性能领域的最新观察与未来预测，聚焦后端服务器技术的多维度演进。主要内容包括：\n\n- **处理器**：3D堆叠技术、AWS Graviton2等云原生CPU推动性能突破；英特尔Sapphire Rapids采用多芯片设计与HBM2E内存。\n- **内存**：DDR5普及，延迟挑战加剧；高带宽内存（HBM）实现芯片级集成，显著提升带宽。\n- **存储**：3D XPoint（如Intel Optane）作为3D NAND加速器，提升存储性能；ZNS SSD优化写入效率；希捷推出20TB HAMR硬盘。\n- **网络**：QUIC协议与eXpress Data Path（XDP）提升低延迟通信能力；800G以太网加速发展。\n- **其他趋势**：FPGA与定制硬件（如谷歌TPU、Cerebras WSE）用于AI与特定负载；微软探索自研ARM服务器芯片。\n\n作者强调这些技术正共同重塑高性能计算架构，并基于其《系统性能（第二版）》的经验提出前瞻性判断。尽管预测可能不完全准确，但旨在激发对下一代系统性能发展方向的深入思考。文末附有演讲视频、幻灯片及详尽参考文献列表，涵盖从2008年至今的关键技术进展。","published_at":"2021-07-05T00:00:00Z"}
{"domain":"brendangregg","path":"https://www.brendangregg.com//blog/2021-07-03/how-to-add-bpf-observability.html","title":"How To Add eBPF Observability To Your Product","summary":"**摘要：**\n\n本文为快速在商业可观测性产品或自研监控系统中集成 eBPF 技术提供实用指南，强调“最小投入、最大价值”的务实思路（版本1）。核心建议如下：\n\n1. **快速起步**：使用成熟的开源工具如 `bcc` 或 `bpftrace`，例如运行 `execsnoop-bpfcc` 观察进程启动，即可发现性能问题（如无限重启的进程）。\n2. **轻量集成**：将已有 BPF 工具（如 execsnoop）嵌入产品，仅运行 10–60 秒以降低开销，避免长期运行带来的性能影响。\n3. **无需重写**：不要从零开始用新语言重写 BPF 工具，应直接复用 `bcc`/`bpftrace` 工具，利用其已有的维护和更新机制，避免因内核升级导致的兼容性问题。\n4. **推荐工具集**：列出 10 个关键 BPF 工具（如 `execsnoop`, `opensnoop`, `biolatency`, `tcplife`, `profile` 等），并配以可视化建议（表格、热力图、火焰图等），构建基础可观测性仪表盘。\n5. **未来方向**：`bcc` 和 `bpftrace` 正逐步支持 BTF + CO-RE，未来可实现无依赖、小体积的二进制部署（需 Linux 5.8+ 及 CONFIG_DEBUG_INFO_BTF 配置）。\n6. **案例参考**：Netflix 和 Facebook 均基于 bpftrace 构建大规模 BPF 监控系统，通过集中管理脚本实现动态更新与统一维护。\n7. **避坑提醒**：切勿盲目移植旧版 BPF 工具（如基于 Ftrace 的 cachestat），这类工具随内核演变更易失效，维护成本极高。\n\n**核心观点**：  \n与其“程序员思维”地从头造轮子，不如“系统管理员思维”——直接利用现有成熟工具快速落地，持续拉取更新。这能避开复杂调试、维护负担和潜在缺陷，是高效引入 eBPF 观测能力的最优路径。\n\n**适合人群**：  \n希望快速接入 eBPF 的可观测性平台开发者、运维工程师、SRE 及企业监控系统建设者。","published_at":"2021-07-03T00:00:00Z"}
{"domain":"googleblog","path":"https://developers.googleblog.com/en/jules-gemini-3/","title":"Building with Gemini 3 in Jules","summary":"**摘要：**\n\n谷歌推出搭载 **Gemini 3 Pro** 的智能编程代理 **Jules**，面向 Google AI Ultra 和 Pro 订阅用户逐步上线。该模型在代码生成、多步骤任务执行和零样本推理方面超越前代，显著提升 Jules 的自主性与可靠性，实现更清晰的逻辑推理、更强的任务意图对齐和上下文保持能力。\n\nJules 现已支持多平台无缝使用（终端、CLI 扩展、API），项目状态跨环境同步，真正实现“始终在线、随处可用”的开发体验，让开发者专注构思而非管理工具。\n\n近期更新包括：\n- CLI 支持并行运行、Windows 兼容、差分预览；\n- API 稳定，支持自定义流程；\n- 改进环境变量与会话记忆；\n- “评审代理”更可靠，能自动重规划；\n- Git 操作更安全，虚拟机响应更快。\n\n未来计划：快速目录接入、自动标题更新、网页端快捷键、简化启动模式、实验性自动创建 Pull Request。\n\n👉 详情见 [jules.google.com](http://jules.google.com/) 及 [更新日志](http://jules.google/docs/changelog)。\n\n**适合人群**：开发者、技术团队、希望提升编码效率的 AI 工具使用者。","published_at":"2025-11-19T00:00:00Z"}
{"domain":"brendangregg","path":"https://www.brendangregg.com//blog/2021-06-15/bpf-internals.html","title":"USENIX LISA2021 BPF Internals (eBPF)","summary":"本文是作者在 USENIX LISA2021 上关于 BPF 内核机制的40分钟深度技术演讲摘要，聚焦于可观测性追踪工具的实现原理。与已有 BPF 文档不同，本次演讲从用户态到机器码逐层剖析 bpftrace 的工作流程，揭示其底层组件如何协同运作，强调其实现逻辑并不复杂。\n\n主要内容包括：\n- 演讲视频和幻灯片已公开（附链接），内容涵盖 BPF 从用户空间到内核的完整调用链。\n- 引用多个权威资料，如 Linux 内核头文件、Cilium 文档、Brendan Gregg 和 BPF 性能工具书等，供深入学习。\n- 建议持续关注 Linux 内核头文件更新，并推荐订阅 `bpf-next` 邮件列表或查阅 KernelNewbies 的内核动态摘要以掌握最新进展。\n- 补充提及微软近期推出的 Windows 上 eBPF 实现，作为另一条发展路径。\n- 作者的《BPF Performance Tools》一书正在限时5天促销（至6月19日）。\n\n适合对象：系统工程师、性能调优专家、内核开发者及对 eBPF 感兴趣的技术人员。","published_at":"2021-06-15T00:00:00Z"}
{"domain":"emptysqua","path":"https://emptysqua.re/blog/how-to-belay-with-glasses/","title":"How To Belay With Prescription Glasses Or Sunglasses","summary":"**总结：**\n\n本文分享了作者在攀岩时佩戴眼镜（包括太阳镜和处方镜）并配合保护器（belay glasses）的实用解决方案。核心要点如下：\n\n- **推荐使用多功能镜片**：如Roka的变色镜，兼具视力矫正与防晒功能，佩戴稳固、防滑，适合跑步、骑行和攀岩。\n- **搭配YY Vertical Clip-Ups保护镜**：可夹在已有眼镜顶部，翻转使用，便于观察上方岩壁或正常视线切换。但重量较重，需额外加固。\n- **增强稳定性**：建议用耳钩（如亚马逊购买）固定镜架，防止汗水导致下滑；同时用强力胶加固镜片底部橡胶垫，避免脱落。\n- **升级收纳方案**：原配收纳盒和卡扣脆弱易损，推荐改用坚固的战术钱包+登山扣，防水耐用，适合作为高空攀爬时的安全存储。\n\n✅ **实用建议**：这套组合能实现全天候清晰视野，尤其适合多段攀岩中既要看清前方又要抬头观察的场景。  \n📌 **适用人群**：戴眼镜/太阳镜的攀岩者，尤其是户外多段攀登爱好者。","published_at":"2025-09-22T00:00:00Z"}
{"domain":"brendangregg","path":"https://www.brendangregg.com//blog/2021-06-04/an-unbelievable-demo.html","title":"An Unbelievable Demo","summary":"这是一篇令人难以置信的开源故事：作者布伦丹·格雷格（Brendan Gregg）在2005年意外发现，Sun Microsystems全球巡展的“革命性DTrace产品”，竟完全由他本人此前开源的工具组成。  \n\n**核心事件**：  \n一位来自美国的Sun高级工程师在悉尼演示其“全新”DTrace GUI产品，展示的正是格雷格自己开发并公开发布的脚本（如`socketsnoop.d`），但所有版权、署名和许可证均被移除，重新包装后以Sun名义销售。格雷格当场认出这些代码正是自己的作品，震惊不已。\n\n**关键洞察**：  \n- 他的开源工具被内部团队直接拿走、去标识化、商业化，甚至用于全球推广。  \n- 这反映出当时Sun公司文化中一种根深蒂固的偏见：认为外部贡献者的作品“不值一提”，可随意重用与再授权。  \n- 尽管有少数团队尊重开源协议（如苹果、Oracle、BSD社区后来正确使用了他的工具），但这一事件暴露了企业对开源社区的严重忽视。\n\n**深层反思**：  \n- 开源开发者常面临“自己的代码被别人当成果卖”的风险。  \n- 格雷格建议：不要重复造轮子，应基于现有成熟项目（如BPF/bcc工具）构建，避免资源浪费和版本落后。  \n- 唯一例外是“火焰图”（Flame Graph），因其算法简单且已稳定，允许自由复刻——但仍希望获得致谢。\n\n**总结**：  \n一个开源者的“自我复制”奇遇，揭示了技术企业与开放社区之间的信任鸿沟。它提醒我们：尊重原创、维护开源精神，比任何“创新”都更重要。","published_at":"2021-06-04T00:00:00Z"}
{"domain":"davidxiang","path":"https://davidxiang.com/2022/03/09/guidelines-for-criticism/","title":"Guidelines For Criticism","summary":"**总结：**\n\n本文强调工程师在团队协作中应秉持的四项核心原则：\n\n1. **自省优先**：避免指责他人，先审视自身问题。对他人行为的负面解读（如效率低、固执）常源于自我合理化，而自己类似行为却常被正当化。\n\n2. **待人宽容，律己严格**：对他人保持包容与理解，对自己则要严苛要求，主动发现并改进不足。\n\n3. **不妄自以为能教导他人**：承认自己知识有限，分享经验时避免居高临下，以谦逊态度提升沟通与反馈效果。\n\n4. **信守承诺建立信任**：唯有言行一致，才能让批评与建议被真正倾听，信任是有效反馈的基础。\n\n**核心启示**：高效协作始于自我觉察与责任感，真正的专业不仅在于技术，更在于品格与关系管理。  \n**适合读者**：开发者、技术团队负责人、希望提升协作能力的工程师。","published_at":"2022-03-09T00:00:00Z"}
{"domain":"brendangregg","path":"https://www.brendangregg.com//blog/2021-05-29/moving-to-australia.html","title":"Moving my US tech job to Australia","summary":"作者从硅谷湾区搬至澳大利亚悉尼，继续在Netflix担任性能工程职位，成为首批从Linux云团队远程迁至澳大利亚的员工之一。尽管工作内容与以往无异，但这一变动反映了科技人才和资本正加速向全球分散，尤其是硅谷之外的地区。作者选择澳大利亚的原因包括：对祖国的归属感、签证不确定性与国际税务复杂性、以及澳洲本地技术生态的蓬勃发展（如AWS、Google及Netflix本地办公室）。  \n\n他强调，远程工作并非新鲜事——Linux内核开发本身就是全球分布式协作的典范，且他曾成功通过远程方式完成《系统性能》第二版的写作。未来，他期待采用“混合办公”模式，定期赴美参与团队会议。为适应时差，他设定早起工作时间，保持与加州3-5小时重叠，并用计时工具追踪专注工作时长，提升效率。  \n\n总结：技术岗位的全球化已成趋势，远程工作不仅可行，且能带来生活质量提升；关键在于主动管理时间、沟通与自我激励。适合那些渴望灵活性并愿意投入额外努力的人。","published_at":"2021-05-29T00:00:00Z"}
{"domain":"emptysqua","path":"https://emptysqua.re/blog/how-to-check-all-your-feeds/","title":"How To Check All Your Feeds With One Tool","summary":"**摘要：**\n\n作者提出，管理所有网络信息源的“终极工具”并非复杂的聚合器或订阅服务，而是简单的浏览器书签夹——他称之为“check”文件夹。通过将所有需定期查看的网站（如社交媒体、RSS订阅、个人项目、社交联络表等）集中存入此文件夹，只需一键打开全部标签页，即可高效浏览。\n\n这一方法不仅是便捷的“上网消遣”方式，更是一种行为调控机制：通过主动管理书签，能引导未来自己的注意力——加入新平台（如Feedbin）或移除无效尝试（如放弃Mastodon），从而避免无意义的执着。对于无法订阅更新的网站（如论坛、会议页面），直接添加书签至该文件夹，即可定期手动检查，无需依赖第三方监控工具。\n\n**核心价值：**\n- 用最小成本实现全网信息追踪。\n- 以“可操作的注意力管理”替代被动刷屏。\n- 简单、灵活、无需依赖外部平台。\n\n**适合人群：** 追求高效数字生活、反感信息碎片化、希望掌控自己在线时间的用户。","published_at":"2025-09-08T00:00:00Z"}
{"domain":"amazonscience","path":"https://www.amazon.science/blog/making-fairness-in-llms-observable-quantifiable-and-governable","title":"Making fairness in LLMs observable, quantifiable, and governable","summary":"**摘要：**\n\n研究人员在大语言模型（LLM）的推理能力上取得显著进展，尤其在有明确答案的编码与数学任务中表现优异。然而，面对涉及个人、社会属性的开放性问题（如职业建议），模型可能因隐含偏见而对不同性别、种族、年龄群体给出差异化的建议，导致不公平结果。\n\n为解决这一问题，研究团队提出 **FiSCo（公平性在语义上下文中）** 三阶段评估框架，将公平性视为“意义层面”的推理问题，而非仅关注用词或情感。其核心思想是：当仅改变用户的敏感属性（如性别）时，模型是否提供语义等价的指导？\n\n**FiSCo 三大步骤：**\n1. **受控生成**：创建仅在敏感属性上不同的匹配提示，生成多轮响应以捕捉随机性；\n2. **语义比较**：分解回答内容，分析行动建议、动机、资源与风险，并进行语义对齐分析；\n3. **统计验证**：使用如 Welch’s t 检验等方法，判断组间差异是否具有统计显著性。\n\n实验发现：  \n- 大型闭源模型（如 GPT-4o、Claude 3）偏差较低；  \n- 小型或中型开源模型（如 Llama 3、Mixtral）存在明显性别与种族偏见；  \n- 更新推理模型未必更公平（如 GPT-OSS-120B 偏差反而更高）。\n\n**结论：** 模型推理能力与公平性并非同步提升，需主动干预。FiSCo 提供可复现、可扩展、适应复杂输出的公平性评估工具，适用于模型审计、治理监控与透明度建设。\n\n👉 项目代码与数据详见：[FiSCo GitHub](https://github.com/HuXiangkun/FiSCo)  \n📌 被选为 **COLM 2025 口头亮点论文**，代表该领域前沿成果。","published_at":"2025-11-20T00:00:00Z"}
{"domain":"googleblog","path":"https://developers.googleblog.com/en/building-ai-agents-with-google-gemini-3-and-open-source-frameworks/","title":"Building AI Agents with Google Gemini 3 and Open Source Frameworks","summary":"**摘要：**\n\n谷歌推出 **Gemini 3 Pro Preview**，作为新一代智能代理（AI Agents）的核心引擎，具备更强的自主决策与复杂任务处理能力。该模型专为构建高级、状态化、多步骤的智能代理而设计，支持以下关键特性：\n\n- **可调推理深度（thinking_level）**：通过 `high`/`low` 设置实现推理强度与性能的灵活权衡。\n- **带加密签名的思维状态保持（Thought Signatures）**：确保跨工具调用时逻辑连贯，防止上下文丢失。\n- **多模态清晰度调节（media_resolution）**：按需平衡图像/文档解析精度与成本。\n- **长上下文一致性**：结合思维签名，避免长时间对话中的“推理漂移”。\n\n谷歌已与主流开源生态深度协作，实现 **Day 0 支持**，包括：\n- **LangChain**：支持图式工作流与状态化多角色代理。\n- **Vercel AI SDK**：提供类型安全的 TypeScript 工具链，显著提升代码生成与推理成功率。\n- **LlamaIndex**：强化知识代理构建，高效连接私有数据。\n- **Pydantic AI**：通过类型安全保障生产级代理的可靠性。\n- **n8n**：让非开发者也能零代码构建高级自动化代理。\n\n**开发建议**：\n- 停用复杂提示工程，改用 `thinking_level` 控制推理；\n- 保持 `temperature=1.0`；\n- 必须捕获并回传 `thoughtSignature`；\n- PDF 使用 `medium` 分辨率以节省 token；\n- 参考 [Gemini 3 开发者指南](https://ai.google.dev/gemini-api/docs/gemini-3) 进行迁移。\n\n**适用人群**：开发者、企业技术团队、业务自动化人员，尤其适合构建高可靠、可扩展的下一代 AI 代理系统。","published_at":"2025-11-19T00:00:00Z"}
{"domain":"shopifyblog","path":"https://shopify.engineering/bfcm-readiness-2025","title":"How we prepare Shopify for BFCM","summary":"**摘要：**\n\nShopify为应对2025年黑五网一（BFCM）流量高峰，启动了全年无休的“韧性建设”计划。通过**容量规划、基础设施升级、风险评估**三线并行推进，构建可扩展的多区域架构，并以**游戏日（Game Days）和混沌工程**模拟系统故障，提前暴露并修复关键路径（如结账、支付）中的瓶颈。\n\n核心举措包括：\n- **大规模压力测试**：每月进行高强度负载测试，最高达200万请求/分钟，覆盖全球三地生产环境；\n- **真实场景模拟**：引入网络延迟、缓存失效、区域故障等复杂情况，验证跨系统容灾能力；\n- **新系统专项攻坚**：针对全新上线的分析平台（无历史数据），通过实验识别出Kafka分区、内存使用、连接超时等问题并优化；\n- **五轮“规模测试”**：从基础性能验证到全链路灾难恢复演练，第四次测试即突破1.46亿请求/分钟，第五次在工作时间完成“彩排”，全面模拟真实流量。\n\n所有发现均录入**韧性矩阵**（Resiliency Matrix），形成标准化应急响应手册，实现系统级加固。工具与流程已沉淀为长期资产，持续提升平台日常稳定性。\n\n最终目标不仅是撑过BFCM，更是打造**全年可用、自动适应、自我修复**的高韧性平台。2025年11月28日，他们已准备就绪。","published_at":"2025-11-20T00:00:00Z"}
{"domain":"kaiwaehner","path":"https://www.kai-waehner.de/blog/2025/11/19/data-streaming-meets-lakehouse-apache-iceberg-for-unified-real-time-and-batch-analytics/","title":"Data Streaming Meets Lakehouse: Apache Iceberg for Unified Real-Time and Batch Analytics","summary":"请提供博客文章内容，以便我为您生成简洁准确的中文摘要。","published_at":"2025-11-19T00:00:00Z"}
{"domain":"davidxiang","path":"https://davidxiang.com/2022/01/24/monolith-to-microservices/","title":"Monolith To Microservices Vs. Your Organization","summary":"**总结：**\n\n“从单体架构向微服务迁移”常被视为技术成功的象征，但这一过程远非单纯的工程挑战，而是一场深刻的企业组织变革。作者指出，微服务的定义模糊，实际系统多为混合或“混乱球状”结构，而非理想化的纯微服务。\n\n文章强调五大关键组织性障碍：\n1. **预算对齐**：微服务运维成本高昂，需提前与高管沟通商业价值并获得明确支持。\n2. **经验缺失**：真正经历过此类迁移的工程师极为稀少，缺乏实战经验易导致失败。\n3. **哲学分歧**：开发团队中“通用型”与“具体型”思维的工程师可能对架构设计有根本冲突，需提前达成共识。\n4. **所有权不清**：若代码模块无人负责，重构将难以推进，组织协作效率大打折扣。\n5. **士气问题**：初期的拆分工作枯燥且无成就感，若规划不当极易挫伤团队积极性。\n\n结论：微服务迁移不仅是技术升级，更是组织能力的考验。没有高层支持、团队共识和清晰治理，再优秀的工程师也无法成功。真正的成功源于组织层面的准备与协同。","published_at":"2022-01-24T00:00:00Z"}
{"domain":"brendangregg","path":"https://www.brendangregg.com//blog/2021-05-23/what-is-observability.html","title":"What is Observability","summary":"**摘要：**\n\n“可观测性”（Observability）是计算机工程中用于描述系统运行状态的观察能力，强调通过工具、数据源（如指标、日志、追踪）非侵入式地理解系统行为。它不同于“可观察的”（observable），因为后者易引发歧义——并非所有指标都“不可观测”。  \n\n关键点：  \n- 可观测性工具仅读取状态，不改变系统（如监控仪表盘）。  \n- 实验性工具会干扰系统（如基准测试），例如汽车0-60加速测试。  \n- 真正的可观测性意味着“先观察，再干预”，避免盲目修改。  \n- 工具虽通常无害，但可能因资源消耗产生“观察者效应”。  \n\n核心理念：  \n\u003e “你有两只手——可观测性和实验性。”  \n解决问题应结合两种方式，单一依赖一种等于“单手操作”，效率低下。\n\n**适用人群**：开发者、运维工程师、性能调优人员。  \n**价值**：提升诊断效率，避免误判，推动系统健康度管理。","published_at":"2021-05-23T00:00:00Z"}
{"domain":"emptysqua","path":"https://emptysqua.re/blog/math-images-rss-hugo/","title":"How My Blog Handles Math and Images in HTML, Atom, and Email in 2025","summary":"该博客作者致力于打造视觉精美、数学与图像（尤其是SVG）呈现效果出色的科技博客，但面临技术限制的挑战。他使用Hugo作为静态站点生成器，因其速度极快（700篇文章下全站重建\u003c1秒），尽管其扩展性较弱且依赖Markdown。\n\n核心痛点在于：**不同平台（网页、RSS订阅、邮件）对图像和数学公式的支持差异巨大**。为此，他构建了一套复杂的“技术折衷”流水线：\n\n1. **图片预览**：通过自定义模板为本地开发服务器中的图片添加哈希缓存标记，确保修改图片后浏览器能正确刷新。\n2. **SVG兼容性**：所有Excalidraw绘制的SVG在发布时自动转换为PNG/JPEG，并通过`\u003cpicture\u003e`标签实现“优先显示SVG，不支持则降级到图片”的优雅回退，保障邮件客户端（如Gmail）也能正常显示。\n3. **数学公式渲染**：\n   - 网页端使用原生HTML `\u003cmath\u003e`标签，由浏览器原生渲染；\n   - 在RSS/邮件中，公式被提前转为带哈希命名的SVG，再转为PNG，通过`\u003cpicture\u003e`标签嵌入，确保兼容性。\n4. **图片样式适配**：针对邮件平台（曾用Mailchimp）的图像显示问题，编写特定模板调整图片布局与样式；后改用Kit，问题得以缓解。\n\n总结：这是一套高度定制、充满“权宜之计”的系统，用于应对当前生态中各平台对现代网页特性支持不足的问题。作者调侃这是“2025年的技术奇观”，感叹“未来已来，只是分布不均”。他的方案虽复杂，但对追求极致内容体验的开发者或技术写作者极具参考价值——尤其适合需要跨平台（网页+邮件+订阅）高质量展示数学与图形内容的人群。","published_at":"2025-08-31T00:00:00Z"}
{"domain":"googleblog","path":"https://developers.googleblog.com/en/5-things-to-try-with-gemini-3-pro-in-gemini-cli/","title":"5 things to try with Gemini 3 Pro in Gemini CLI","summary":"**Gemini 3 Pro 已上线 Gemini CLI，开启终端智能新体验**\n\n谷歌将最强模型 **Gemini 3 Pro** 集成至 **Gemini CLI**，大幅提升终端开发效率。该模型具备卓越的推理能力，支持复杂工程任务、多模态理解与智能工具调用，助力开发者从创意到落地一键完成。\n\n**核心亮点：**\n- **智能编码**：可基于自然语言描述生成完整可运行项目（如带 3D 图形的网页应用），甚至通过上传草图自动转换为代码。\n- **多模态理解**：支持图像输入，将手绘界面草图转化为 HTML/CSS/JS 代码。\n- **自然语言命令**：用日常语言生成复杂 Shell 命令（如 Git Bisect 查找问题提交）。\n- **智能文档生成**：自动分析代码库，生成结构清晰、含搜索功能的用户与开源贡献文档。\n- **跨服务调试**：联动 Cloud Run 与 Snyk 等工具，自动诊断性能瓶颈并推荐修复方案。\n\n**访问方式：**\n- 仅限 **Google AI Ultra** 订阅用户及拥有付费 Gemini API Key 的开发者。\n- Gemini Code Assist Enterprise 用户即将开放。\n- 其余用户可加入 [等待列表](https://forms.gle/ospXWr8SRTg73eBA8)，关注 [GitHub 滚动状态页](https://goo.gle/geminicli-waitlist-status)。\n\n**快速上手：**\n```bash\nnpm install -g @google/gemini-cli@latest\n```\n进入 `/settings`，开启“预览功能”即可使用 Gemini 3 Pro。\n\n**适用人群：** 开发者、工程师、技术团队，尤其适合希望提升日常开发效率、实现智能化工作流的用户。  \n**一句话总结：** 用自然语言驱动终端，让代码生成、调试、文档撰写变得更智能、更高效。","published_at":"2025-11-18T00:00:00Z"}
{"domain":"kaiwaehner","path":"https://www.kai-waehner.de/blog/2025/11/13/data-streaming-in-retail-social-commerce-from-influencers-to-inventory/","title":"Data Streaming in Retail: Social Commerce from Influencers to Inventory","summary":"**社交电商重塑零售：实时数据流是核心驱动力**\n\n社交平台（如TikTok、Instagram、Facebook）已从内容传播渠道演变为全链路购物平台，实现“灵感—发现—购买”无缝衔接，这标志着**社交电商**时代的到来。与早期直播带货不同，社交电商将购物嵌入日常社交行为中，每条视频、帖子或故事都可能触发即时购买。\n\n**关键挑战在于实时性**：网红推广可能在数秒内引发海量订单，传统基于定时轮询的API接口因延迟、不一致和系统脆弱性，极易导致超卖、库存错误或交易失败。\n\n解决方案是构建**事件驱动的实时数据流架构**，以Apache Kafka和Flink为核心：\n\n- **持续数据流动**：订单、库存、价格变动等事件实时同步至所有系统（ERP、CRM、物流、广告平台）。\n- **统一数据真相**：确保用户在社交平台看到的商品状态与仓库、官网完全一致。\n- **智能响应**：支持动态定价、自动补货、个性化推荐，并为生成式AI与代理型AI提供实时上下文，提升决策质量。\n- **跨生态协同**：连接线上线下的全渠道体验，打通供应链、营销与客户互动，实现“从内容到交付”的闭环管理。\n\n更进一步，面对OpenAI等AI平台进军零售带来的竞争，数据流技术让品牌能自主构建具备实时性、智能化与个性化能力的私有化购物体验，甚至通过合作将自身数据接入外部AI生态，掌握主动权。\n\n**结论**：社交电商的本质是“实时零售”。唯有依托**数据流平台**，才能支撑高并发、强交互、全链路融合的现代零售模式，打造可信、敏捷、智能的未来商业基础设施。","published_at":"2025-11-13T00:00:00Z"}
{"domain":"davidxiang","path":"https://davidxiang.com/2021/12/30/use-more-1-1-1s/","title":"Use More 1-1-1s","summary":"**总结：**\n\n1-1-1会议是领导力工具箱中的高效协作方式，由三位关键人员（如经理、下属及其上级或跨团队成员）参与，适用于复杂情境下的目标对齐与决策推进。文章列举了5种典型使用场景：\n\n1. **汇报关系调整**：在员工转岗时，由现任经理、原直属员工和新经理三方共同确认绩效与未来期望，确保平稳过渡。  \n2. **临时资源调配**：项目需临时调人时，通过1-1-1明确工作投入、里程碑和职责分工，提升协作效率。  \n3. **资深工程师嵌入团队**：为避免“悬浮工程师”现象，通过会议明确资深工程师以指导、评审为主，而非直接贡献代码，统一团队认知。  \n4. **特殊角色融入团队**：如技术作家、产品设计师等稀缺角色入驻时，协调其职责定位（目标制定或项目交付），防止误解与资源错配。  \n5. **推动僵局决策**：当两位资深成员意见相持不下时，引入第三方（如主管或高阶专家）主持1-1-1，打破“同侪综合征”，加速决策。\n\n**核心价值**：1-1-1能清晰定义期望、化解冲突、建立共识，是提升组织协同效率的重要手段。**推荐所有工程领导者掌握并灵活运用这一机制。**","published_at":"2021-12-30T00:00:00Z"}
{"domain":"brendangregg","path":"https://www.brendangregg.com//blog/2021-05-09/poor-disk-performance.html","title":"Poor Disk Performance","summary":"本文通过一个实际案例，深入解析了硬盘性能诊断中常见问题：**如何判断性能指标“好”或“坏”**。作者展示了一块因灰尘污染且未安装盖板的老旧IDE硬盘在不同状态下的性能数据（iostat、biolatency、biosnoop），揭示了性能异常的根本原因。\n\n### 核心观点：\n- **性能好坏需结合上下文判断**：单一指标（如`r_await`）不能孤立分析。高延迟（如434ms）但队列长度低（`aqu-sz`小），说明是**物理故障**而非工作负载过重。\n- **振动是主因**：硬盘盖板缺失导致剧烈振动，使磁头无法稳定飞行。施加压力（如用手压盖板）可显著改善性能，证明问题源于机械稳定性而非盘片本身损坏。\n- **工具组合使用更有效**：`iostat`提供总体统计，`biolatency`显示延迟分布（出现2秒级异常），`biosnoop`记录每条I/O事件，三者结合才能准确识别问题本质——**非排队延迟，而是磁头反复尝试读取失败**。\n\n### 关键发现：\n1. 灰尘并未直接摧毁磁头，反而可通过外部压力维持部分读取能力（成功读取99.9999%扇区）。\n2. 现代硬盘（如SMR）可能对灰尘更敏感，但本实验表明老式硬盘具有惊人容错性。\n3. 用身体重量“压住”盖板模拟螺丝固定，是一种实用的临时修复方法。\n\n### 实用建议：\n- 面对异常性能时，应优先排查**物理因素**（振动、松动、灰尘）而非立即怀疑硬件故障。\n- 推荐使用BPF工具链（如`biolatency`、`biosnoop`）进行细粒度分析，避免被平均值误导。\n- 对于老旧设备，适度“人工干预”（如固定外壳）可能恢复部分功能。\n\n### 适合读者：\n系统管理员、运维工程师、性能调优人员，以及对存储底层原理感兴趣的开发者。","published_at":"2021-05-09T00:00:00Z"}
{"domain":"emptysqua","path":"https://emptysqua.re/blog/review-common-knowledge-part-2/","title":"Knowledge and Common Knowledge in a Distributed Environment, Part 2","summary":"**摘要：**\n\n本文是关于分布式系统中“知识”与“共识”理论的系列文章第二篇，深入探讨了著名的“协调攻击问题”（Coordinated Attack Problem）及其与**共同知识**（common knowledge）之间的根本矛盾。\n\n- **核心论点**：在异步系统中，即使通信可靠，两个将军也无法**绝对确信**达成一致攻击时间。因为任何消息确认都可能丢失或延迟，导致双方无法确认对方是否收到并同意。\n  \n- **关键洞见**：要实现协同行动，必须达成“共同知识”——即每个人都知道计划，且每个人都清楚对方也知道，依此类推，无限递归。但异步系统中，这种无限层级的知识无法被保证，因此**协调攻击不可能实现**，这与FLP不可能性定理一致。\n\n- **形式化模型**：作者引入了“不可区分图”（indistinguishability graph）来形式化“知识”的定义——一个节点知道某事实，当且仅当该事实在所有其无法区分的状态中都为真。通过构建状态图并标注各节点的观察等价类，可以直观分析谁“知道”什么。\n\n- **应用实例**：以Raft协议为例，展示了领导者如何基于追随者发送的确认，判断日志是否已多数复制（即“多数复制”这一事实是否成为共同知识），并通过图结构验证知识传播路径。\n\n- **意义**：该框架不仅解释了为何某些分布式协议存在局限，也为形式化验证系统知识状态提供了强大工具。\n\n✅ **适合读者**：分布式系统开发者、形式化方法研究者、对共识机制和逻辑推理感兴趣的工程师。","published_at":"2025-08-25T00:00:00Z"}
{"domain":"kaiwaehner","path":"https://www.kai-waehner.de/blog/2025/10/30/kafka-proxy-demystified-use-cases-benefits-and-trade-offs/","title":"Kafka Proxy Demystified: Use Cases, Benefits, and Trade-offs","summary":"请提供博客文章内容，以便我为您生成简洁准确的中文摘要。","published_at":"2025-10-30T00:00:00Z"}
{"domain":"davidxiang","path":"https://davidxiang.com/2021/12/17/4-questions-to-ask-yourself/","title":"4 Questions To Ask Yourself","summary":"本文以角色视角梳理了工程师（IC）与管理者在不同职级的成长关键指标：\n\n**初级工程师（Junior IC）**：  \n- 是否能独立编码与排查问题？  \n- 能否清晰介绍团队工作？  \n- 是否清楚遇到难题时的求助路径（非仅依赖导师）？  \n- 是否完整主导过从零到一的项目交付？\n\n**资深工程师（Senior IC）**：  \n- 是否推动其他团队调整工作方向？  \n- 对产品目标与技术决策是否有坚定见解？  \n- 是否理解同事面临的挑战（即使非本职）？  \n- 是否有同事主动解决复杂问题，且无需自己介入？\n\n**管理者（Manager）**：  \n- 下属是否展现出更大影响力，晋升理由是否充分？  \n- 自身职责与权责是否持续提升？是主动争取还是被动承担？  \n- 是否有明确接班人选？  \n- 团队成果源于规模扩张，还是因自身推动的效率创新？\n\n**核心启示**：职业成长不只看任务量，更在于影响力、主动性与系统性贡献。每个层级需超越“执行者”定位，向“驱动者”和“赋能者”演进。","published_at":"2021-12-17T00:00:00Z"}
{"domain":"brendangregg","path":"https://www.brendangregg.com//blog/2020-11-04/bpf-co-re-btf-libbpf.html","title":"BPF binaries: BTF, CO-RE, and the future of BPF perf tools","summary":"**摘要：**\n\nBTF（BPF类型格式）和CO-RE（BPF编译一次，随处运行）两项技术正推动eBPF走向大规模应用，有望催生一个千亿级产业。它们解决了eBPF部署中依赖LLVM、Clang和内核头文件导致的庞大体积（超100MB）问题，使BPF程序可轻量化运行于各类环境，尤其适合嵌入式系统。\n\n- **BTF** 提供内核结构体类型信息，避免运行时依赖头文件。\n- **CO-RE** 实现BPF字节码重定位，让编译后的程序无需重新编译即可在不同内核版本上运行。\n\n结果是：工具如`opensnoop`可打包为仅151KB的独立ELF二进制文件，不依赖libLLVM或libclang，兼容支持BTF的任意内核。\n\n关键前提：需启用内核配置 `CONFIG_DEBUG_INFO_BTF=y`（仅增加约1.5MB），当前Ubuntu 20.10已默认开启。\n\n未来趋势：\n- BCC Python脚本将逐步被libbpf C替代，其Python接口将被弃用（书中附录C示例已过时）。\n- bpftrace将继续优化，目标减小安装包体积，提升灵活性。\n- 高级复杂工具推荐使用libbpf，而快速原型开发仍可用bpftrace。\n\n最终形态：轻量级、跨内核、即插即用的BPF工具集，极大促进eBPF在性能分析、安全与网络领域的普及。","published_at":"2020-11-04T00:00:00Z"}
{"domain":"emptysqua","path":"https://emptysqua.re/blog/speak-up-if-youre-stuck-in-a-zazen-rut/","title":"Speak Up If You're Stuck in a Zazen Rut","summary":"这篇博客探讨了禅修中长期被回避的敏感话题：**关于进步、体验与目标的讨论**。作者在纽约新帕尔兹禅中心的演讲中，坦诚分享自己多年来的禅修困境——尽管坚持每日坐禅，却常陷入“停滞期”，感到无聊、分心、无趣，甚至怀疑是否值得继续。\n\n核心观点如下：\n\n1. **禅宗沉默的代价**：  \n   禅修社区普遍回避谈论“进步”“深度体验”或“如何提升”。这种沉默让修行者误以为“不应评价自己的禅修”，导致许多人独自承受挫败感，不敢向老师或同修倾诉。作者回忆自己曾因嫉妒他人（如一位同学快速进入“无”之境）而痛苦，也因无法重现某次深刻的寂静之夜而愤怒，这说明**对经验的执着与比较，恰恰是修行中的常见障碍**。\n\n2. **突破瓶颈的尝试：参加Jhourney禅修营**：  \n   作者尝试了一种基于上座部佛教“禅那”（Jhana）体系的现代禅修项目，强调通过实验性方法（如调整姿势、观想、情绪引导）来主动培养平静、开放的心境。他成功进入“初禅”，感受到身体温暖、心灵轻盈、喜悦涌动。关键转变在于：**不再抗拒念头，而是接纳它们，像欢迎朋友一样邀请它们加入当下**。\n\n3. **从“对抗”到“拥抱”**：  \n   他发现，真正的禅修不是压抑杂念，而是以温柔、开放的态度面对一切。当不再试图“控制”内心，反而更容易进入深层专注。这一改变使他的日常坐禅从“挣扎”变为“轻松享受”。\n\n4. **批判“反目标”的极端思维**：  \n   作者指出，许多禅修者反对设定目标，认为这是“执着”，但讽刺的是，“禅”（Zen）正是源自梵语“禅那”（Dhyana），即禅定。禅宗本身也有明确的阶次（如公案考试），为何不能接受适度的目标？**真正的自由，是能根据需要选择是否追求目标**。\n\n5. **精神友谊的力量**：  \n   作者强调，与志同道合的朋友坦诚交流至关重要。在孤独中隐藏困惑只会加深痛苦；而一旦说出“我的禅修一团糟”，才发现原来大家都有类似经历，从而重获希望。\n\n6. **最终的洞见：真正的禅是自由**  \n   佛陀临终时说：“你们要做自己的岛屿，做自己的灯。”禅的本质不是盲从传统或沉默，而是**在适当的时候打破沉默，在必要时保持静默**。真正的修行，是忠于自我觉察，既不沉迷过去体验，也不否定当下努力。\n\n📌 **总结**：  \n这篇文字是一次勇敢的自我揭露与精神解放。它提醒我们：  \n- 不必害怕谈论禅修的进展与感受；  \n- 接纳自己的失败与好奇，才是进步的开始；  \n- 真正的禅，不是压抑与沉默，而是**自由地看见、表达与探索**。  \n\u003e “别怕说‘我搞砸了’——那是你重新开始的起点。”","published_at":"2025-08-19T00:00:00Z"}
{"domain":"kaiwaehner","path":"https://www.kai-waehner.de/blog/2025/10/25/how-stablecoins-use-blockchain-and-data-streaming-to-power-digital-money/","title":"How Stablecoins Use Blockchain and Data Streaming to Power Digital Money","summary":"请提供博客文章内容，以便我为您生成简洁准确的中文摘要。","published_at":"2025-10-25T00:00:00Z"}
{"domain":"brendangregg","path":"https://www.brendangregg.com//blog/2020-07-15/systems-performance-2nd-edition.html","title":"Systems Performance: Enterprise and the Cloud, 2nd Edition","summary":"**《系统性能：企业与云》第二版简要总结**\n\n作者Brendan Gregg推出其经典著作《系统性能：企业与云》第二版，该书自2012年首版以来广受好评，销量超1万册，被众多公司列为必读书目，甚至出现在职位招聘要求中。新版基于作者在Netflix六年高级性能工程师的经验，全面更新内容：\n\n- **新增重点**：深入涵盖BPF、BCC、bpftrace、perf和Ftrace等现代性能观测工具；\n- **删减内容**：移除大部分Solaris相关内容，聚焦于现代Linux与云环境；\n- **全面更新**：涵盖最新Linux内核特性、云计算架构及性能调优实践；\n- **质量提升**：由30多位技术专家参与审校，确保准确性与实用性。\n\n书中通过对比色标注（从黄到红）直观展示章节更新情况，例如第六章“CPU”部分变化显著。全书约800页，将于2020年11月由Addison-Wesley出版，已在Amazon上线。\n\n本书可视为“系统性能入门与通识指南”，适合所有希望理解计算机内部工作原理和系统性能的工程师。而其姊妹篇《BPF性能工具》则聚焦于BPF追踪技术，适合希望快速上手高级观测工具的读者。\n\n**建议**：两本均推荐购买，前者为系统性基础手册，后者为进阶实战工具书，互补性强。  \n官网：[Systems Performance: Enterprise and the Cloud, 2nd Edition](/systems-performance-2nd-edition-book.html)","published_at":"2020-07-15T00:00:00Z"}
{"domain":"kaiwaehner","path":"https://www.kai-waehner.de/blog/2025/10/15/cybersecurity-with-a-digital-twin-why-real-time-data-streaming-matters/","title":"Cybersecurity with a Digital Twin: Why Real-Time Data Streaming Matters","summary":"请提供博客文章内容，以便我为您生成简洁准确的中文摘要。","published_at":"2025-10-15T00:00:00Z"}
{"domain":"brendangregg","path":"https://www.brendangregg.com//blog/2020-03-08/lisa2019-linux-systems-performance.html","title":"LISA2019 Linux Systems Performance","summary":"本文介紹了在40分鐘內快速掌握Linux系統效能分析的核心內容，涵蓋六個關鍵領域：監控工具、分析方法、基準測試、剖析（profiling）、追蹤（tracing）與調校。作者強調，即使非專業的效能或核心工程師，也能透過這些技術有效提升應用程式與系統性能。講義與影片已公開於YouTube及PDF格式，並提及個人著作《Systems Performance》第二版正在編寫中，同時未來將推出更完整的BPF效能工具工作坊錄影課程，以支援遠端學習。","published_at":"2020-03-08T00:00:00Z"}
{"domain":"kaiwaehner","path":"https://www.kai-waehner.de/blog/2025/09/30/scaling-kafka-consumers-proxy-vs-client-library-for-high-throughput-architectures/","title":"Scaling Kafka Consumers: Proxy vs. Client Library for High-Throughput Architectures","summary":"请提供博客文章内容，以便我为您生成简洁准确的中文摘要。","published_at":"2025-09-30T00:00:00Z"}
{"domain":"brendangregg","path":"https://www.brendangregg.com//blog/2019-12-22/bpf-theremin.html","title":"BPF Theremin, Tetris, and Typewriters","summary":"本文分享了Netflix工程师Brendan Gregg在AWS re:Invent演讲中展示的eBPF（BPF）技术实战应用，重点呈现其“BPF超能力”：通过内核级追踪实现创新监控与交互。核心内容包括：\n\n1. **无线信号转音频**：使用`bpftrace`快速追踪Intel网卡驱动`__iwl_dbg`函数，实时获取Wi-Fi信号强度，并将其转化为音调（类“电子琴”效果），演示了BPF在系统可观测性中的即时响应能力。\n\n2. **从bpftrace到BCC的进阶**：为实现音频输出，将原一行为`bpftrace`脚本升级为基于Python和BCC的程序，结合Pygame生成动态音效，展示了BPF工具链的灵活性。\n\n3. **开发建议**：推荐新手从`bpftrace`入手，因其语法简洁、易上手；仅在需要复杂逻辑或外部库时才转向BCC，避免“从字节码写Java”的低效路径。\n\n4. **扩展案例**：\n   - 基于bpftrace的《俄罗斯方块》游戏（支持键盘输入追踪）\n   - “打字机音效”工具`bpf-typewriter`，通过追踪键盘事件触发声音反馈\n\n5. **技术演进**：Linux 5.3提升BPF指令上限至百万级，使复杂程序成为可能，推动BPF向通用计算发展。\n\n**总结**：本文以趣味项目为切入点，展示了eBPF在性能分析、系统调试与创意交互中的强大潜力，强调“从简单开始、用合适工具”的实践原则，鼓励开发者利用BPF构建实用或富有想象力的观测工具。适合对系统性能、内核编程和BPF感兴趣的开发者阅读。","published_at":"2019-12-22T00:00:00Z"}
{"domain":"kaiwaehner","path":"https://www.kai-waehner.de/blog/2025/09/22/square-sumup-shopify-real-time-point-of-sale-pos-in-the-age-of-data-streaming/","title":"Square, SumUp, Shopify: Real-Time Point-of-Sale (POS) in the Age of Data Streaming","summary":"请提供博客文章内容，以便我为您生成简洁准确的中文摘要。","published_at":"2025-09-22T00:00:00Z"}
{"domain":"brendangregg","path":"https://www.brendangregg.com//blog/2019-12-02/bpf-a-new-type-of-software.html","title":"BPF: A New Type of Software","summary":"BPF（伯克利包过滤器）已从最初的网络数据包过滤工具，演变为Linux内核中通用的可执行引擎，能够运行用户定义的内核态程序。这类程序不以进程或内核模块形式存在，传统可观测性工具无法追踪，但正悄然改变50年来操作系统的核心架构——通过提供一种新型接口，让应用程序在系统调用之外直接与内核交互。\n\n目前Netflix和Facebook分别在云服务器上运行15个和40个BPF程序，广泛用于性能监控、安全检测等场景。作者认为，这是近几十年来操作系统最重大的变革之一。其新书《BPF性能工具》聚焦于BPF在可观测性领域的应用，并在Ubuntu Masters和AWS re:Invent大会上深入分享该技术。这标志着BPF已成为一种全新的软件形态，正在重塑现代系统的可观测性和控制能力。","published_at":"2019-12-02T00:00:00Z"}
{"domain":"kaiwaehner","path":"https://www.kai-waehner.de/blog/2025/09/15/online-feature-store-for-ai-and-machine-learning-with-apache-kafka-and-flink/","title":"Online Feature Store for AI and Machine Learning with Apache Kafka and Flink","summary":"请提供博客文章内容，以便我为您生成简洁准确的中文摘要。","published_at":"2025-09-15T00:00:00Z"}
{"domain":"brendangregg","path":"https://www.brendangregg.com//blog/2019-10-15/kernelrecipes-kernel-ftrace-internals.html","title":"Two kernel mysteries and the most technical talk I've ever seen","summary":"本文揭示了 Linux 内核中两个令人困惑的机制：`__fentry__` 的存在和 Ftrace 能够低开销实时追踪所有内核函数的原因。\n\n1. **`__fentry__` 的作用**：每个内核函数开头都插入 `callq __fentry__`，这是 Ftrace（内核跟踪工具）的核心机制。它并非用于性能监控，而是作为“钩子”（hook），允许动态注入代码，实现函数调用的自动探测，而无需修改原函数逻辑。\n\n2. **Ftrace 的低开销原理**：通过“动态重写”技术，在运行时仅在需要时才启用追踪逻辑。默认情况下，`__fentry__` 是一个空操作（no-op），只有当用户启用追踪时才会触发实际行为，因此几乎不影响系统性能。\n\n文章强调，这一机制源于 2014 年至 2019 年间 Steven Rostedt 在 Kernel Recipes 上的深度分享，是理解内核动态追踪机制的关键。作者推荐观看其完整视频与相关演讲（如 BPF 在 Facebook 的应用、eBPF 的重要性），以深入掌握现代内核可观测性技术。","published_at":"2019-10-15T00:00:00Z"}
{"domain":"kaiwaehner","path":"https://www.kai-waehner.de/blog/2025/09/11/how-data-streaming-powers-ai-and-autonomous-networks-in-telecom-insights-from-tm-forum-innovate-americas/","title":"How Data Streaming Powers AI and Autonomous Networks in Telecom – Insights from TM Forum Innovate Americas","summary":"请提供博客文章内容，以便我为您生成简洁准确的中文摘要。","published_at":"2025-09-11T00:00:00Z"}
{"domain":"brendangregg","path":"https://www.brendangregg.com//blog/2019-08-19/bpftrace.html","title":"A thorough introduction to bpftrace","summary":"**bpftrace 简介总结（中文）**\n\n**核心主旨**：  \nbpftrace 是一款基于 eBPF 的开源 Linux 跟踪工具，专为高效诊断生产环境性能问题而设计。它通过动态追踪内核与用户态函数，提供细粒度的性能洞察，尤其擅长分析延迟分布、异常峰值和系统瓶颈。\n\n**关键亮点**：\n- **轻量级、快速上手**：支持命令行一元式脚本（one-liners），无需复杂开发即可快速排查问题。\n- **强大可视化能力**：可生成幂次方直方图（如读取延迟分布），揭示平均值无法反映的“双峰”或异常值（如缓存命中/未命中）。\n- **丰富内置探针**：支持 `kprobe`、`kretprobe`、`tracepoint`、`usdt` 等多种类型，覆盖内核、系统调用、用户程序等场景。\n- **变量与函数强大**：使用 `@name` 作为 BPF 映射变量，支持 `hist()`、`lhist()`、`count()` 等内置函数，轻松汇总数据。\n- **开箱即用工具集**：自带 28 个实用脚本（如 `biolatency.bt`、`opensnoop.bt`），涵盖 I/O、网络、进程、内存等常见性能问题。\n\n**典型应用场景**：\n- 快速定位慢查询、小文件频繁读写、高延迟磁盘操作。\n- 分析系统调用频率、进程间调度、内存分配行为。\n- 安全团队用于快速探测潜在漏洞（零日攻击）。\n\n**与 BCC 对比**：\n- **bpftrace**：适合临时调试、即兴分析，语法简洁，响应快。\n- **BCC**：适合构建长期运行的工具、监控代理，支持多语言（Python/C++），功能更完整但代码更冗长。\n\n**适用人群**：\n- 系统管理员、DevOps 工程师、性能优化专家。\n- 运维、安全、开发团队均可借助其快速排查问题。\n\n**学习资源**：\n- [官方 GitHub](https://github.com/iovisor/bpftrace)\n- 一元脚本教程：[tutorial_one_liners.md](https://github.com/iovisor/bpftrace/blob/master/docs/tutorial_one_liners.md)\n- 参考手册：[reference_guide.md](https://github.com/iovisor/bpftrace/blob/master/docs/reference_guide.md)\n\n\u003e ✅ 推荐理由：对于希望快速获得系统深层可见性的工程师，bpftrace 是当前最高效的 eBPF 入门与实践工具。","published_at":"2019-08-19T00:00:00Z"}
{"domain":"brendangregg","path":"https://www.brendangregg.com//blog/2019-07-15/bpf-performance-tools-book.html","title":"BPF Performance Tools: Linux System and Application Observability (book)","summary":"**《BPF性能工具：Linux系统与应用可观测性》书籍摘要**\n\n本书由性能工程专家Brendan Gregg撰写，是首部聚焦于eBPF技术在生产环境性能分析中应用的权威指南，即将由Addison Wesley出版。书中包含150多个可直接运行的BPF可观测性工具（其中超100个为全新开发），覆盖CPU、内存、磁盘、文件系统、网络、多语言应用、容器、虚拟化及安全分析等广泛领域。\n\n核心亮点：\n- **实战导向**：以真实生产场景（如Netflix）为基础，提供可复用的诊断案例与避坑经验。\n- **工具丰富**：涵盖BCC和bpftrace两大主流前端，支持快速上手并自定义开发。\n- **内容深度**：远超网络资源，融合传统工具（如iostat、perf）与现代BPF能力，强调“用对工具解决对问题”。\n- **未来兼容**：虽部分工具依赖不稳定接口（如kprobe），但已通过tracepoint优化，并预留更新机制（GitHub仓库持续维护）。\n- **社区共建**：受益于全球BPF开发者协作，包括bpftrace创建者Alastair Robertson、eBPF奠基人Alexei Starovoitov等。\n\n本书标志着Linux可观测性的新纪元——让开发者能随时提出任意系统问题，并获得精准数据响应。它不仅是工具手册，更是性能思维升级的指南。\n\n适合读者：系统工程师、运维人员、开发人员、SRE及任何希望深入理解生产系统性能瓶颈的人群。\n\n\u003e 作者曾著有畅销书《系统性能》，本作专注“可观测性”，可视为其进阶之作。后续将推出第二版《系统性能》。","published_at":"2019-07-15T00:00:00Z"}
{"domain":"brendangregg","path":"https://www.brendangregg.com//blog/2019-04-26/yow2018-cloud-performance-netflix.html","title":"YOW! 2018 Cloud Performance Root Cause Analysis at Netflix","summary":"该博客分享了作者在2018年YOW!澳大利亚大会上的主题演讲经历，内容聚焦于Netflix的云性能分析实践。作者系统梳理了Netflix的技术架构，介绍了如何从全局视角诊断云环境中的性能问题，并通过火焰图等工具深入定位到具体实例。演讲兼具技术深度与实用性，可视为新入职Netflix员工的“60分钟入门速成课”。尽管内容详实、准备充分（甚至超过以往任何一次演讲），但作者反思其深度可能超出关键演讲的受众预期，且更新成本高，因此不太可能再次公开讲授。此外，演讲中存在一处笔误（将1.3亿用户误写为13万），并特别感谢了大会组织者及同行的协助。整体而言，此次巡演不仅是一次技术分享，更是一段充满人际连接与归属感的难忘经历，被作者称为最具意义的演讲体验。","published_at":"2019-04-26T00:00:00Z"}
{"domain":"brendangregg","path":"https://www.brendangregg.com//blog/2019-01-01/learn-ebpf-tracing.html","title":"Learn eBPF Tracing: Tutorial and Examples","summary":"**eBPF 学习指南摘要（按级别划分）**\n\n- **核心观点**：eBPF 已成为现代 Linux 系统可观测性、性能分析与安全的核心技术，掌握它是一项极具价值的技能。本文提供从入门到进阶的 eBPF 追踪学习路径。\n\n---\n\n### 🟢 **初学者：使用 bcc 工具**\n- **目标**：无需编写代码，直接运行现成工具。\n- **推荐操作**：\n  - 安装 [bcc](https://github.com/iovisor/bcc)（如 Ubuntu 上 `sudo apt-get install bpfcc-tools`）。\n  - 使用预置工具：`opensnoop`、`tcplife`、`biolatency`、`profile` 等，观察系统行为（如文件打开、网络连接、磁盘延迟）。\n- **学习资源**：\n  - [bcc 教程](https://github.com/iovisor/bcc/blob/master/docs/tutorial.md)（11 个常用工具实操）。\n  - 工具附带详细示例和 man 手册，可快速上手。\n- **关键优势**：高效且低开销，可在生产环境长期运行。\n\n---\n\n### 🟡 **中级用户：使用 bpftrace 开发脚本**\n- **目标**：编写自定义追踪脚本，用高阶语言快速实现。\n- **推荐工具**：[bpftrace](https://github.com/iovisor/bpftrace)，支持类似命令行的一行脚本。\n- **学习路径**：\n  - [bpftrace 一元教程](https://github.com/iovisor/bpftrace/blob/master/docs/tutorial_one_liners.md)（12 个渐进式示例）。\n  - 参考 [参考手册](https://github.com/iovisor/bpftrace/blob/master/docs/reference_guide.md) 和 [工具示例](https://github.com/iovisor/bpftrace/tree/master/tools)。\n- **示例**：\n  ```bash\n  bpftrace -e 'tracepoint:syscalls:sys_enter_open { printf(\"%d %s\\n\", pid, str(args-\u003efilename)); }'\n  ```\n\n---\n\n### 🔴 **高级用户：开发 bcc 工具并贡献社区**\n- **目标**：深入开发，参与开源项目。\n- **学习方向**：\n  - 掌握 bcc 的 Python/C++ 用户层 + BPF 内核层双层开发。\n  - 阅读 [bcc 开发者教程](https://github.com/iovisor/bcc/blob/master/docs/tutorial_bcc_python_developer.md) 与 [参考指南](https://github.com/iovisor/bcc/blob/master/docs/reference_guide.md)。\n  - 贡献代码：提交 issue、修复问题、撰写文档、做演示。\n- **进阶挑战**：参与内核 BPF 引擎开发，关注 [netdev 邮件列表](https://www.spinics.net/lists/netdev/)。\n\n---\n\n### ✅ **总结建议**\n- 初学者：**运行 bcc 工具** → 快速体验系统洞察。\n- 中级者：**用 bpftrace 编写脚本** → 自定义监控逻辑。\n- 高级者：**开发 bcc 工具 + 贡献社区** → 深入内核与生态。\n\n\u003e 📚 **延伸推荐**：作者新书《BPF Performance Tools》（Addison Wesley）系统讲解 eBPF 性能观测，是进阶必读。  \n\u003e 🔗 官方资源页：[eBPF Tracing Tools](http://www.brendangregg.com/ebpf.html)\n\n**新年决心？学 eBPF，让系统可见、可控、可优化！**","published_at":"2019-01-01T00:00:00Z"}
{"domain":"brendangregg","path":"https://www.brendangregg.com//blog/2018-12-15/flamescope-origin.html","title":"FlameScope Origin","summary":"**总结：**\n\n本文介绍了Netflix团队为解决每15分钟出现一次的间歇性性能瓶颈问题，开发并应用**FlameScope**工具的过程。核心问题表现为服务“ums”请求延迟周期性上升，但工作负载未变，初步怀疑是垃圾回收（GC），实际并非如此。\n\n关键步骤包括：\n1. 使用`perf`采集3分钟堆栈样本，记录异常发生时的数据。\n2. 初步尝试按时间切片生成火焰图（每10秒或1秒一个），耗时且难以定位。\n3. 引入**亚秒级热力图**（subsecond-offset heatmap）可视化，将时间粒度细化至20毫秒，清晰显示三种模式：\n   - 每60秒出现的三道高CPU使用垂直带（监控系统伺服）；\n   - 约60毫秒的短时高负载突发（垃圾回收）；\n   - 采样起始阶段的异常高峰（初始化开销）。\n4. 基于热力图，开发**FlameScope**工具，支持点击任意时间区间自动生成对应火焰图，实现快速定位——最终确认根本原因是**应用缓存定期刷新**。\n\n**价值与启示：**\n- 通过高精度时间维度可视化，显著提升性能分析效率；\n- 工具从原型到开源（Netflix FlameScope），已成为分析系统性能瓶颈的重要利器；\n- 推荐给运维、开发及性能调优工程师，尤其适用于排查周期性、瞬时性性能问题。","published_at":"2018-12-15T00:00:00Z"}
{"domain":"brendangregg","path":"https://www.brendangregg.com//blog/2018-11-08/flamescope-pattern-recognition.html","title":"FlameScope Pattern Recognition","summary":"**FlameScope 概要总结（中文）**\n\nFlameScope 是 Netflix 开源的一款性能分析可视化工具，结合**子秒级偏移热力图**与**火焰图**，用于分析系统中**周期性行为、波动性及异常扰动**。其核心创新在于“子秒级偏移热力图”——以秒为单位的横轴，纵轴表示每秒内事件发生的分布（分桶），颜色深浅反映事件密度，直观展现高精度时间序列上的活动模式。\n\n### 主要功能与洞察：\n- **周期性活动识别**：通过热力图可清晰分辨单线程/多线程每秒或每半秒唤醒一次的规律，甚至判断是否为忙等待（busy-wait）及其工作时长（可通过斜率估算）。\n- **负载波动分析**：展示不同负载水平（如 5%~100%）下的 CPU 利用情况，识别突发负载或周期性高峰（如每 30 秒持续 5 秒重载）。\n- **异常扰动检测**：\n  - 全局峰值（如垃圾回收 GC）表现为所有核心瞬间满载；\n  - 集体阻塞（如 I/O 等待）表现为全核空闲；\n  - 单线程阻塞（如全局锁）则显示为仅一条线活跃，其余空闲 —— 此时点击该线即可生成火焰图，快速定位问题代码路径。\n\n### 实际价值：\n- 将复杂性能问题“视觉化”，无需深入日志即可快速定位瓶颈；\n- 支持交互式选择特定模式，自动生成对应火焰图，实现从现象到根因的高效追踪。\n\n### 适用人群：\n开发者、运维工程师、性能调优专家，尤其适合排查高并发、低延迟系统的隐性性能问题。\n\n\u003e 🔗 项目地址：[https://github.com/Netflix/flamescope](https://github.com/Netflix/flamescope)  \n\u003e 📌 推荐：掌握热力图模式后，能显著提升性能诊断效率。欢迎分享发现的典型模式！","published_at":"2018-11-08T00:00:00Z"}
{"domain":"brendangregg","path":"https://www.brendangregg.com//blog/2018-10-08/dtrace-for-linux-2018.html","title":"bpftrace (DTrace 2.0) for Linux 2018","summary":"**bpftrace 公开发布：Linux 系统追踪的 DTrace 替代品**\n\n**核心观点**  \n`bpftrace` 是一个开源的高级系统追踪工具，基于 eBPF（扩展伯克利包过滤器）构建，旨在成为现代 Linux 环境下的 DTrace 2.0。其私有仓库已公开，标志着该项目进入成熟阶段。\n\n**关键亮点**  \n- **高阶语言设计**：语法类似 DTrace，支持一元脚本和短脚本，适合快速排查性能问题。\n- **完整功能覆盖**：现已支持结构体解析、内核/用户态探针（kprobes/uprobes）、栈跟踪保存、变量聚合等，可实现文件打开、系统调用计数、读延迟分析等场景。\n- **创新能力**：能将用户栈作为变量保存，用于检测文件描述符泄漏、内存分配未释放等问题，且在内核中完成，效率远高于传统方法。\n- **与 DTrace 对比**：不仅兼容多数 DTrace 功能，还具备更强大的能力（如栈变量存储），同时与 bcc 工具互补，适用于不同场景。\n\n**技术架构**  \n- 基于 eBPF 虚拟机运行，通过 LLVM IR 编译为 BPF 字节码。\n- 使用 lex/yacc 解析器，支持复杂逻辑与动态数据处理。\n- 依赖 `bcc` 库，但提供更高层次抽象，降低使用门槛。\n\n**适用人群**  \n- 系统工程师、性能优化专家、运维人员。\n- 熟悉 DTrace 的用户可快速上手。\n- 希望在生产环境实时诊断性能瓶颈的技术团队。\n\n**推荐行动**  \n- 安装要求：Linux 内核 4.9+（建议 4.18+），参考 [INSTALL.md](https://github.com/iovisor/bpftrace/blob/master/INSTALL.md)。\n- 学习资源：[one-liners 教程](https://github.com/iovisor/bpftrace/blob/master/docs/tutorial_one_liners.md) 和 [参考指南](https://github.com/iovisor/bpftrace/blob/master/docs/reference_guide.md)。\n- 参与贡献：提交 issue，协助修复缺陷或开发新功能。\n\n**总结**  \n`bpftrace` 是 Linux 追踪生态的重要突破，融合了 DTrace 的易用性与 eBPF 的强大能力，是系统级可观测性的利器。它不仅是工具升级，更是整个系统调试范式的演进。","published_at":"2018-10-08T00:00:00Z"}
{"domain":"brendangregg","path":"https://www.brendangregg.com//blog/2018-06-30/benchmarking-checklist.html","title":"Evaluating the Evaluation: A Benchmarking Checklist","summary":"**总结：**\n\n本文分享了作者在性能分析与基准测试中的核心方法论，源自同事推荐的“性能七诫”（如“不要做”“少做”“并发做”等），并进一步提出一套用于评估基准测试准确性的**七大检查问题**，旨在识别和避免误导性基准结果。\n\n**核心要点：**\n1. **为何不翻倍？** 检查性能瓶颈，通过主动观测（active benchmarking）找出限制因素。\n2. **是否已调优？** 确保测试环境和目标系统已启用所有生产级优化配置，避免遗漏关键功能。\n3. **是否突破极限？** 验证结果是否超出硬件物理极限（如网络带宽、内存吞吐），警惕缓存欺骗。\n4. **是否有错误？** 关注错误率，高错误率会扭曲性能数据，不可忽视。\n5. **结果是否可复现？** 多次运行对比，确保稳定性；可通过系统负载均值归零来减少干扰。\n6. **是否真实有意义？** 评估指标是否贴近实际应用场景，避免脱离现实的“极端测试”误导决策。\n7. **是否真执行了？** 警惕测试未真正发起（如防火墙拦截），客户端误判超时为延迟。\n\n**实用价值：**  \n该清单适用于产品选型、自研性能验证或评审他人基准报告，帮助识别虚假性能宣称。作者强调精准基准测试对技术投资至关重要，并将其纳入个人在线方法论库（[Performance Analysis Methodology](http://www.brendangregg.com/methodology.html)）供参考。\n\n**推荐人群：** 开发者、架构师、性能工程师、技术决策者。","published_at":"2018-06-30T00:00:00Z"}
{"domain":"brendangregg","path":"https://www.brendangregg.com//blog/2018-05-31/linux-tcpdrop.html","title":"Linux bcc/eBPF tcpdrop","summary":"该博客分享了作者在排查生产环境内核级TCP数据包丢失问题时，利用Linux 4.7新增的`tcp_drop()`函数（由Eric Dumazet引入）结合eBPF与bcc工具进行深入分析的经验。关键亮点包括：\n\n- **新工具tcpdrop**：基于bcc开发，可追踪TCP数据包被丢弃时的完整上下文，包括源/目的IP、端口、连接状态、TCP标志位及调用栈，帮助定位丢包原因。\n- **精准追踪**：相比过去通过`__kfree_skb()`追踪所有内存释放带来的噪声，`tcp_drop()`使仅关注异常丢包路径成为可能。\n- **深度洞察**：通过获取内核栈跟踪，能揭示丢包背后的代码逻辑（如`tcp_rcv_established`等函数），这是传统抓包工具（如tcpdump）无法获取的信息。\n- **eBPF实现创新**：首次在eBPF中直接读取TCP/IP头部（使用`skb_to_tcphdr()`和`skb_to_iphdr()`），实现对数据包方向与标志位的精确解析，并将信息传递至用户态处理。\n- **未来建议**：提议为`tcp_drop()`添加“丢包原因”参数或升级为tracepoint，以进一步提升可观测性。\n\n**总结**：`tcp_drop()`是网络调试的重大进步，配合eBPF实现了对隐藏于内核中的TCP丢包行为的可视化与诊断能力，显著提升生产系统排障效率。推荐给运维、SRE及网络开发者。","published_at":"2018-05-31T00:00:00Z"}
{"domain":"brendangregg","path":"https://www.brendangregg.com//blog/2018-05-19/sloth-cloud-instance.html","title":"Sloth Cloud Instance","summary":"**总结：**\n\n该博客记录了一次在EC2实例上发现的严重性能问题：CPU运行速度极慢，表现为`man ls`命令执行耗时超过3秒。通过`showboost`和`turbostat`工具检测，发现CPU实际频率仅约130-140 MHz，远低于其2.5 GHz的基础频率，相当于Pentium Pro时代的性能。\n\n关键发现：\n- 多个工具（`showboost`、`turbostat`）一致显示CPU频率异常低下。\n- `dmesg`无明显错误，但系统报告为Intel Xeon Platinum 8175M CPU。\n- `turbostat --debug` 显示处理器支持睿频（Turbo Boost），但所有功率限制（PKG/DRAM）均被禁用，且未启用动态调频（HWP）。\n- 基准测试（如`perl`循环、`cksum`、`man`）均显著变慢，确认非单一命令问题。\n\n结论：此问题极可能是由EC2底层硬件或BIOS配置导致，而非软件或系统设置问题，建议排查虚拟化层或联系云服务提供商。","published_at":"2018-05-19T00:00:00Z"}
{"domain":"brendangregg","path":"https://www.brendangregg.com//blog/2018-04-30/usenix-lisa-2018-cfp.html","title":"USENIX LISA 2018: CFP Now Open","summary":"**LISA'18 南纳什维尔会议邀请总结**\n\nUSENIX LISA 2018 将于2018年10月29日至31日在田纳西州纳什维尔的奥米尼酒店举行，这是LISA首次在中美地区举办，也是其首次扩展为3天会议。作为系统运维领域最具影响力的年度技术盛会，LISA以技术深度、行业中立性和专业交流著称，汇聚了来自华尔街银行、科技巨头及各行业的系统管理员、SRE、DevOps工程师、安全专家等。\n\n本届会议主题涵盖云原生、容器化、机器学习、自动化、可靠性工程、监控与性能优化等前沿议题。主办方Brendan Gregg与Rikki Endsley诚邀从业者提交演讲或教程提案（截止日期：5月24日），并鼓励分享真实运维经验、架构迁移故事与实战解决方案。\n\n作为持续32年的老牌技术会议，LISA已从早期的大型系统管理演变为覆盖现代复杂生产系统的综合性平台。参会不仅可获取最新技术知识，还能面对面交流、建立人脉，甚至成为技术分享者。\n\n欢迎访问[CFP页面](https://www.usenix.org/conference/lisa18/call-for-participation)提交提案，或通过邮件推荐讲者。  \n**适合人群**：系统工程师、SRE、DevOps、运维专家、技术管理者及对生产系统工程感兴趣的开发者。  \n\n\u003e 附注：支持开放技术社区，可加入USENIX会员，获取《;login:》杂志。","published_at":"2018-04-30T00:00:00Z"}
{"domain":"brendangregg","path":"https://www.brendangregg.com//blog/2018-03-22/tcp-tracepoints.html","title":"TCP Tracepoints","summary":"Linux 4.15 和 4.16 引入了多个新的 TCP 与 socket 级别的 tracepoint，显著提升了网络性能分析能力。核心亮点包括：\n\n- **新增 7 个稳定 tracepoint**：涵盖 `tcp:tcp_retransmit_skb`、`tcp:tcp_probe`、`sock:inet_sock_set_state` 等，可追踪重传、连接状态变化、RST 包发送/接收等关键事件。\n- **`sock:inet_sock_set_state` 为关键突破**：能准确捕获 TCP 状态转移（如 `CLOSE → SYN_SENT → ESTABLISHED`），替代旧版依赖内核实现细节的 kprobe，具备更高稳定性与可维护性。\n- **工具演进**：原基于 kprobe 的 `tcplife` 工具已升级为使用 tracepoint，新工具 `tcpstates` 可显示每阶段持续时间，提升可观测性。\n- **优势对比**：相比 libpcap 抓包，tracepoint 开销更低，且能访问内核内部状态，更适合生产环境深度诊断。\n\n作者强调，这些 tracepoint 是“稳定 API”，长期维护更可靠。未来可能扩展至 `tcp_send`/`receive` 和错误路径（如连接拒绝）的 tracepoint，但需谨慎控制性能开销。\n\n**推荐用途**：系统管理员、性能调优工程师、网络故障排查者，以及希望构建低延迟监控工具的开发者。建议先用 kprobe 验证需求，再推动 tracepoint 合并至内核。","published_at":"2018-03-22T00:00:00Z"}
{"domain":"brendangregg","path":"https://www.brendangregg.com//blog/2018-02-09/kpti-kaiser-meltdown-performance.html","title":"KPTI/KAISER Meltdown Initial Performance Regressions","summary":"**博客摘要：Meltdown/Spectre 安全补丁对性能的影响及优化策略**\n\n该博客深入分析了为应对 Meltdown 漏洞而引入的 Linux 内核页表隔离（KPTI）补丁所带来的性能开销，并提供实用的调优建议。\n\n**核心观点：**  \nKPTI 补丁虽有效缓解了安全风险，但可能导致显著性能下降，范围从 0.1% 到超过 800%，具体取决于工作负载特征。\n\n**关键影响因素：**\n1. **系统调用频率**：高系统调用率（如 \u003e50k/秒/核）导致性能损失上升，每增加一倍调用率，损耗约 2%。\n2. **上下文切换与页错误率**：与系统调用类似，高频切换和页错误会加剧开销。\n3. **工作集大小（热数据）**：超过 10MB 的工作集会导致额外性能损失（最高达 7%），主要源于 TLB 刷新。\n4. **缓存访问模式**：特定内存访问模式可能使工作集更快脱离缓存，带来额外 1%~10% 的损耗。\n\n**性能优化方案：**\n- ✅ 使用 **Linux 4.14+** 并启用 **PCID**（支持可大幅减少 TLB 刷新开销）。\n- ✅ 启用 **大页（Huge Pages）**，可将性能损失转为收益（尤其在大工作集场景下）。\n- ✅ 降低系统调用频率：通过 `perf-tools`、`bcc/eBPF` 等工具识别高频系统调用并优化代码逻辑。\n\n**实测验证：**  \n真实应用（如 MySQL OLTP）测试结果与模型预测高度一致，误差通常在 ±1% 以内。极端案例中因高并发引发的超大开销也得到解释。\n\n**结论：**  \n对于大多数云服务（如 Netflix），预期性能损失在 0.1%~6% 之间，通过上述调优手段可控制在 2% 以下。此外，还需注意其他三类潜在开销：微码更新、云平台虚拟化层改动、编译器修复（retpoline）。\n\n\u003e **推荐读者**：系统工程师、运维人员、云平台开发者、性能调优专家。  \n\u003e **行动建议**：评估自身工作负载的系统调用率与工作集大小，优先升级内核、启用 PCID 与大页。","published_at":"2018-02-09T00:00:00Z"}
{"domain":"brendangregg","path":"https://www.brendangregg.com//blog/2018-01-17/measure-working-set-size.html","title":"How To Measure the Working Set Size on Linux","summary":"**摘要：**\n\n本文介绍了**工作集大小（Working Set Size, WSS）** 的概念及其在性能分析与容量规划中的重要性。WSS 指应用程序在短时间内实际频繁访问的内存，远小于其总驻留内存（RSS），是衡量缓存效率和内存使用真实需求的关键指标。\n\n作者开发了两个基于 Linux 内核特性的工具来估算 WSS：\n1. **`wss.pl`（方法一：引用页标志）**  \n   利用内核 2.6.22 引入的 `clear_refs` 和 `smaps` 接口，通过清空并统计页面“被访问”标志来测量短时间内的活跃内存。适用于分析 CPU 缓存命中率（如 0.1 秒内访问量）。但存在风险：会干扰内核回收逻辑，对大进程（\u003e100GB）可能引入显著延迟甚至潜在崩溃风险，需谨慎使用。\n\n2. **`wss-v1` / `wss-v2`（方法二：空闲页标志，Linux 4.3+）**  \n   基于新引入的 `idle_page_tracking` 功能，无需修改页面状态，更安全。通过标记进程页为“空闲”，等待访问后统计未被访问的页数，从而推断工作集。`wss-v2` 优化了性能，避免大量系统调用，但仍存在测量时间膨胀问题。\n\n此外，作者提出**WSS 分布图（Profile Charts）**，通过多尺度采样（如 0.001~32 秒）绘制工作集随时间增长曲线，用于区分短期缓存行为与长期内存驻留特性。图表显示，短时数据反映缓存能力，长时数据揭示真实内存占用模式。\n\n**核心价值：**\n- 提供了首个可落地的、基于内核机制的 WSS 测量工具链。\n- 强调了传统工具（如 top）仅显示 RSS/PSS，无法反映真实“热数据”规模。\n- 推荐结合多种方法进行综合评估，并建议未来内核接口改进（如 `/proc/PID/clear_idle`）以提升准确性与效率。\n\n**适用人群：** 系统性能工程师、数据库/高负载服务运维人员、系统架构师，用于优化内存使用、预测扩容需求、诊断性能瓶颈。","published_at":"2018-01-17T00:00:00Z"}
{"domain":"brendangregg","path":"https://www.brendangregg.com//blog/2017-12-31/reinvent-netflix-ec2-tuning.html","title":"AWS re:Invent 2017: How Netflix Tunes EC2","summary":"本文是Brendan Gregg在2017年AWS re:Invent大会上演讲的总结，主题为《Netflix如何优化EC2实例性能》。该演讲基于其2014年的旧版内容更新，因热度极高，现场三间溢出会议室同步直播仍人满为患。\n\n核心内容包括：\n- **团队介绍**：Netflix性能与操作系统团队负责基础AMI、内核调优、性能工具（如Vector）及自服务工具，并支持各开发团队进行性能优化。\n- **关键内核调优参数**（适用于2017年Ubuntu Xenial EC2实例）：\n  - **CPU**：使用`schedtool -B PID`提升调度效率。\n  - **虚拟内存**：`vm.swappiness=0`减少交换。\n  - **大页内存**：启用`madvise`模式以优化透明大页。\n  - **NUMA**：关闭`numa_balancing`避免干扰。\n  - **文件系统**：提高脏页比例与刷新延迟，挂载时禁用访问时间更新（`noatime`）。\n  - **存储I/O**：设置队列调度器为`noop`，增加请求队列深度和预读大小。\n  - **网络**：大幅提高连接数、缓冲区大小与端口范围，启用`tcp_tw_reuse`等优化。\n  - **虚拟化层（Xen）**：切换时钟源为`tsc`以提升精度。\n\n文中强调这些调优配置自2014年以来变化不大，但重点在于**实战经验**与**可复用的性能工程方法论**。\n\n此外，作者特别提及新推出的**Nitro虚拟化架构**（后正式命名），以及裸金属实例的发布，标志着AWS EC2性能能力的重大跃升。\n\n最后推荐了多位同事在re:Invent上的精彩演讲，涵盖自动扩缩容、混沌工程、网络安全、实时监控、负载均衡等多个领域，展现了Netflix技术团队的广泛影响力。\n\n\u003e ✅ **适用人群**：云原生开发者、系统工程师、DevOps、性能优化人员  \n\u003e 🔍 **核心价值**：提供经大规模生产环境验证的EC2性能调优实践指南，兼具技术深度与可操作性。","published_at":"2017-12-31T00:00:00Z"}
{"domain":"brendangregg","path":"https://www.brendangregg.com//blog/2017-11-29/aws-ec2-virtualization-2017.html","title":"AWS EC2 Virtualization 2017: Introducing Nitro","summary":"该博客详细回顾了AWS EC2实例虚拟化技术的演进历程，重点展示硬件辅助虚拟化如何显著提升云性能。核心观点如下：\n\n**主论点**：通过逐步引入VT-x、SR-IOV、NVMe、APICv等硬件虚拟化技术，AWS EC2已实现接近裸金属的性能，尤其在CPU、内存、网络和存储层面。\n\n**关键进展**：\n1. **早期阶段**：完全软件模拟（慢速）→ 与Xen结合的半虚拟化（PV）→ 硬件虚拟化（HVM）。\n2. **性能突破**：2013年起支持SR-IOV增强网络（达10–25 Gbps）；2017年i3实例实现300万存储IOPS。\n3. **Nitro hypervisor**（2017）：基于KVM但轻量化，移除传统中间层（如dom0），实现直通式I/O访问，中断处理优化（使用posted interrupts + APICv），性能近乎裸金属（\u003c1%开销）。\n4. **裸金属实例**：提供零虚拟化开销，适合极致性能需求，且可运行任意虚拟化方案。\n\n**实用价值**：\n- 多数工作负载应优先选择**Nitro实例**（如c5/m5），兼顾性能与易用性。\n- 高性能分析能力增强：支持数百个性能监控计数器（PMCs），便于深度调优。\n- 未来趋势：几乎所有新实例将采用Nitro架构，仅裸金属实例例外。\n\n**适用人群**：云架构师、性能工程师、运维人员及关注云基础设施优化的技术决策者。","published_at":"2017-11-29T00:00:00Z"}
{"domain":"brendangregg","path":"https://www.brendangregg.com//blog/2017-11-13/brilliant-jerks.html","title":"Brilliant Jerks in Engineering","summary":"本文探讨了“天才型混蛋”（brilliant jerks）在科技行业中的危害，强调公司不应容忍这类人才。作者通过虚构的两位工程师——**自利型混蛋鲍勃**（Bob）和**无私型混蛋爱丽丝**（Alice）——对比说明：虽然两者都才华横溢，但只有鲍勃会系统性地破坏团队、打压同事、制造敌意。\n\n- **爱丽丝**虽缺乏同理心、态度强硬，但为公司利益着想，行为可被接受或引导改进。\n- **鲍勃**则自私自利、操控他人、贬低同事、滥用权力，甚至导致员工离职、心理创伤与法律风险，严重损害组织健康。\n\n文章指出，**真正的“天才混蛋”危害远超其技术贡献**，其负面影响包括：\n- 降低团队效率与创新力；\n- 增加员工流失与招聘难度；\n- 损害客户与投资者信心；\n- 激发模仿效应，形成恶性文化。\n\n作者支持如Netflix所倡导的“**无天才混蛋政策**”，即无论多优秀，若品行恶劣，就不应被录用或留任。关键在于：\n- 管理层必须明确拒绝容忍此类行为；\n- 建立安全反馈机制（如定期一对一沟通）；\n- 公开演讲等资源应公平分配，避免让混蛋垄断影响力；\n- 个人也需自省：是否只关心对错，却忽视人际关系？\n\n最后提醒：**真正的“天才”不会以伤害他人为代价；而一个“混蛋”，即使再聪明，也是组织的毒瘤**。  \n推荐企业采纳“无混蛋规则”，保护团队氛围与长期成功。","published_at":"2017-11-13T00:00:00Z"}
{"domain":"brendangregg","path":"https://www.brendangregg.com//blog/2017-10-28/bsd-performance-analysis-methodologies.html","title":"EuroBSDcon: System Performance Analysis Methodologies","summary":"本文是Brendan Gregg在2017年EuroBSDcon大会上关于系统性能分析方法的演讲总结。他以FreeBSD 11.1为分析目标，分享了一套可复用的性能诊断方法论，并将其从其他系统移植至BSD环境，仅需数天时间，体现了该方法的高效性与通用性。\n\n核心内容包括：\n- **FreeBSD性能检查清单**：列出10个关键命令，涵盖负载、内核错误、CPU/内存/I/O/网络使用及进程状态，帮助快速定位性能瓶颈。\n- **新工具 tstates.d**：基于DTrace开发，用于分析线程在不同调度状态（如运行、等待CPU、睡眠、锁等待等）的时间分布，特别新增“不可中断睡眠（USL）”以精准识别磁盘I/O延迟。\n- 工具输出示例展示了典型进程（如`cksum`、`idle`、`sshd`）的状态耗时，便于诊断阻塞点。\n\n作者强调，这些方法不仅适用于FreeBSD，更可在整个职业生涯中反复应用。演讲视频和幻灯片已公开，适合系统管理员、开发者及性能调优人员参考。","published_at":"2017-10-28T00:00:00Z"}
{"domain":"brendangregg","path":"https://www.brendangregg.com//blog/2017-09-05/solaris-to-linux-2017.html","title":"Solaris to Linux Migration 2017","summary":"本文是一位资深系统工程师对从 Solaris/illumos 迁移到 Linux 的全面指南，基于其多年跨平台经验。核心观点如下：\n\n**主论点**：尽管 Solaris 团队大规模离职令人惋惜，但如今 Linux 已在功能、可观测性、容器化等方面全面追赶甚至超越，迁移已变得切实可行。\n\n**关键发现与建议**：\n1. **ZFS**：通过 OpenZFS 项目在 Linux 上稳定运行，性能接近原生；同时 btrfs 作为内核原生文件系统发展迅速，正与 ZFS 争夺生产环境地位。\n2. **可观测性**：传统 DTrace 功能已由 **bpftrace**（轻量脚本）和 **BCC**（复杂工具）取代，配合 ftrace、perf 等内建工具，构成强大的性能分析体系。\n3. **容器**：Linux 容器依赖 cgroups + namespaces，主流使用 Docker/Kubernetes，但缺乏“容器 ID”是痛点，需通过 /proc/PID/ns 等方式间接识别。\n4. **虚拟化**：KVM 成为主流（优于 Xen），支持 SR-IOV/NVMe 可达近裸金属性能。\n5. **服务管理**：Systemd 是 Linux 版的 SMF，虽有争议但终将普及。\n6. **性能与安全**：Linux 通常启动更快，应用优化更优；安全机制（SELinux/AppArmor/seccomp）成熟，结合云环境快速迭代提升可靠性。\n7. **调试与崩溃处理**：`gdb`/`lldb`/`drgn` 等替代 `mdb`；`kdump` + `oops` 消息可高效定位问题，社区响应极快。\n8. **生态与职业**：开源社区庞大，但文档稀少；就业市场向云（如 AWS）和分布式系统倾斜，传统内核岗位减少。\n\n**实用建议**：\n- 推荐从 **Ubuntu LTS** 或 **RHEL/CentOS** 入手。\n- 优先学习 **eBPF/BCC/bpftrace** 技术栈。\n- 积极参与 **lkml** 和 **MAINTAINERS** 文件维护的子系统，贡献代码或测试。\n- 利用 [rosetta-stone](https://certsimple.com/rosetta-stone) 快速对照命令差异。\n\n**总结**：迁移虽有挑战（如文档缺失、术语差异），但现代 Linux 在技术上已完全具备替代 Solaris 的能力。作者鼓励工程师拥抱变化，积极参与开源，让优秀技术精神延续。","published_at":"2017-09-05T00:00:00Z"}
{"domain":"brendangregg","path":"https://www.brendangregg.com//blog/2017-08-24/total-solar-eclipse-2017.html","title":"Total Solar Eclipse 2017","summary":"作者在2017年8月21日日全食期间，将摄像机对准地景而非天空，试图捕捉月球阴影掠过地面的景象。拍摄地点位于俄勒冈州马德拉以北、正对全食带中心线。视频显示，日偏食阶段光线逐渐减弱，但视觉变化不明显；直到接近全食时，环境突然变暗，宛如黄昏四起，山影（如杰斐逊山）被阴影吞没，天地间呈现出类似日落的昏暗氛围。\n\n视频虽真实还原了视觉感受，但音频因自动增益调节而失真——实际现场异常安静，却录到远处引擎声渐强。作者推测，相机的自动曝光与变焦设置使其画面亮度变化与人眼同步，从而更贴近真实观感。\n\n全食瞬间（+0秒）后，作者用双筒望远镜短暂观测太阳，发现三处日珥清晰呈现，色彩为罕见的深紫，细节丰富，远超多数摄影记录。他指出，当前主流照片和视频普遍因过度曝光而使日珥模糊或过饱和，仅呈白色/紫色斑块，无法体现人眼所见的动态范围与真实质感——这可能源于摄影师为拍出日冕而牺牲日珥细节。\n\n总结：  \n- **核心观点**：日全食期间地景变化极具戏剧性，且人眼感知远优于现有影像记录。  \n- **关键发现**：日食前后光线变化平缓，全食时环境似“全方位日落”；日珥色彩与细节极富表现力，但常被摄影设备忽略或失真。  \n- **实用启示**：未来拍摄应优化设备稳定性与曝光设置，兼顾日珥与日冕，以更真实还原人类视觉体验。  \n- **推荐人群**：天文爱好者、摄影创作者、自然现象观察者。","published_at":"2017-08-24T00:00:00Z"}
{"domain":"brendangregg","path":"https://www.brendangregg.com//blog/2017-08-08/linux-load-averages.html","title":"Linux Load Averages: Solving the Mystery","summary":"Linux 系统负载平均值（load averages）并非仅反映 CPU 使用情况，而是衡量系统整体资源需求的“系统负载平均值”，包含可运行任务和处于不可中断睡眠状态（TASK_UNINTERRUPTIBLE）的任务。这一设计源于1993年的一次关键补丁，由 Matthias Urlichs 提出，旨在解决“慢速磁盘导致负载下降”这一反直觉现象——因为旧版仅统计可运行进程，未计入因磁盘 I/O 阻塞而无法响应的进程。\n\n### 核心要点：\n- **历史演变**：早期如 TENEX 系统中，负载平均值仅表示 CPU 需求；Linux 在 0.99.14 版本后引入不可中断任务，使负载反映更全面的系统压力。\n- **计算方式**：三个数值（1/5/15分钟）是指数加权移动平均，基于每5秒采样，而非真实时间窗口。\n- **不可中断状态的意义**：包括磁盘 I/O、锁等待等阻塞行为，体现系统实际工作负荷，即使无 CPU 活动也计入负载。\n- **现代挑战**：如今有近400个代码路径会设置 `TASK_UNINTERRUPTIBLE`，部分可能应被排除（如锁竞争），但总体仍合理——这些线程仍在“工作”，非完全空闲。\n\n### 实用建议：\n- **解读负载值**：不能简单与 CPU 核数比较。若负载从 20 升至 40，说明压力显著上升，需结合其他指标分析。\n- **分解负载**：可通过 eBPF 工具（如 `offcputime` + 火焰图）追踪不可中断时间来源，识别瓶颈（如 systemd-journal、页错误、锁争用）。\n- **替代指标**：推荐使用更精准的指标：\n  - **CPU**：`mpstat`、`runqlat`（调度延迟）、`pidstat`\n  - **I/O**：`iostat`、`blktrace`\n  - **锁/阻塞**：`offcputime` 火焰图分析\n\n### 总结：\n尽管负载平均值常被误解，但它在云原生自动伸缩中仍有价值——尤其用于相对趋势判断。其真正意义在于“系统是否繁忙”，而非单纯“CPU 是否忙碌”。理解其背后逻辑，配合现代可观测性工具，才能真正发挥其作用。","published_at":"2017-08-08T00:00:00Z"}
{"domain":"brendangregg","path":"https://www.brendangregg.com//blog/2017-07-30/coloring-flamegraphs-code-type.html","title":"Coloring Flame Graphs: Code Hues","summary":"本文介绍了作者对火焰图（Flame Graph）代码着色逻辑的改进。最初，代码类型通过正则表达式简单判断：含 `::` 为 C++（黄色），含 `/` 为 Java（绿色），其余为系统代码（红色）。但该方法存在误判问题，如部分 Java 符号使用 `.` 分隔或无包名时被错误归类。\n\n为提升准确性，作者利用 `perf script` 输出中括号内的符号信息（如 `/tmp/perf-PID.map` 表示 JIT 编译代码），在 `stackcollapse-perf.pl` 中引入 `--all` 选项添加注解标签：\n- `_k`：内核代码\n- `_j`：JIT 代码（如 Java、Node.js）\n- `_i`：内联函数\n- `_w`：唤醒栈（用于 offwake/chain 图）\n\n基于这些注解，新的“java”调色板实现更精准的颜色区分：\n- 绿色：JIT 代码（Java/Node.js）\n- 青色：内联函数\n- 黄色：C++\n- 橙色：内核\n- 红色：用户态原生代码\n\n建议自动化火焰图生成流程中加入 `--all` 选项，以获得更准确的着色。对于自研工具，也可借鉴此机制，按代码类型动态分配颜色，便于快速识别性能瓶颈来源。","published_at":"2017-07-30T00:00:00Z"}
{"domain":"brendangregg","path":"https://www.brendangregg.com//blog/2017-06-30/package-flame-graph.html","title":"Java Package Flame Graph","summary":"**总结：**\n\n本文介绍了**Java包火焰图**（Java package flame graph）这一可视化CPU负载的新方法，作为传统栈跟踪火焰图的补充。与基于函数调用层级的普通火焰图不同，包火焰图按Java包名层级展示CPU占用时间，忽略函数调用关系，能更直观地看出某一包（如`java/util`）直接消耗的CPU时间。\n\n- **优势**：可快速识别特定包的直接CPU开销（如`java/util`占3.91%），无需手动排除子调用；在栈深度超限（如超过127层）时仍可用，且性能开销更低。\n- **使用方式**：通过`perf record`不启用`-g`选项收集样本，结合`pkgsplit-perf.pl`提取包名，再用`flamegraph.pl`生成图表。\n- **适用场景**：适合分析代码归属、定位高开销包，尤其适用于复杂调用栈或堆栈溢出问题。\n- **结论**：包火焰图并非替代品，而是提供另一种视角，与传统火焰图配合使用，提升性能分析效率。","published_at":"2017-06-30T00:00:00Z"}
{"domain":"brendangregg","path":"https://www.brendangregg.com//blog/2017-05-16/working-at-netflix-2017.html","title":"Working at Netflix 2017","summary":"**总结：**\n\n作者在Netflix工作三年，分享了其工作体验、技术贡献与公司文化。核心要点如下：\n\n- **规模增长**：Netflix从4000万用户扩展至1亿订阅者，遍布190国，但未经历重大技术危机，依靠EC2云平台和微服务架构实现持续平稳扩展。\n  \n- **日常工作**：以50/50比例兼顾**主动项目**（如开发性能工具、协作新系统）与**被动响应**（排查JVM崩溃、容器性能问题、延迟异常等），同时参与定期会议与跨团队协作。\n\n- **文化特色**：“自由与责任”为核心，强调结果导向、高绩效与透明决策，文化文档被实际用于日常管理，减少官僚主义，鼓励工程师专注创造价值。\n\n- **使命清晰**：致力于通过优质产品改善全球娱乐消费体验，坚持诚信经营，拒绝数据滥用或用户陷阱。\n\n- **技术贡献**：\n  - 推动Linux性能分析工具发展，主导开发`perf-tools`与`bcc/eBPF`系列工具；\n  - 实现EC2上对硬件性能计数器（PMCs）的支持；\n  - 改进ftrace、gdb调试、内核调优与监控机制；\n  - 持续推动eBPF在生产环境的应用。\n\n- **团队与成长**：团队扩大，新任经理为前同事；个人从SRE轮值中退出，回归专注性能工程。\n\n- **结语**：仍热爱在Netflix的工作，认为这里不仅是技术高地，更是理想职场的典范。建议求职者通过官网提交简历，而非直接联系作者。\n\n\u003e **适合人群**：技术从业者、关注云计算/性能工程/高绩效文化的读者。","published_at":"2017-05-16T00:00:00Z"}
{"domain":"brendangregg","path":"https://www.brendangregg.com//blog/2017-05-15/container-performance-analysis-dockercon-2017.html","title":"Container Performance Analysis at DockerCon 2017","summary":"本文是作者在2017年DockerCon上的演讲总结，聚焦于**Linux容器性能分析的三大瓶颈识别方法**：\n\n1. **主机与容器之间**：使用系统级指标（如`top`、`htop`、`iostat`、`sar`）对比资源使用情况。  \n2. **容器内应用代码**：通过CPU火焰图（flame graphs）定位热点函数和性能瓶颈。  \n3. **内核层级**：利用追踪工具（如`perf`、`bpftrace`相关工具`iosnoop`、`runqlat`、`funccount`）深入分析系统调用和内核行为。\n\n演讲强调**掌握分析框架比死记工具更重要**，并介绍了从基础到高级的多种工具链，包括容器感知工具（如`docker stats`、`systemd-cgtop`、`nsenter`）及Netflix自研工具（如Vector、Intel snap）。\n\n核心创新点是提出**反向诊断法（Reverse Diagnosis）**：先列出所有可能的结果，再反推所需指标来快速锁定问题。以CPU为例，优先检查`/sys/fs/cgroup/cpu.stat`中的`throttled_time`，判断是否受硬性配额限制，从而高效缩小排查范围。\n\n背景为Netflix Titus容器平台，其演进经验也作为实践案例。演讲获得“最佳讲师”奖项，内容已公开在视频与幻灯片中，适合运维、开发者和性能工程师参考。","published_at":"2017-05-15T00:00:00Z"}
{"domain":"brendangregg","path":"https://www.brendangregg.com//blog/2017-05-09/cpu-utilization-is-wrong.html","title":"CPU Utilization is Wrong","summary":"**总结：**\n\n传统“CPU利用率”（%CPU）指标具有严重误导性，它衡量的并非处理器实际运行任务的繁忙程度，而是“非空闲时间”——即CPU未执行空闲线程的时间。在现代系统中，由于CPU速度远超内存访问速度，大多数高%CPU值实际上源于CPU等待内存I/O的“阻塞周期”（stalled cycles），而非真正计算密集。\n\n关键洞察：\n- **真实瓶颈是内存延迟**，而非CPU性能。\n- 通过性能监控计数器（PMCs）可获取**每周期指令数（IPC）**：若IPC \u003c 1.0，说明系统内存受限，应优化内存访问、缓存和局部性；若IPC \u003e 1.0，说明代码本身是瓶颈，应减少冗余计算。\n- 现代多核、超线程架构加剧了此问题，因阻塞周期可能被其他线程利用，导致%CPU虚高。\n\n建议行动：\n- 使用 `perf stat` 或 `tiptop` 等工具查看IPC，识别真实瓶颈。\n- 监控工具应同时展示IPC或拆分%CPU为“指令执行”与“阻塞”占比。\n- 云环境（如AWS EC2专用主机）已支持PMCs，可有效诊断性能问题。\n\n结论：%CPU应重命名为%CYC（周期使用率），并辅以IPC等更精确指标，才能准确反映系统真实负载。否则，误判将导致错误的调优方向，尤其在自动伸缩的云环境中风险更高。","published_at":"2017-05-09T00:00:00Z"}
{"domain":"brendangregg","path":"https://www.brendangregg.com//blog/2017-05-04/the-pmcs-of-ec2.html","title":"The PMCs of EC2: Measuring IPC","summary":"**摘要：**\n\n本文介绍了AWS EC2专用主机（如m4.16xlarge、i3.16xlarge）上公开的性能监控计数器（PMCs），这些硬件级性能指标可帮助深入分析现代系统的核心瓶颈——内存子系统（如缓存、内存总线、互连）。作者强调“内存即新磁盘”，随着存储速度提升，内存成为主要性能瓶颈。\n\n文中重点展示了7个**架构级PMCs**（如指令退休、未停顿周期、LLC引用与缺失等），它们是分析CPU行为的黄金标准。通过`perf`工具测量**每周期指令数（IPC）**，可判断应用是否为“内存绑定”（IPC \u003c 1）或“指令绑定”（IPC \u003e 1），从而指导优化方向。\n\n作者以真实案例“RxNetty vs Tomcat”说明，借助PMCs成功解释了46%的性能差异，揭示了事件驱动模型在高负载下更高效的根本原因。此外，文章还解释了云环境中如何安全地访问PMCs——通过虚拟化层（Xen）的白名单机制（如`vpmu=arch`），仅开放关键计数器，兼顾性能分析与安全性。\n\n**核心价值：**\n- **可用性**：现可在EC2专用主机上使用关键PMCs。\n- **实用性**：通过IPC快速定位性能瓶颈，指导内存或代码优化。\n- **战略意义**：能观测和调优的云才是真正的高性能云。\n\n\u003e “你无法分析的云，就是更慢的云。”","published_at":"2017-05-04T00:00:00Z"}
{"domain":"brendangregg","path":"https://www.brendangregg.com//blog/2017-04-29/usenix-lisa-2016-bcc-bpf-tools.html","title":"USENIX/LISA 2016 Linux bcc/BPF Tools","summary":"**总结：**\n\n本文介绍了作者在2016年USENIX LISA大会上关于Linux bcc/BPF性能分析工具的演讲，重点展示BPF（Berkeley Packet Filter）如何革新内核级追踪与性能调优。随着内核从ftrace、perf_events发展到现代BPF，系统可观测性大幅提升。\n\n- **核心价值**：BPF不再局限于网络包过滤，已演变为强大的动态追踪机制，支持实时性能分析、故障排查和安全监控。\n- **关键工具**：通过`bcc`工具集（如`execsnoop`、`biolatency`、`tcpconnect`等），可轻松追踪进程创建、磁盘I/O延迟、网络连接等行为，且多数工具即开即用。\n- **使用门槛**：需4.4及以上内核，推荐4.9+；可通过APT或Snap安装`bcc-tools`，并利用`/usr/share/bcc/tools`目录下的丰富工具快速上手。\n- **实战示例**：`biolatency`可生成磁盘I/O延迟分布直方图，帮助识别慢速存储瓶颈；`execsnoop`实时显示新进程启动情况。\n- **未来方向**：作者认为当前阶段已超越基础追踪，未来可能探索更高层的BPF前端（如ply）、可视化界面（如Netflix Vector）或新应用场景。\n\n**适用人群**：系统管理员、性能工程师、内核开发者及关注Linux可观测性的技术人员。  \n**推荐理由**：为深入理解现代Linux性能分析提供了实用指南与技术前瞻。","published_at":"2017-04-29T00:00:00Z"}
{"domain":"brendangregg","path":"https://www.brendangregg.com//blog/2017-04-23/usenix-lisa-2013-flame-graphs.html","title":"USENIX/LISA 2013 Blazing Performance with Flame Graphs","summary":"本文回顾了2013年在USENIX LISA大会上关于**火焰图（Flame Graphs）**的演讲，这是一种用于可视化性能剖析堆栈轨迹的工具，现已被Netflix、Facebook、LinkedIn等公司广泛用于识别消耗CPU的代码路径。演讲深入讲解了火焰图的起源、解读方法，并展示了多种可可视化的性能分析事件类型。\n\n尽管当时尚未支持后续添加的功能（如缩放、搜索、混合颜色高亮和差异火焰图），但演讲中已使用DTrace实现火焰图；如今已在Linux上通过`perf`和`bcc/BPF`实现更高级功能，包括无需技巧的**离CPU火焰图**（off-CPU flame graphs），得益于BPF在内核4.6中对堆栈跟踪的支持。\n\n该演讲原计划45分钟，因突发情况被迫延长至90分钟——演讲者凌晨5点仍在准备，次日早上8点被通知临时顶替患病的主讲人。这一经历也体现了其与USENIX团队的合作与贡献。\n\n作者还提及后续在ACM Queue和CACM发表的相关文章，并推荐查阅其火焰图页面的[更新](/flamegraphs.html#Updates)部分以获取最新进展。\n\n**核心要点：**\n- 火焰图是性能调优的重要工具，广泛应用于大型科技公司。\n- 技术演进：从DTrace到perf、bcc/BPF，支持更多场景（如离CPU分析）。\n- 演讲背景充满戏剧性，反映技术传播中的偶然与坚持。\n- 适合系统工程师、性能优化专家及对底层调试感兴趣的开发者阅读。","published_at":"2017-04-23T00:00:00Z"}
{"domain":"brendangregg","path":"https://www.brendangregg.com//blog/2017-03-16/perf-sched.html","title":"perf sched for Linux CPU scheduler analysis","summary":"Linux 4.10 为 `perf` 引入了新的调度器分析工具 `perf sched timehist`，可详细追踪任务的等待时间（wait time）、调度延迟（sch delay）和运行时间（run time），帮助诊断性能瓶颈。\n\n**核心功能：**\n- **`perf sched timehist`**：以时间轴形式展示每个任务的调度延迟，区分“等待唤醒”和“被唤醒后到执行”的延迟，是分析调度问题的关键。\n- **支持可视化选项**：使用 `-MVw` 可显示 CPU 状态（`s` 表示上下文切换，`m` 表示迁移），并标注唤醒事件，便于理解调度流程。\n- **高精度数据**：记录从唤醒到实际运行的时间差，例如 `sleep 1` 的等待时间为 1000.104 毫秒，调度延迟仅 0.006 毫秒，说明其主要耗时在睡眠而非调度。\n\n**其他 `perf sched` 子命令：**\n- `latency`：按任务汇总平均与最大调度延迟。\n- `map`：以文本方式显示各 CPU 的上下文切换轨迹，类似时间线视图。\n- `script`：输出原始调度事件，适合深入排查。\n\n**适用场景：**\n- 云服务器故障前紧急诊断（如实例即将终止）。\n- 分析多核系统中任务调度不均、延迟突增等问题。\n- 结合 eBPF 工具（如 runqlat）进行低开销监控，或用 `perf sched` 采集完整事件用于事后分析。\n\n**总结：**  \n`perf sched timehist` 是 Linux 调度性能分析的强大利器，尤其适合需要精确识别调度延迟来源的场景。尽管全量事件记录有较高开销，但在关键问题排查中极具价值。推荐给系统调优、内核开发者及运维工程师。","published_at":"2017-03-16T00:00:00Z"}
{"domain":"brendangregg","path":"https://www.brendangregg.com//blog/2017-02-06/flamegraphs-vs-treemaps-vs-sunburst.html","title":"Flame Graphs vs Tree Maps vs Sunburst","summary":"本文对比了多种文件系统空间使用情况的可视化工具，以 Linux 4.9-rc5 源码目录为例，分析其优劣：\n\n- **火焰图（Flame Graph）**：最直观展示层级结构与占比，通过矩形长度快速识别大目录（如 `drivers` 超过 50%），适合高阶概览，便于打印或嵌入演示文稿。\n\n- **树状图（Treemap）**：用面积表示大小，能清晰显示少数大文件（如 `drivers/gpu/drm/amd`），但难以准确比较尺寸，且标签缺失影响信息获取。\n\n- **太阳图（Sunburst）**：视觉美观，但存在认知偏差——角度小的扇区可能实际更大，需依赖角度判断，不易读取真实比例。\n\n- **ncdu**：命令行工具，逐层显示，带进度条，交互性强，适合快速排查，但仅限当前层级。\n\n- **du**：最简洁高效，适合初筛，需手动排序阅读，无图形化。\n\n**结论**：理想方案应提供多种视图，**默认推荐火焰图**，因其在信息密度与可读性间平衡最佳。建议结合多工具使用，根据场景选择。  \n推荐阅读：Brendan Gregg 的《The Flame Graph》及 Heer 等人的《A Tour through the Visualization Zoo》。","published_at":"2017-02-06T00:00:00Z"}
{"domain":"brendangregg","path":"https://www.brendangregg.com//blog/2017-02-05/file-system-flame-graph.html","title":"Where has my disk space gone? Flame graphs for file systems","summary":"该博客介绍了一种利用火焰图（Flame Graph）可视化文件系统空间占用的开源工具，帮助快速定位磁盘空间被大量占用的目录。作者因笔记本磁盘空间异常耗尽而开发此工具，通过将目录层级结构以火焰图形式展示，宽度代表文件大小，直观呈现空间分布。\n\n主要亮点：\n- 使用 `files.pl` 收集目录大小数据，结合 `flamegraph.pl` 生成可交互的 SVG 火焰图。\n- 支持命令行操作，可通过 Git 克隆或直接下载两个 Perl 脚本运行。\n- 示例展示了 Linux 4.9-rc5 源码树的空间分布，支持点击缩放和 Ctrl+F 搜索。\n- 实际应用中成功排查了朋友电脑中未知备份程序占用空间的问题。\n\n使用方法简洁：\n```bash\n./files.pl /path/to/dir | ./flamegraph.pl --hash --countname=bytes \u003e out.svg\n```\n\n可自定义参数如标题、宽度、颜色主题、最小宽度等，提升可视化效果。推荐用于系统管理员、开发者排查存储问题，尤其适合需要快速掌握大目录空间分布的场景。  \n附：对比火焰图、树状图与太阳图的后续文章已发布。","published_at":"2017-02-05T00:00:00Z"}
{"domain":"brendangregg","path":"https://www.brendangregg.com//blog/2017-01-31/golang-bcc-bpf-function-tracing.html","title":"Golang bcc/BPF Function Tracing","summary":"本文介紹如何使用 Linux 4.x 增強版 BPF（eBPF）對 Go 程序進行動態追蹤，以實現性能分析與除錯。作者通過 `bcc` 工具（如 `funccount` 與 `trace`）演示了在不修改程式碼或重啟的情況下，即時監控 Go 函數的執行。\n\n**核心要點：**\n- **gccgo 編譯**：產生動態連結二進位檔，支援直接用 BPF 追蹤 `fmt.*` 等函數，且可獲取參數與呼叫次數。\n- **Go gc 編譯**：產生靜態二進位檔，雖能追蹤函數，但因未遵循標準 x86_64 ABI（參數存於堆疊而非寄存器），導致 `trace` 工具無法正確讀取參數。\n- **解決方案**：作者透過修改 `bcc trace` 工具，新增 `go1`、`go2` 等自定義別名來讀取堆疊上的參數，證明可行，但仍需正式整合。\n- **挑戰**：\n  - 接口（interface）類型參數難以解析。\n  - 多返回值、跨協程（goroutine）的延遲追蹤（`funclatency`）會因線程切換而失真。\n  - 需開發專門工具如 `gofunclatency`，利用 Go ID（GOID）而非 OS TID 進行精確追蹤。\n\n**實用價值：**\n- 可在生產環境中無侵入式追蹤問題。\n- 比傳統方法（如 `gdb`、`go trace`）更靈活，適用於高頻率或複雜場景。\n\n**未來方向：**\n- 改進 `bcc` 對 Go gc 編譯程式的支援（參數、接口、多返回值）。\n- 整合內核與使用者空間追蹤。\n- 加強堆疊追蹤功能（已由 Go 1.7 支援）。\n\n**適合讀者：**  \n系統工程師、Go 性能優化專家、Linux 內核與 BPF 技術愛好者。","published_at":"2017-01-31T00:00:00Z"}
{"domain":"brendangregg","path":"https://www.brendangregg.com//blog/2016-12-27/linux-tracing-in-15-minutes.html","title":"Give me 15 minutes and I'll change your view of Linux tracing","summary":"本文介绍了作者在2016年USENIX/LISA大会上展示的Linux性能追踪工具演示，重点讲解了ftrace、perf和bcc/BPF（eBPF）的发展与应用。演示历时15分钟，展示了这些内核内置工具如何从基础追踪演进到具备编程能力的高级分析手段，尤其强调了bcc/BPF带来的强大灵活性和实时可观测性。\n\n作者指出，尽管这些工具自2008年起已集成于Linux内核，但仍未被广泛认知。他通过实际案例改变了听众对Linux追踪的认知，并推荐了相关学习资源，包括官方文档、GitHub实验项目和教程。此外，他还提到与Sasha Goldshtein合办的半日培训课，其配套材料可在GitHub获取。\n\n文章还提及了其他追踪工具如SystemTap、LTTng和sysdig，但未在演示中涵盖。整体强调：随着Linux 4.x系列内核普及，BPF技术将越来越重要，是现代系统性能调优的关键利器。","published_at":"2016-12-27T00:00:00Z"}
{"domain":"brendangregg","path":"https://www.brendangregg.com//blog/2016-11-30/linux-bcc-tcplife.html","title":"Linux bcc/BPF tcplife: TCP Lifespans","summary":"**总结：**\n\n作者开发了 `tcplife` 工具，用于追踪 TCP 连接的生命周期（时长、传输数据量等），特别适用于性能分析与网络调试。该工具基于 BPF（eBPF）实现，通过内核动态跟踪（kprobes）`tcp_set_state()` 函数来低开销地捕获连接从建立到关闭的全过程，避免了传统抓包工具（如 tcpdump）的高负载问题。\n\n关键功能包括：\n- 显示连接的 **持续时间（MS）**、**发送/接收字节数（TX_KB/RX_KB）**、**PID 和进程名（COMM）** 以及 **源/目的地址和端口**。\n- 支持按 **远程端口（-D）**、**本地端口（-L）** 或 **进程 PID（-p）** 过滤。\n- 输出支持宽格式（适配 IPv6）、时间戳、CSV 格式等。\n\n技术亮点：\n- 利用 Linux 内核新增的 `struct tcp_info` 字段（如 `tcpi_bytes_acked`）获取准确吞吐量数据。\n- 通过缓存任务上下文解决状态变更时无法直接获取进程信息的问题。\n\n适用场景：系统管理员、开发者进行网络性能调优、安全审计或故障排查。需较新内核（4.4+）。  \n项目位于 [bcc](https://github.com/iovisor/bcc) 项目中，灵感源自 Julia Evans 的建议。","published_at":"2016-11-30T00:00:00Z"}
{"domain":"brendangregg","path":"https://www.brendangregg.com//blog/2016-10-27/dtrace-for-linux-2016.html","title":"DTrace for Linux 2016","summary":"Linux 内核在 4.9 版本中终于实现了与 DTrace 相当的高级追踪能力，这得益于 eBPF（扩展伯克利数据包过滤器）技术的演进。该技术最初用于网络数据包重定向，后被扩展为支持内核和用户态动态追踪、性能分析、延迟统计、堆栈跟踪等功能。\n\n**核心亮点：**\n- 支持基于 BPF 的动态追踪（kprobes/uprobes）、静态追踪（tracepoints）、定时采样、性能计数器（PMCs）、自定义变量、哈希表、频率统计与延迟直方图。\n- 通过 **bcc 工具集**（如 `execsnoop`、`biolatency`、`ext4slower`、`tcpconnect`、`gethostlatency` 等），可实现进程创建、磁盘 I/O 延迟、文件系统操作、网络连接、DNS 延迟、数据库查询等实时监控。\n- 支持通过 USDT 探针追踪 MySQL 等应用行为，具备生产环境安全性，已被 Netflix、Facebook 等公司广泛使用。\n\n**现状与挑战：**\n- 当前工具链主要依赖 Python/Lua 编写，代码量远高于 DTrace 的简洁脚本，开发门槛较高。\n- 尽管功能强大，但缺乏统一的高级语言接口，未来有望通过 SystemTap、ply 等项目改善。\n- 需要社区推动：推广、教育、文档完善、新工具开发及图形化界面集成。\n\n**总结：**  \n尽管 Linux 没有 DTrace 的语言，但其追踪能力已全面追平甚至超越——**“现在有了 DTrace Toolkit”**。随着 Linux 4.9 的发布，开发者可通过 `apt-get install bcc-tools` 获得强大的性能分析能力，适用于微服务、云原生环境下的故障排查与调优。未来重点在于提升易用性与可视化。","published_at":"2016-10-27T00:00:00Z"}
{"domain":"brendangregg","path":"https://www.brendangregg.com//blog/2016-10-21/linux-efficient-profiler.html","title":"Linux 4.9's Efficient BPF-based Profiler","summary":"Linux 4.9 引入了基于 BPF（eBPF）的优化性能分析功能，实现了无需生成 `perf.data` 文件的实时堆栈采样与汇总，显著降低性能开销。该特性允许在定时采样时直接在内核中执行 BPF 程序，利用 BPF 的堆栈遍历和频率统计能力，将完整的堆栈轨迹作为哈希键进行聚合，仅将汇总结果发送至用户空间。\n\n相比早期版本：\n- **Linux 2.6**：使用 `perf record` 将所有采样数据写入二进制文件（`perf.data`），后续由用户空间处理，存在延迟与磁盘 I/O。\n- **Linux 4.5**：`perf report -g folded` 支持折叠格式输出，提升效率。\n- **Linux 4.9**：通过 `perf_event_open()` + `PERF_EVENT_IOC_SET_BPF` 将 BPF 程序绑定到性能事件，实现真正的内核级实时采样与聚合。\n\n工具 `profile.py`（bcc 工具集）利用此功能，可实时输出堆栈轨迹及采样次数，支持 `-f` 参数直接生成火焰图所需的折叠格式，兼容 `flamegraph.pl`，无需再用 `stackcollapse-perf.pl`。\n\n关键优势：\n- 零 `perf.data` 文件开销，节省 CPU 与磁盘资源；\n- 支持按进程、用户/内核栈筛选；\n- 可用于构建实时火焰图，实现低延迟性能分析。\n\n适用人群：系统开发者、性能调优工程师、内核研究人员。  \n推荐场景：生产环境性能诊断、高频率实时监控、复杂应用瓶颈定位。","published_at":"2016-10-21T00:00:00Z"}
{"domain":"brendangregg","path":"https://www.brendangregg.com//blog/2016-10-15/linux-bcc-tcptop.html","title":"Linux bcc tcptop","summary":"**摘要：**\n\n本文介绍了基于 Linux BPF 技术开发的 `tcptop` 工具，用于实时统计服务器上活跃的 TCP 连接流量（发送/接收字节数），按进程（PID）、本地/远程地址分组输出，支持 IPv4 与 IPv6。该工具是开源项目 [bcc](https://github.com/iovisor/bcc) 的一部分，适用于性能分析和故障排查，可发现异常流量并优化系统。\n\n**核心功能与特点：**\n- 实时追踪 `tcp_sendmsg` / `tcp_recvmsg` 等内核函数，汇总会话数据。\n- 支持间隔输出（默认 1 秒）、不刷新屏幕（`-C`）、仅追踪指定 PID（`-p`）等选项。\n- 输出包含系统负载信息，并分组显示 IPv4/IPv6 流量，便于观察趋势或共享数据。\n\n**性能与开销：**\n- 当前实现通过在内核中聚合数据、用户态定时拉取，显著降低开销。\n- 在典型生产环境（4k–15k TCP 事件/秒）下 CPU 占用仅 0.5%–2%，但高负载（如 300k 事件/秒）时可达 40% 单核。\n- 相比于直接抓包，BPF + TCP 层追踪效率更高，因受缓冲影响事件率更低。\n\n**未来优化方向：**\n- 探索利用 `tcp_info` 中的 RFC4898 新增计数器（如 `bytes_acked`, `bytes_received`）进行轮询获取，理论上可进一步降低开销。\n- 但存在两大挑战：**短生命周期连接易丢失**（需结合 BPF 关闭路径追踪 + 缓存机制）；**轮询 `tcp_info` 本身开销大**（“ss -nti” 可达百毫秒级）。\n- 目前看，原生 BPF 发送/接收追踪仍是更可靠且高效的选择。\n\n**背景与意义：**\n- 原始版本基于 DTrace，强调减少动态探针以提升稳定性。\n- 作者感谢 Netflix 团队建议使用 BPF 构建新版本，体现 BPF 在现代 Linux 性能分析中的强大潜力。\n- 未来希望引入静态 tracepoint，使工具跨内核版本兼容。\n\n**推荐人群：**\n系统管理员、DevOps 工程师、性能调优专家，尤其适合需要监控网络行为、排查高延迟或异常流量场景。","published_at":"2016-10-15T00:00:00Z"}
{"domain":"brendangregg","path":"https://www.brendangregg.com//blog/2016-10-12/linux-bcc-nodejs-usdt.html","title":"Linux bcc/BPF Node.js USDT Tracing","summary":"**摘要：**\n\n本文介绍了如何利用 Linux 内核的 BPF（Berkeley Packet Filter）功能，结合 Node.js 内置的 USDT（用户静态定义跟踪）探针进行性能分析与调试。尽管 V8 已引入自身追踪机制（通过 `--enable-tracing` 生成 JSON 日志），但 USDT 配合 BPF 仍具有独特价值——它能深入系统级调用，实现跨进程、跨内核与用户空间的全栈可观测性。\n\n核心要点包括：\n- **USDT 探针**：Node.js 支持编译时启用 USDT 探针（如 `http__server__request`），用于记录请求路径等信息。\n- **BPF + bcc 工具链**：使用 `bcc`（eBPF 工具集）可编写脚本（如 Python）监听这些探针，实时输出请求详情（如路径、客户端地址）。\n- **探针发现**：可通过 `tplist` 命令查看二进制文件或运行进程中的所有可用探针，涵盖 Node.js、libc、libpthread、V8 等多个组件。\n- **部署方式**：需安装 `systemtap-sdt-dev` 并以 `--with-dtrace` 编译 Node.js；验证探针存在可用 `readelf -n` 检查。\n- **优势与前景**：相比 V8 追踪仅限于 JS 层，BPF 可覆盖系统调用、内存分配、线程同步等底层行为，支持栈回溯、延迟统计、直方图分析，适合复杂性能问题诊断。\n- **未来方向**：虽有 V8 追踪简化部分场景，但 USDT + BPF 提供更全面、可定制的观测能力，未来可发展为自动化工具与可视化界面。\n\n**适用人群**：系统工程师、Node.js 性能调优专家、Linux 内核/应用层深度调试开发者。","published_at":"2016-10-12T00:00:00Z"}
{"domain":"brendangregg","path":"https://www.brendangregg.com//blog/2016-10-08/linux-bcc-runqlat.html","title":"Linux bcc/BPF Run Queue (Scheduler) Latency","summary":"**摘要：**\n\n`runqlat` 是 BCC 工具集中的一个性能分析工具，用于测量调度器运行队列延迟——即线程从变为可运行状态到实际开始在 CPU 上执行的时间。该指标对诊断系统响应性问题至关重要，尤其在高负载或异常等待场景下。\n\n- **核心功能**：以直方图形式统计运行队列延迟，支持微秒（默认）和毫秒两种单位（通过 `-m` 选项）。\n- **典型输出**：在高负载系统中呈现双峰分布，显示大量延迟集中在 16–32 毫秒区间；而在空闲系统中，延迟普遍低于 1 毫秒，表明无排队压力。\n- **使用灵活**：支持按进程（`-P`）、线程（`-L`）或指定 PID（`-p`）过滤，可设置采样间隔与次数。\n- **实用场景**：帮助识别因 CPU 竞争导致的性能瓶颈，指导调优策略（如调整调度参数、负载均衡）。\n- **互补工具**：配合 `cpudist`（展示线程实际运行时间），可全面分析“等待”与“执行”的时间分布。\n\n**推荐人群**：系统管理员、内核开发者、性能调优工程师。  \n**价值点**：快速定位调度延迟问题，提升系统响应效率。","published_at":"2016-10-08T00:00:00Z"}
{"domain":"brendangregg","path":"https://www.brendangregg.com//blog/2016-10-06/linux-bcc-ext4dist-ext4slower.html","title":"Linux bcc ext4 Latency Tracing","summary":"该博客介绍了两个基于 BCC 框架的性能分析工具：`ext4dist` 和 `ext4slower`，用于在文件系统层（ext4）追踪 I/O 操作延迟，以更准确地反映应用程序实际体验的性能瓶颈。\n\n**核心观点**：  \n传统块设备层的 I/O 监测虽有用，但无法反映应用真实感受；而从虚拟文件系统（VFS）到文件系统的完整调用链路测量延迟，能更真实体现应用端性能。\n\n**关键工具与功能**：\n- **`ext4dist`**：统计 ext4 文件系统常见操作（读、写、打开、fsync）的延迟分布，输出为 2 的幂次分组直方图。例如显示读取延迟存在双峰分布——快的一类（\u003c7μs）可能来自内存缓存，慢的一类（256–1023μs）来自磁盘，揭示缓存命中率与存储性能。\n- **`ext4slower`**：筛选出超过指定阈值（如 1ms）的慢速操作，输出时间、进程、文件名和延迟，便于排查性能热点。支持设置为 0 来捕获所有事件（需谨慎使用，避免日志爆炸）。\n\n**优势与适用场景**：\n- 能精准判断延迟是否由存储子系统引起（如磁盘、文件系统、卷管理器）。\n- 可验证“偶发长延迟”是否由单个慢 I/O 导致，或多个快速操作累积而成。\n- 配合 `ext4dist` 使用可评估操作频率，避免高负载下过度采样造成系统开销。\n\n**技术实现**：  \n基于 Linux 内核动态追踪（kprobes + BPF），属于 BCC 工具集，同样支持 btrfs、xfs、zfs 等文件系统。\n\n**推荐人群**：  \n系统管理员、性能工程师、开发者，尤其适用于诊断数据库、高并发服务中的慢响应问题。","published_at":"2016-10-06T00:00:00Z"}
{"domain":"brendangregg","path":"https://www.brendangregg.com//blog/2016-10-04/linux-bcc-mysqld-qslower.html","title":"Linux MySQL Slow Query Tracing with bcc/BPF","summary":"**摘要：**\n\n`mysqld_qslower` 是一个基于 BCC 工具集的 Linux 内核级追踪工具，用于实时捕获 MySQL 服务器中执行时间超过指定阈值（默认 1 毫秒）的查询语句。它利用 MySQL 编译时启用的 USDT（User Statically Defined Tracing）探针，通过 BPF 技术在运行时动态插入追踪逻辑，无需重启服务。\n\n该工具核心机制为：\n- 在 `query__start` 和 `query__done` 探针处记录查询开始与结束时间；\n- 使用 BPF 哈希表保存线程上下文中的查询起始时间与查询内容；\n- 计算查询耗时并输出慢查询详情，包括时间戳、进程 ID、耗时（毫秒）和完整 SQL 语句。\n\n优势：\n- 实时、低开销的慢查询监控，类似自定义慢日志；\n- 可动态调整阈值，灵活应对性能调优需求；\n- 支持丰富的 USDT 探针（如连接、读写、索引访问等），可扩展用于深入分析数据库行为。\n\n使用方法：\n- 通过 `pgrep mysqld` 获取进程号；\n- 运行 `mysqld_qslower \u003cPID\u003e` 查看慢查询；\n- 用 `tplist -l /path/to/mysqld` 列出可用探针，确认编译时已启用 DTrace 支持（需 `--with-dtrace`）。\n\n适用人群：数据库管理员（DBA）、系统工程师、性能优化人员。  \n推荐场景：生产环境性能排查、慢查询根因分析、MySQL 稳定性调优。","published_at":"2016-10-04T00:00:00Z"}
{"domain":"brendangregg","path":"https://www.brendangregg.com//blog/2016-10-01/linux-bcc-security-capabilities.html","title":"Linux bcc Tracing Security Capabilities","summary":"**总结：**\n\n本文介绍了一款名为 `capable` 的 Linux 工具，用于实时追踪应用程序执行的**安全能力检查（security capabilities）**，基于 BPF 技术（通过 bcc 工具集）动态跟踪内核函数 `cap_capable()`。该工具可显示进程、用户、能力编号及名称，并区分是否触发审计日志。\n\n- **核心功能**：  \n  - 默认仅输出带审计标记的能力检查（`AUDIT=1`），便于识别真正影响安全决策的行为。\n  - 支持 `-v` 选项查看所有调用，包括非审计调用（如 `CAP_SYS_ADMIN` 被频繁检查但未审计）。\n  - 可通过 `-p PID` 限定追踪特定进程。\n  - 计划新增 `-K`（内核栈追踪）和 `-U`（用户栈追踪）选项，帮助定位能力检查来源。\n\n- **关键发现**：  \n  - 某些能力检查（如 `CAP_SYS_ADMIN`）出现在 `security_vm_enough_memory_mm()` 中，属于内存预留逻辑而非安全控制，因此未启用审计，不应视为权限滥用。\n  - 通过内核栈分析可精准定位能力检查上下文，提升安全审计准确性。\n\n- **兼容性要求**：  \n  - `capable` 需要内核 4.4+；`-K` 栈追踪需 4.6+。\n  - 对旧内核（如 3.x），可用 `perf-tools` 中的 `kprobe` 替代方案，但配置更复杂。\n\n- **实践价值**：  \n  帮助系统管理员和开发者**精确了解应用实际使用的安全能力**，从而通过 `setcap` 精简权限，实现最小权限原则，增强系统安全性。\n\n**适用人群**：系统管理员、安全工程师、Linux 内核开发者。","published_at":"2016-10-01T00:00:00Z"}
{"domain":"brendangregg","path":"https://www.brendangregg.com//blog/2016-09-28/java-warmup.html","title":"Java Warmup","summary":"本文通过一系列火焰图（flame graphs）展示了Java微服务在启动和预热过程中的性能变化，使用Linux `perf` 工具进行采样，揭示了JVM运行时的关键行为。主要发现如下：\n\n- **0–30秒**：JVM初始化堆内存，`os::pretouch_memory()` 触发页面故障（内核代码），大量时间消耗在内存清零（`clear_page_c_e` 汇编函数）。此时多数Java方法仍由解释器执行（红色“Interpreter”栈帧），未达到编译阈值（默认10,000次调用）。\n  \n- **30–60秒**：堆初始化完成，但仍在持续编译。约55% CPU时间用于C2即时编译器（`C2Compiler::compile_method`），解释器栈依然显著。垃圾回收（GC）开始触发（`ParNewGenTask::work`），同时观察到频繁的文件删除操作（`UnixFileSystem::delete0`），可能与日志轮转有关。\n\n- **90秒后**：不同阶段的预热模式显现，各阶段的热点方法呈现绿色（已编译为本地代码），显示性能趋于稳定。\n\n- **600–630秒**（10分钟）：系统进入生产负载状态，编译塔消失，大部分时间用于执行已编译的Java代码，性能达到稳定。\n\n**技术亮点**：\n- 使用 `perf` 可穿透查看内核、C++ 和 Java 代码的完整调用栈，而传统JVM工具存在盲区。\n- 火焰图颜色编码清晰：黄色（C++）、绿色（Java）、橙色（内核）、红色（其他用户态）。\n- 存在栈截断问题（默认最多127层），导致部分调用栈无法正确合并，未来可通过 `kernel.perf_event_max_stack` 调整。\n- 符号解析依赖 `jmaps` 脚本抓取映射信息，若方法被重编译，可能导致符号丢失。\n\n**生成流程**：\n- 用 `perf record -F 99 -a -g` 采集100次30秒数据；\n- 用 `jmaps` 提取Java符号；\n- 用 `stackcollapse-perf.pl` 和 `flamegraph.pl` 处理并生成可视化火焰图。\n\n**适用人群**：性能调优工程师、JVM开发者、系统架构师。建议结合 `perf-tools` 或 `bcc` 进一步深入分析异常点。","published_at":"2016-09-28T00:00:00Z"}
{"domain":"brendangregg","path":"https://www.brendangregg.com//blog/2016-09-03/sudden-disk-busy.html","title":"Sudden Disk Utilization","summary":"**摘要：**\n\n一台Jenkins主机的磁盘使用率（%busy）突然飙升至80%，引发性能问题。通过监控工具Atlas发现磁盘利用率持续高位。使用`iostat`和`iolatency`分析显示I/O延迟正常，无硬件瓶颈，但`iosnoop`发现大量来自Java进程的读取请求（TYPE=M），且主要由`stat()`系统调用触发。\n\n进一步通过`perf`追踪调用栈，定位到问题根源：一个名为“DiskUsageMonitor”的监控程序正频繁对文件系统执行`stat()`操作以统计磁盘使用情况，导致大量不必要的I/O负载。\n\n**关键发现：**\n- 磁盘高负载并非硬件或工作负载本身问题，而是由监控工具自身引起的。\n- `stat()`调用在文件系统遍历中产生高频随机读取，形成性能瓶颈。\n- 该案例展示了如何利用内核级追踪工具（如perf、ftrace）快速诊断性能问题。\n\n**实践启示：**\n- 监控工具若设计不当，可能成为性能杀手。\n- 建议定期审查监控组件的资源开销，避免“监控监控”带来的副作用。\n- 推荐使用`perf-tools`等低开销工具进行深度性能分析。\n\n**适用人群：** 系统管理员、DevOps工程师、运维开发人员。","published_at":"2016-09-03T00:00:00Z"}
{"domain":"brendangregg","path":"https://www.brendangregg.com//blog/2016-08-09/gdb-example-ncurses.html","title":"gdb Debugging Full Example (Tutorial): ncurses","summary":"本文通过一个真实的GDB调试案例，详细演示了如何使用GDB定位并解决一个Python程序因`ncurses`库崩溃导致的段错误（Segmentation Fault）。以下是核心内容总结：\n\n---\n\n### **核心问题**\n`bcc`工具中的`cachetop.py`脚本在运行时出现“Segmentation fault (core dumped)”，需通过GDB分析核心转储文件定位原因。\n\n---\n\n### **关键调试步骤与发现**\n\n1. **启用核心转储**  \n   默认`ulimit -c`为0，禁用核心转储。通过设置：\n   ```bash\n   ulimit -c unlimited\n   echo \"/var/cores/core.%e.%p\" \u003e /proc/sys/kernel/core_pattern\n   ```\n   成功生成核心文件。\n\n2. **初步分析：堆栈回溯（`bt`）**  \n   GDB显示崩溃发生在`doupdate()`函数中，但符号信息缺失，`??`占多数，无法直接定位。\n\n3. **注册器检查（`info registers`）**  \n   发现`%rsi`寄存器值为0，指向空指针，确认是**空指针解引用**导致段错误。\n\n4. **加载调试符号（`libncursesw5-dbg`）**  \n   安装调试包后，堆栈回溯显示真实调用路径：  \n   `ClrBlank() → ClrUpdate() → doupdate()`，并定位到`if (back_color_erase)`语句。\n\n5. **源码分析（`disas/s` + `list`）**  \n   发现`back_color_erase`是宏定义，实际访问的是`CUR Booleans[28]`，而`CUR`依赖于`cur_term`全局变量。  \n   问题根源：`cur_term`未被正确初始化。\n\n6. **深入追踪：`set_curterm()`被传入`NULL`**  \n   通过`uprobe`、`perf-tools`和`bcc trace.py`工具发现：  \n   `llvm::sys::Process::FileDescriptorHasColors()`函数内部调用`set_curterm(nullptr)`，这是**LLVM的一个已知缺陷**。\n\n7. **临时解决方案**  \n   通过`-fno-color-diagnostics`编译选项绕过该代码路径，成功修复问题。\n\n8. **高级技巧展示**  \n   - `reverse-stepi`（反向单步）  \n   - `layout split`（TUI界面查看源码+汇编）  \n   - `conditional breakpoints`（条件断点）  \n   - `ret`指令跳过危险函数（实验性）\n\n9. **Python调试增强**  \n   安装`python-dbg`后，可使用`py-bt`和`py-list`查看完整的Python堆栈和源码行号，精准定位到`cachetop.py`第188行。\n\n---\n\n### **实用建议与启示**\n\n- **核心转储是调试利器**，但需提前配置。\n- **调试符号包**（如`*-dbg`）极大提升分析效率。\n- **外部工具**（如`cscope`、`uprobe`、`bcc`）可补充GDB能力。\n- **避免随意写内存或跳过函数**，有严重风险。\n- **`py-bt`等语言扩展**让调试高级语言更高效。\n\n---\n\n### **目标读者**\n- 系统管理员、开发者、运维人员\n- 需要调试二进制程序或性能问题的技术人员\n- 学习GDB调试技巧的初学者\n\n\u003e ✅ **推荐**：此篇是极佳的**带完整输出的GDB实战教程**，尤其适合希望从“只看命令”转向“理解过程”的用户。","published_at":"2016-08-09T00:00:00Z"}
{"domain":"brendangregg","path":"https://www.brendangregg.com//blog/2016-07-23/deirdre.html","title":"Deirdré","summary":"本文作者回顾了与技术教育先驱德伊德雷·斯特劳根（Deirdré Straughan）长达十余年的合作历程。两人均致力于推动技术内容的创新传播，早在2009年于Kernel Conference相遇后便携手打造高质量的技术文章、视频、演讲和书籍。德伊德雷不仅是作者写作与出版的重要合作者，更是其思想上的伙伴——她深度参与每本书的构思、撰写与修改，以极强的技术理解力和文字功底提升内容质量。\n\n在共同创作的艰难过程中，两人建立了深厚的信任与情感纽带。当德伊德雷罹患癌症时，作者深切感受到无力与痛心，但最终她战胜病魔，现已康复。如今，二人不仅继续计划合著新书，更正式成为生活伴侣。\n\n文章致敬德伊德雷作为技术女性的杰出贡献与人格魅力，也表达了对技术内容共创精神的坚持与感恩。推荐阅读她的博客、Techies项目及Twitter账号了解更多信息。","published_at":"2016-07-23T00:00:00Z"}
{"domain":"brendangregg","path":"https://www.brendangregg.com//blog/2016-07-13/llnode-nodejs-memory-leak-analysis.html","title":"llnode for Node.js Memory Leak Analysis","summary":"当 Node.js 进程内存持续增长时，可通过 **llnode** 工具进行深度内存分析。该工具基于 lldb，支持在 Linux 上解析核心转储文件（core dump），并提供 `findjsobjects` 等命令，快速定位内存泄漏的根源。\n\n### 核心步骤：\n1. **安装 llnode**：通过 `apt-get` 安装依赖后，从 GitHub 克隆并编译 llnode（或使用 `npm install llnode`）。\n2. **生成核心转储**：使用 `gcore` 或发送 `SIGBUS` 信号触发进程崩溃，保存 core 文件。\n3. **处理内存范围文件**（仅旧版 lldb 需要）：用 `readelf2segments.py` 生成内存区域文件，并设置 `LLNODE_RANGESFILE` 环境变量。\n4. **分析内存对象**：\n   - 使用 `v8 findjsobjects` 查看所有 JavaScript 对象及其实例数量与大小。\n   - 通过 `v8 findjsinstances \u003c类名\u003e` 列出特定对象实例。\n   - 用 `v8 inspect \u003c地址\u003e` 深入查看对象结构和属性。\n\n### 关键发现：\n- 高频出现的对象如 `Socket`、`ServerResponse`、`TickObject` 可能是内存增长的源头。\n- 结合两次核心转储对比，可识别随时间增长的对象类型。\n\n### 实用建议：\n- 适用于生产环境故障排查，尤其适合无法复现但内存持续膨胀的问题。\n- 未来版本将简化流程（如自动处理内存范围），当前需注意 lldb 版本兼容性问题（如 3.8/3.9 差异）。\n\n\u003e ✅ 推荐给运维、性能调优工程师及高级开发者，用于诊断复杂内存泄漏问题。","published_at":"2016-07-13T00:00:00Z"}
{"domain":"brendangregg","path":"https://www.brendangregg.com//blog/2016-06-14/ubuntu-xenial-bcc-bpf.html","title":"Ubuntu Xenial bcc/BPF","summary":"**摘要：**\n\nUbuntu 16.04 LTS（Xenial）搭载 Linux 4.4 内核，支持基于 eBPF 的高性能性能分析与故障排查工具。通过 `bcc` 工具集，用户可高效追踪系统行为，如磁盘 I/O、文件系统延迟等。\n\n**核心要点：**\n- **安装简便**：可通过官方源一键安装 `bcc-tools`，未来还将支持 Snap 包。\n- **高效追踪**：工具利用 BPF 在内核态完成事件采样与统计，仅将结果传至用户空间，显著降低开销。\n- **典型工具示例**：\n  - `biosnoop`：实时显示磁盘读写详情及延迟。\n  - `biolatency`：以直方图形式展示 I/O 延迟分布，内核侧统计提升效率。\n  - `ext4slower`：筛选并显示超过阈值的 ext4 文件系统操作延迟。\n- **使用方式**：类 Unix 命令行接口，支持参数控制输出频率、单位、时间戳等。\n- **文档完善**：所有工具配有手册页和示例文件，便于学习与使用。\n\n**注意事项：**\n- 高频事件可能带来性能影响，建议先在测试环境验证。\n- 某些依赖新 BPF 特性的工具（如栈跟踪）在 Xenial 上不可用，可尝试 `/usr/share/bcc/tools/old` 中的兼容版本。\n\n**适用人群**：系统管理员、开发人员、性能调优工程师。  \n**推荐理由**：借助 eBPF 技术实现低开销、高精度的实时监控，是现代 Linux 系统可观测性的强大工具。","published_at":"2016-06-14T00:00:00Z"}
{"domain":"brendangregg","path":"https://www.brendangregg.com//blog/2016-06-08/linux-hist-triggers.html","title":"Hist Triggers in Linux 4.7","summary":"**Linux 4.7 新特性：hist triggers 深度剖析**\n\n**核心亮点**：Linux 4.7-rc1 引入了 **hist triggers**，一种高效、内核级的自定义直方图追踪机制，无需用户空间开销即可实现系统级可观测性。\n\n**关键功能与应用**：\n- **按进程名+PID统计系统调用**：`hist:key=common_pid.execname` 可精准识别高调用进程（如 `dumpsystemstats` 调用 5.1 万次 `read()`）。\n- **结合返回值分析**：支持 `values=ret` 累加返回值，过滤有效读取（`if ret \u003e= 0`），揭示数据读取行为。\n- **内核栈追踪磁盘 I/O 起源**：以 `stacktrace` 为键，定位触发磁盘请求的完整调用路径，适用于排查异步 I/O 问题。\n- **用户态函数调用追踪**：通过 `perf probe` 动态注入 `malloc()` 探针，统计各进程内存分配频率（如 `tar` 调用 53.6 万次）。\n\n**使用方式**：\n- 三步操作：`echo 'hist:config' \u003e /sys/kernel/debug/tracing/.../trigger` → `cat /.../hist` 查看结果 → `echo '!hist:config'` 停止。\n- 支持复杂配置：多字段键、值聚合、条件过滤、自定义大小（`size=4096` 防溢出）。\n\n**优势与对比**：\n- 相比旧版 perf 工具需导出数据再处理，hist triggers 实现 **零用户空间开销**，性能极高（约 0.25μs/事件）。\n- 与 BPF 对比：更轻量、易用（仅需 shell），适合快速诊断；BPF 更强大但需编译和学习成本。二者互补，长期共存。\n\n**注意事项**：\n- 需启用 `CONFIG_HIST_TRIGGERS`。\n- 高频事件下注意 `Dropped: 0`，可调大 `size`。\n- 新功能建议先在测试环境验证。\n\n**适用人群**：系统管理员、性能调优工程师、内核开发者。推荐通过 `perf-tools`、`trace-cmd` 等前端工具便捷使用。\n\n\u003e 总结：hist triggers 是 Linux 内核观测能力的一次飞跃，让实时、高效、细粒度的系统行为分析触手可及。","published_at":"2016-06-08T00:00:00Z"}
{"domain":"brendangregg","path":"https://www.brendangregg.com//blog/2016-05-04/srecon2016-perf-checklists-for-sres.html","title":"SREcon: Performance Checklists for SREs 2016","summary":"**摘要：**\n\n在Netflix，系统故障时每分钟都至关重要，传统性能工程难以应对紧急情况。本文分享了SRE（站点可靠性工程）在应急响应中使用“性能检查清单”的实战经验，强调其在快速诊断与恢复中的关键作用。\n\n作者作为Netflix CORE应急团队的轮值SRE，介绍了从云级监控到Linux底层排查的多层级检查清单，涵盖性能、可靠性与基础设施层面。核心要点包括：\n\n- **检查清单价值**：在高压场景下，结构化检查清单可显著提升响应效率，避免遗漏关键指标。\n- **典型清单示例**：\n  - **Linux性能60秒分析清单**：通过`uptime`、`dmesg`、`vmstat`、`iostat`、`top`等命令快速定位负载、内存、磁盘、网络和CPU瓶颈。\n  - **磁盘检查清单**：关注I/O延迟、文件系统状态、磁盘错误（如`ext4slower`、`smartctl`），利用BPF工具深入诊断。\n  - **网络检查清单**：分析接口利用率、TCP重传、DNS配置、连接异常及路由问题，借助`tcpretrans`、`tcpconnect`等BPF工具。\n  - **CPU检查清单**：结合`mpstat`、`pidstat`、火焰图、子秒级偏移热图进行深度分析，识别热点进程与调度问题。\n\n这些清单均建议以可视化仪表盘形式实现，便于实时监控与快速决策。文章还指出，虽然部分清单为Netflix定制，但其方法论具有普适性，适用于各类高可用系统运维。\n\n**实践意义**：  \n对SRE、DevOps工程师和系统管理员极具参考价值，尤其适合构建应急响应流程、优化监控体系与提升故障排查效率。\n\n**推荐人群**：系统工程师、SRE从业者、运维团队负责人、技术管理者。","published_at":"2016-05-04T00:00:00Z"}
{"domain":"brendangregg","path":"https://www.brendangregg.com//blog/2016-04-30/linux-perf-folded.html","title":"Linux 4.5 perf folded format","summary":"Linux 4.5 引入了 `perf` 工具的 `-g folded` 输出模式，显著降低了火焰图生成的 CPU 消耗。该功能使 `perf report` 可直接输出折叠格式（folded format）的调用栈数据，无需再通过 `stackcollapse-perf.pl` 在用户空间处理，从而减少了性能开销。\n\n传统方式需先用 `perf script` 输出原始数据，再经由 Perl 脚本转换为折叠格式，整体 CPU 消耗较高（约 9 秒）。而新方法使用 `perf report --stdio --no-children -n -g folded,0,caller,count -s comm` 配合 `awk` 处理，可直接生成火焰图所需输入，总 CPU 消耗降至约 4.3 秒，效率提升明显。\n\n此改进对自动化火焰图生成场景尤其有价值，尽管未来 BPF（Linux 4.6+）将支持在内核中直接聚合堆栈样本，进一步优化性能，但当前 `-g folded` 已是值得采用的实用方案。","published_at":"2016-04-30T00:00:00Z"}
{"domain":"brendangregg","path":"https://www.brendangregg.com//blog/2016-03-30/working-at-netflix-2016.html","title":"Working at Netflix 2016","summary":"这篇博客分享了作者在Netflix工作两年的亲身经历，揭示了这家公司为何能打破“科技公司光鲜外表背后实则糟糕”的普遍印象。以下是核心要点总结：\n\n**核心观点**：  \nNetflix并非表面光鲜的幻象，而是一个真正以专业、责任与创新为核心文化的公司，实际体验与外界期待一致，甚至超出预期。\n\n**关键洞察**：\n- **文化驱动**：得益于著名的《Netflix文化手册》（Culture Deck），公司倡导“自由与责任并重”，员工高度自主，协作高效，注重工作生活平衡。\n- **挑战性与成长**：工作极具挑战，尤其在系统级深度领域（如内核、虚拟化、分布式系统分析）有大量实战机会，持续推动个人能力跃升。\n- **SRE实战经验**：作为核心SRE团队成员，参与重大故障响应，在高压下解决跨服务复杂问题，借助先进工具与团队支持，压力可控且学习收获巨大。\n- **技术前沿实践**：主导开发性能分析工具（如Java CPU火焰图、Linux perf/ftrace工具链）、贡献BPF/CC、深入研究Xen、Tomcat与rxNetty对比等，持续推动技术创新。\n\n**其他亮点**：\n- 参与多项国际会议演讲（JavaOne、LinuxCon、BSD会议等）；\n- 业余参与公司板球俱乐部，团队氛围融洽；\n- 工作环境开放现代，位于加州洛斯加托斯新办公楼。\n\n**适合人群**：  \n仅推荐给顶尖资深工程师或专业人士——若你自信、求知欲强、愿意面对未知挑战，且能适应高要求环境，那么这里值得考虑。\n\n**建议行动**：  \n查看[文化手册](http://www.slideshare.net/reed2001/culture-1798664)和[职位页面](https://jobs.netflix.com/jobs)，但请勿直接联系作者，应通过官方渠道投递简历。\n\n\u003e 总结：这是一份来自一线工程师的真实反馈——Netflix不仅是“理想公司”，更是一个让顶级人才持续成长、敢于挑战的技术高地。","published_at":"2016-03-30T00:00:00Z"}
{"domain":"brendangregg","path":"https://www.brendangregg.com//blog/2016-03-28/linux-bpf-bcc-road-ahead-2016.html","title":"Linux BPF/bcc Road Ahead, March 2016","summary":"**BPF与bcc现状及未来展望（中文摘要）**\n\n本文总结了Linux BPF（eBPF）在系统追踪领域的最新进展，以及其开源前端工具bcc的当前能力与发展方向。\n\n**当前状态（Linux 4.6-rc1）：**\n- **内核级动态追踪**：支持kprobes（内核探针）。\n- **用户级动态追踪**：支持uprobes（用户空间探针）。\n- **过滤、调试输出（bpf_trace_printk）、事件输出（bpf_perf_event_output）**。\n- **数据结构支持**：全局/线程局部变量、关联数组、频率统计、直方图（幂次、线性、自定义）。\n- **时间功能**：获取时间戳与时间差（bpf_ktime_get）。\n- **堆栈追踪**：内核与用户空间均支持（通过BPF stackmap），并可生成火焰图。\n\n**bcc增强功能（用户层）：**\n- 提供Python接口，支持debug输出、事件输出、定时输出、直方图打印。\n- 支持内核/用户符号解析（ksym(), usymaddr()）、tracepoint支持、堆栈遍历与火焰图生成。\n- 内置大量辅助宏与函数，提供数十个实用工具（位于/tools目录）。\n\n**未来计划：**\n- **内核层**：静态追踪（tracepoints）、定时采样事件、环形缓冲区覆盖。\n- **bcc层**：用户级静态追踪（USDT）、更多易用辅助函数、新增工具与测试。\n\n**其他相关工作：**\n- LLVM BPF调试优化、32位子寄存器支持、BPF运行时统计、图形化界面（如热力图、火焰图）、终端界面（TUI）、内置编译器、高级语言支持、性能优化与缺陷修复。\n\n**如何参与贡献：**\n1. **推广宣传**：分享BPF/bcc资源链接，提升社区认知。\n2. **内核开发**：参与BPF代码提交、测试与代码审查，可从samples/bpf示例入手。\n3. **bcc开发**：贡献Python/C/汇编代码，支持多架构兼容（如寄存器别名问题）。\n4. **发行版打包**：为各Linux发行版创建无依赖的bcc安装包。\n5. **测试**：使用并报告工具缺陷。\n6. **文档撰写**：协助编写教程、参考手册，尤其针对Ubuntu 16.04 LTS等新版本。\n7. **使用案例**：发布早期实践案例，推动项目演进。\n\n\u003e 总结：BPF已进入成熟阶段，功能强大且持续完善。尽管接口仍处演化期，但已具备实战价值。欢迎开发者、运维人员和性能工程师共同参与，共建下一代系统观测生态。","published_at":"2016-03-28T00:00:00Z"}
{"domain":"brendangregg","path":"https://www.brendangregg.com//blog/2016-03-05/linux-bpf-superpowers.html","title":"Linux BPF Superpowers","summary":"**总结：**\n\nBrendan Gregg 在 Facebook 的 Performance @Scale 活动中介绍了 Linux 4.x 系列中即将推出的 BPF（Berkeley Packet Filter）强大功能，现已演变为更通用的内核级字节码框架。该技术可实现无需重启系统的系统级性能追踪，支持动态探针、网络虚拟化等场景。\n\n他重点演示了基于 BCC（BPF Compiler Collection）的开源工具，如 `gethostlatency`（实时监控全系统 DNS 延迟）、`execsnoop`、`opensnoop`、`runqlat` 等，这些工具能高效诊断性能瓶颈，且只需内核 4.1+ 即可运行。\n\n文章强调，尽管当前仍处于早期阶段，但随着 Ubuntu 16.04 等主流发行版采用 4.x 内核，这些工具将迅速普及。作者还提供了丰富的学习资源链接，涵盖 BPF、perf、火焰图（Flame Graphs）及 Netflix 实践案例。\n\n**核心价值：**  \n- BPF 让 Linux 性能分析进入“无侵入、动态、高精度”新时代。  \n- BCC 工具集为开发者提供强大、易用的性能诊断能力。  \n- 适合系统工程师、运维人员和开发人员关注与实践。","published_at":"2016-03-05T00:00:00Z"}
{"domain":"brendangregg","path":"https://www.brendangregg.com//blog/2016-02-08/linux-ebpf-bcc-uprobes.html","title":"Linux eBPF/bcc uprobes","summary":"**摘要：**\n\nbcc 已新增用户态动态追踪支持，基于 eBPF 技术，可无侵入式监控系统中所有运行的 bash 会话和 libc 库函数调用。  \n\n- **bashreadline**：通过 `uretprobe` 追踪 `readline()` 函数返回值，实时捕获所有 shell 中执行的命令（包括失败命令），无需特殊启动模式，即插即用，实现“系统级命令审计”。\n- **gethostlatency**：利用 `uprobe` 和 `uretprobe` 追踪 `getaddrinfo`、`gethostbyname` 等 DNS 解析函数的调用与返回，计算并输出系统级域名解析延迟，用于性能分析与故障排查。\n\n关键技术点：  \n- 使用 `bpf_probe_read()` 安全读取用户空间数据；  \n- 依赖 x86_64 `%ax` 寄存器获取返回值（未来将提供统一别名如 `rval`）；  \n- 支持对任意进程和库函数动态插入探针，无需重启服务。\n\n**意义**：标志着 eBPF 在用户态可观测性上的重大突破，为系统诊断、安全审计和性能优化提供了强大工具。  \n**推荐人群**：系统管理员、SRE、DevOps 工程师、性能调优专家。","published_at":"2016-02-08T00:00:00Z"}
{"domain":"brendangregg","path":"https://www.brendangregg.com//blog/2016-02-05/ebpf-chaingraph-prototype.html","title":"Who is waking the waker? (Linux chain graph prototype)","summary":"本文介绍了**链式调用图（Chain Graphs）**这一性能分析新工具，用于追踪线程阻塞的完整唤醒路径。作者此前提出的“离CPU火焰图”（off-wake flame graphs）虽能显示线程阻塞与唤醒的栈信息，但无法揭示唤醒链的全部过程——例如，`sshd` 被 `kworker` 唤醒，但谁又唤醒了 `kworker`？  \n\n为解决此问题，作者基于 eBPF 开发了**链式调用图原型**，可可视化从应用到硬件中断的完整唤醒链。示例显示：`vmstat 1` 每秒触发一次定时器，唤醒 `kworker`，最终唤醒 `sshd`，总耗时达 9 秒。这揭示了系统延迟的根本原因：**所有路径终归于硬件中断或定时器**。\n\n当前挑战包括：\n- 受限于 eBPF 栈大小，仅支持有限层级的调用栈；\n- 仅捕获内核栈，缺乏用户态栈；\n- 存在重复数据和内存占用问题；\n- 高频调度事件可能导致性能开销。\n\n尽管如此，链式调用图前景广阔：它不仅能解释为何线程阻塞，还能揭示**阻塞持续时间的根源**，是未来生产环境性能诊断的重要补充工具，尤其适合与 CPU 火焰图协同使用。作者期待该功能未来整合进 bcc 工具集。","published_at":"2016-02-05T00:00:00Z"}
{"domain":"brendangregg","path":"https://www.brendangregg.com//blog/2016-02-01/linux-wakeup-offwake-profiling.html","title":"Linux Wakeup and Off-Wake Profiling","summary":"本文介绍了利用 eBPF 技术实现的四种火焰图（Flame Graph）类型，用于深入分析系统性能瓶颈，尤其聚焦于线程阻塞与唤醒机制。核心贡献是首次将**离 CPU 时间**（off-CPU）与**唤醒栈**（wakeup stack）结合，形成全新的**离唤醒时间火焰图**（off-wake time flame graph），揭示了线程“为何阻塞”及“被谁唤醒”的完整因果链。\n\n### 主要内容总结：\n1. **传统火焰图**：  \n   - **CPU 火焰图**：展示线程在 CPU 上执行的时间。  \n   - **离 CPU 火焰图**：显示线程因 I/O、锁、睡眠等事件阻塞的时间，但无法说明“为何被唤醒”。\n\n2. **新引入的两种工具与火焰图**：  \n   - **`wakeuptime`**：追踪唤醒事件，显示**唤醒者线程的堆栈**，可识别哪个线程唤醒了阻塞线程（如 `tar` 唤醒 `gzip`）。  \n   - **`offwaketime`**：融合离 CPU 与唤醒栈，在同一图中呈现**阻塞路径**（蓝色，自底向上）与**唤醒路径**（青色，自顶向下），中间以灰色分隔，逻辑清晰。\n\n3. **实际案例分析**：  \n   - 在 `tar | gzip` 备份流程中，`offwaketime` 图清晰显示：`gzip` 阻塞因等待 `tar` 写入，而 `tar` 又因磁盘 I/O 被阻塞，完整还原了延迟链条。  \n   - 增加 `cron` 执行 `dumpsystemstats` 的示例，量化各子进程启动、I/O 和等待耗时，验证了该方法对复杂系统调用链的诊断能力。\n\n4. **当前局限与未来方向**：  \n   - 依赖 eBPF 堆栈模拟，仅支持内核栈，且唤醒栈深度限制为 10 层。  \n   - 未来将支持用户态栈、多级唤醒链（如唤醒者自身也被阻塞），提升准确性。\n\n### 实用价值：\n- 为性能调优提供**端到端的阻塞与唤醒因果分析**，特别适用于诊断 I/O、锁竞争、调度延迟等问题。\n- 是 Linux 性能分析工具箱的重要补充，尤其适合系统级和应用级性能剖析。\n\n\u003e ✅ 推荐读者：系统工程师、性能优化专家、内核开发者、DevOps 工程师。","published_at":"2016-02-01T00:00:00Z"}
{"domain":"brendangregg","path":"https://www.brendangregg.com//blog/2016-01-27/unikernel-profiling-from-dom0.html","title":"Unikernel Profiling: Flame Graphs from dom0","summary":"**总结：**\n\n本文探讨了如何对基于 Xen 的未核（unikernel）进行性能分析与调试，反驳了“未核是不可渗透的黑盒”这一误解。作者以 MirageOS 为例，展示了两种可行的 profiling 方法：\n\n1. **常规进程模式**：将未核编译为 Unix 二进制程序，在 Linux 上使用 `perf_events` 工具生成 CPU 火焰图，适用于开发阶段的性能调优与问题排查。\n\n2. **Xen 宿主（dom0）到客户机（domU）模式**：通过 `xenctx` 命令从 dom0 拾取 domU 的寄存器状态和调用栈，结合符号映射文件（`.map`），可实现对运行在 Xen 上的未核的堆栈追踪。作者构建了一个简易脚本，循环采集堆栈并生成火焰图，验证了该方法的可行性。\n\n**关键洞察：**\n- 未核并非无法观测；通过保留帧指针（`+fp` 编译器）、符号表和工具链支持，即可实现可观测性。\n- 与传统系统相比，未核结构更简单（单一地址空间、无上下文切换），反而使堆栈分析更直接。\n- 当前缺乏成熟工具，但已有原型证明技术路径可行。\n\n**实践建议：**\n- 开发者可在 Unix 模式下使用标准工具（如 `perf`, `strace`）进行调试。\n- 对生产环境中的未核，可通过 `xenctx` + 脚本实现粗粒度采样分析。\n- 更理想的方向是开发 **domU 内部的原生探测器**（类似 Java Flight Recorder），无需依赖 dom0。\n\n**结论：** 未核并非“防火毒”的黑箱，其可观测性虽挑战较大，但通过现有工具与适度开发，完全可实现有效的性能分析。","published_at":"2016-01-27T00:00:00Z"}
{"domain":"brendangregg","path":"https://www.brendangregg.com//blog/2016-01-20/ebpf-offcpu-flame-graph.html","title":"Linux eBPF Off-CPU Flame Graph","summary":"本文介绍了使用**离CPU（Off-CPU）时间火焰图**分析系统性能瓶颈的方法，结合eBPF技术实现高效、低开销的离CPU profiling。\n\n### 核心观点：\n- **CPU火焰图**揭示程序在CPU上执行时的热点函数；\n- **离CPU火焰图**则展示线程因等待资源（如I/O、锁、定时器）而被阻塞的时间，帮助定位延迟根源。\n\n### 关键发现：\n- 在编译内核过程中，`as`、`make` 被文件系统读取（`vfs_read`）阻塞；`gcc` 和 `sh` 等等待子进程完成；多个线程在 `poll` 中等待工作。\n- 多个线程并行阻塞可累积达数百秒的等待时间，即使总运行时间仅30秒。\n\n### eBPF的重要性：\n- 传统方法（如perf_events）在高负载下事件数量可达百万/秒，导致高开销甚至丢包；\n- eBPF可在内核中聚合离CPU时间，仅将汇总结果传给用户空间，极大降低开销，使生产环境可用。\n\n### 工具与实践：\n- 使用 `bcc` 工具集中的 `offcputime` 命令生成离CPU栈数据：\n  ```bash\n  ./offcputime -f 30 \u003e out.offcpustacks01\n  ```\n- 结合 `flamegraph.pl` 生成可视化火焰图。\n- 示例显示 `sleep` 和 `vmstat` 都因等待定时器而阻塞，符合预期。\n\n### 其他工具对比：\n- DTrace、SystemTap 也可实现内核级聚合；\n- 作者曾用 SystemTap 实现过类似功能，但 eBPF 更高效且更易集成。\n\n### 未来方向：\n- 需支持完整的**用户态和内核态栈追踪**（已由 Linux 4.8 实现）；\n- 进一步整合采样与聚合功能，构建统一的性能分析框架；\n- 探索如何更好融合 CPU 与离CPU火焰图（参考“热/冷火焰图”）；\n- 增加对阻塞原因（如文件描述符、互斥锁）的上下文信息。\n\n\u003e ✅ **总结**：通过 eBPF 技术，离CPU时间火焰图已成为实用的性能分析手段，能精准定位阻塞问题，是优化系统延迟的关键工具。","published_at":"2016-01-20T00:00:00Z"}
{"domain":"brendangregg","path":"https://www.brendangregg.com//blog/2016-01-18/ebpf-stack-trace-hack.html","title":"Linux eBPF Stack Trace Hack","summary":"**摘要：**\n\n本文介绍了在 Linux 4.4 中尚未支持堆栈跟踪的 eBPF 环境下，如何通过一个巧妙的“黑客”方案实现内核堆栈追踪功能。作者基于 bcc 工具集开发了两个新工具：\n\n- **`stackcount`**：频率统计特定内核函数（如 `submit_bio`）调用时的堆栈路径，仅将唯一堆栈及其出现次数传回用户空间，高效用于分析高频调用路径。例如，可发现文件重命名触发了 ext4 块分配与写回操作。\n- **`stacksnoop`**：实时打印每次事件发生时的完整内核堆栈，适合低频调试，但不适合高频率调用场景。\n\n**实现原理**：利用 eBPF 在内核中运行自定义堆栈遍历代码（仅限 x86_64 架构），通过手动解析 RBP 寄存器链来获取返回地址，使用 `bpf_probe_read` 安全读取内存，并以展开循环方式限制最大深度（10 层）。该方法为临时替代方案，依赖于内核特定结构。\n\n**对比其他方案**：  \n- ftrace、perf-tools 可打印堆栈但效率较低；  \n- SystemTap 支持堆栈计数但非主线内核模块。\n\n**未来展望**：从 Linux 4.5 起，eBPF 可能原生支持堆栈获取（如 `BPF_FUNC_get_stack`），届时上述复杂代码将被简化为单函数调用。\n\n**适用人群**：系统性能调优工程师、内核开发者、Linux 运维专家，尤其适用于在旧版内核上进行深入内核行为分析。","published_at":"2016-01-18T00:00:00Z"}
{"domain":"brendangregg","path":"https://www.brendangregg.com//blog/2015-12-03/linux-perf-60s-video.html","title":"Linux Performance Analysis in 60s (video)","summary":"本文分享了Netflix在处理系统性能问题时的快速诊断方法，重点介绍在60秒内使用标准Linux命令进行初步分析的流程。尽管多数问题通过其开源工具Atlas和Vector已解决，但该方法仍具普适价值。\n\n关键发现包括：\n- 系统负载稳定，无异常内核错误（dmesg）；\n- 用户态CPU占用率高且均匀分布于所有核心，仍有空闲时间；\n- 内存使用正常，网络吞吐量低但未达瓶颈，无TCP重传；\n- 存在大量活跃连接。\n\n据此，后续应优先排查：  \n1. 使用`perf`与火焰图分析CPU热点；  \n2. 检查活跃连接来源及延迟情况。\n\n内存、磁盘或文件系统I/O可暂缓处理。  \n\n作者还推荐其Velocity 2015大会的90分钟完整教程视频，系统讲解Linux性能分析工具。","published_at":"2015-12-03T00:00:00Z"}
{"domain":"brendangregg","path":"https://www.brendangregg.com//blog/2015-11-06/java-mixed-mode-flame-graphs.html","title":"Java Mixed-Mode Flame Graphs at Netflix, JavaOne 2015","summary":"本文介绍了Netflix在Java性能分析中使用**混合模式火焰图（Java mixed-mode flame graphs）**的实践，基于JDK 8u60新增的`-XX:+PreserveFramePointer`功能，使系统级剖析工具（如Linux perf_events）能准确捕获Java与JVM的栈轨迹。\n\n核心亮点包括：\n- **多维度分析**：可生成针对不同系统事件的火焰图，揭示Java代码触发的关键行为：\n  - **页错误（Page faults）**：定位内存增长根源。\n  - **上下文切换（Context switches）**：识别阻塞原因（如锁、I/O、睡眠）。\n  - **磁盘I/O请求**：追踪引发磁盘操作的代码路径。\n  - **TCP事件**：显示连接建立、数据发送等网络操作的调用链。\n  - **缓存未命中（Cache misses）**：可视化物理内存访问热点，辅助优化内存访问效率。\n  - **CPI火焰图（Cycles Per Instruction）**：以颜色标注指令密度与流水线停顿，红色为高指令量，蓝色为高内存停顿，首次在Linux上实现。\n\n文中强调这些工具完全基于开源软件，可通过自动化脚本（如Netflix的Vector工具）实现一键生成。示例图展示了具体应用效果，例如`AbstractByteBuf.forEachByteAsc0`函数存在指令密集问题。\n\n推荐读者参考作者此前关于“Java in Flames”和“CPI火焰图”的博客，以及相关技术文档，深入了解其原理与实践价值。","published_at":"2015-11-06T00:00:00Z"}
{"domain":"brendangregg","path":"https://www.brendangregg.com//blog/2015-10-31/tcpconnect-tcpaccept-bcc.html","title":"tcpconnect and tcpaccept for Linux (bcc)","summary":"该博客介绍了两个基于eBPF和bcc工具集的Linux内核追踪工具：`tcpconnect` 和 `tcpaccept`，用于实时监控系统中发起的TCP连接和接收的连接。\n\n- **`tcpconnect`** 显示当前进程通过 `connect()` 系统调用建立的出站TCP连接，输出包括进程ID（PID）、程序名（COMM）、IP版本、源地址（SADDR）、目标地址（DADDR）和端口（DPORT）。例如，`curl` 正在连接到公网的80端口服务器。\n- **`tcpaccept`** 显示正在监听并接受入站连接的套接字，输出包含接收方地址（RADDR）、本地地址（LADDR）和端口（LPORT），如SSH服务在22端口监听来自不同客户端的连接。\n\n这些工具并非对所有网络包进行捕获（如tcpdump），而是直接追踪内核中`connect()`和`accept()`函数的调用，因此效率更高、开销更小。它们依赖于Linux 4.1+内核的eBPF功能，由bcc提供Python接口，支持过滤（如指定PID）、时间戳等选项。\n\n作者曾使用DTrace在Solaris上实现类似功能，现在借助eBPF可在Linux上实现更稳定、易用的追踪工具。尽管仍存在与内核版本兼容性相关的局限性，但相比旧有方法（如ftrace）更可靠。未来计划开发更多基于eBPF的TCP/UDP追踪工具。\n\n✅ **适用人群**：系统管理员、性能调优工程师、安全分析师  \n✅ **核心价值**：低开销、实时可见的网络连接行为分析，无需解析全部数据包","published_at":"2015-10-31T00:00:00Z"}
{"domain":"brendangregg","path":"https://www.brendangregg.com//blog/2015-09-22/bcc-linux-4.3-tracing.html","title":"bcc: Taming Linux 4.3+ Tracing Superpowers","summary":"本文介绍了在 Linux 4.3+ 内核中利用 eBPF 技术开发的一系列开源性能分析工具，由 Brendan Gregg 在硅谷 Linux 技术研讨会上演示。这些工具基于 **eBPF（扩展伯克利包过滤器）** 和 **bcc（BPF 编译集合）** 框架，实现了高效、低开销的系统级追踪。\n\n### 核心内容总结：\n- **关键创新**：Linux 4.3 引入了从 eBPF 程序中打印字符串的能力，使复杂追踪成为可能。\n- **eBPF 优势**：可在内核事件触发时执行轻量级程序，实现事件标记、数据聚合、过滤和低延迟上报，显著降低性能损耗。\n- **使用障碍**：直接编写 eBPF 汇编或 C 代码复杂难用，开发者体验差。\n- **解决方案**：**bcc 项目** 提供 Python 前端 + C 后端接口，大幅简化 eBPF 工具开发，支持快速构建如 `biolatency`、`biosnoop`、`opensnoop`、`vfsstat`、`funccount`、`funclatency` 等实用工具。\n\n### 主要工具功能：\n| 工具 | 功能 |\n|------|------|\n| `biolatency` | 统计磁盘 I/O 延迟分布，生成直方图 |\n| `biosnoop` | 追踪每个磁盘读写操作的时间、进程、扇区与字节数 |\n| `opensnoop` | 监控 `open()` 系统调用，显示进程、路径及返回状态 |\n| `vfsstat` | 实时统计 VFS 层操作频率（读/写/创建/打开/同步） |\n| `funccount` | 统计匹配模式的内核函数调用次数（如 `tcp*send*`） |\n| `funclatency` | 测量特定内核函数（如 `tcp_sendmsg`）的调用延迟 |\n\n### 实际价值：\n- 所有工具均开源，位于 bcc 项目 [tools 目录](https://github.com/iovisor/bcc/tree/master/tools)。\n- 相比传统 ftrace 工具（如 perf-tools），新工具具有更低开销、更强功能、更易维护。\n- 可用于生产环境（如 Netflix）的性能诊断与监控，且可集成至其他分析平台（如 Vector）。\n- 未来有望通过包管理器一键安装，进一步提升可用性。\n\n### 展望：\n- 未来将推动 eBPF 与 perf_events、SystemTap 等工具融合，形成统一追踪生态。\n- 将逐步迁移旧工具至 eBPF 架构，并开发更多此前难以实现的新工具。\n\n\u003e ✅ **推荐人群**：系统工程师、运维人员、性能调优专家、Linux 内核开发者。  \n\u003e 🔗 **学习资源**：[bcc GitHub](https://github.com/iovisor/bcc)、[eBPF 官方文档](https://www.iovisor.org/)、作者博客文章《eBPF: One Small Step》。","published_at":"2015-09-22T00:00:00Z"}
{"domain":"brendangregg","path":"https://www.brendangregg.com//blog/2015-08-11/flame-graph-search.html","title":"Flame Graph Search","summary":"该博客介绍了火焰图（Flame Graph）新增的搜索功能，用户可通过搜索关键词（如 `tcp_send`）快速定位性能热点。文中以 `tcp_send` 为例，展示其在内核网络栈中的分布，并指出左上方小调用可能源于不同路径或上下文，鼓励读者点击查看详情。搜索结果以百分比形式显示（如 `tcp_send` 占 59.3%），帮助量化性能瓶颈。\n\n文章强调该功能对理解 Linux 内核及软件内部机制极具价值，尤其适用于性能分析与优化决策。作者引用 Bill Joy 1981 年的性能数据对比，说明此类分解对优先级判断和提速估算的重要性，而传统方法耗时费力，火焰图搜索显著提升了效率。\n\n该火焰图来自 iperf 本地基准测试，通过 `perf record` + `stackcollapse-perf.pl` + `flamegraph.pl` 生成，使用 `sed` 清理无用帧。支持搜索的关键词还包括 `re?cv`、`spin`、`copy`、`xen` 等。工具开源于 [Brendan Gregg 的 FlameGraph 项目](https://github.com/brendangregg/FlameGraph)，并提及类似功能已由 Thorsten Lorenz 在 Web 版界面实现。\n\n最后，作者还推荐阅读其关于混合模式 Java 火焰图的文章（Netflix 技术博客）。  \n**适用人群：系统工程师、性能优化开发者、深入理解内核与应用行为的技术人员。**","published_at":"2015-08-11T00:00:00Z"}
{"domain":"brendangregg","path":"https://www.brendangregg.com//blog/2015-07-08/choosing-a-linux-tracer.html","title":"Choosing a Linux Tracer (2015)","summary":"**《Linux追踪工具：性能分析的魔法》总结**\n\n本文由Brendan Gregg撰写，深入浅出地介绍了Linux系统中各类追踪工具（tracers）的应用与选择策略，强调“追踪是性能分析的魔法”，并为不同角色提供实用建议。\n\n---\n\n### **核心观点**\n- 追踪工具远不止`strace`或`tcpdump`，可深入内核与应用层，实现全面性能洞察。\n- 工具繁多，各有优劣，需根据使用者角色选择合适方案。\n\n---\n\n### **对普通用户（开发者、运维、SRE等）的建议**\n1. **优先掌握 `perf_events`**  \n   - 用于CPU性能剖析，生成火焰图（Flame Graph），直观定位热点函数。\n   - 示例命令：  \n     ```bash\n     perf record -F 99 -a -g -- sleep 30\n     perf script | ./stackcollapse-perf.pl | ./flamegraph.pl \u003e perf.svg\n     ```\n   - 关键难点：确保符号表和堆栈信息完整（参考其在Netflix的实践）。\n\n2. **了解能力边界，以备不时之需**  \n   - 知道追踪能分析文件系统、网络协议、驱动、应用逻辑等，关键时刻可快速引入专家或工具。\n\n3. **推动前端工具发展**  \n   - 倡议企业采购支持Linux追踪的可视化工具（如延迟热力图、点选式界面）。\n   - 推荐使用其开源工具集 `perf-tools`（如 `execsnoop`, `opensnoop`）简化操作。\n\n---\n\n### **对性能/内核工程师的建议**\n需深度掌握追踪技术，推荐以下路径：\n\n#### **推荐策略**\n- **选一个主工具深耕**：如最新版SystemTap（需从源码编译），或采用混合路线：\n  - 优先使用 `ftrace` / `perf_events`\n  - 结合新兴的 `eBPF`（未来主力）\n  - 必要时补足 `SystemTap` / `LTTng`\n\n#### **各工具简评**\n| 工具 | 优势 | 局限 |\n|------|------|------|\n| **ftrace** | 内核原生、功能强大、适合内核调优 | 不支持编程，需后处理 |\n| **perf_events** | 安全、易用、支持采样与性能计数 | 无内核编程能力 |\n| **eBPF** | 高效、安全、未来方向（已集成至4.1+） | 仍在发展中 |\n| **SystemTap** | 功能最全，支持内核编程 | 容易引发崩溃，依赖调试符号 |\n| **LTTng** | 极高采集效率，安全稳定 | 无内核编程，分析依赖事后回放 |\n| **ktap** | 曾有潜力，但因等待eBPF整合而停滞 |\n| **dtrace4linux / OL DTrace** | DTrace移植尝试，功能逐步完善 | 社区活跃度低，许可问题存疑 |\n| **sysdig** | 类似tcpdump语法，支持Lua脚本 | 目前仅限系统调用，缺乏深度探针 |\n\n---\n\n### **未来趋势**\n- `eBPF` 是统一追踪生态的关键，有望整合 ftrace、perf、SystemTap 的能力。\n- 可视化前端（如Netflix的Vector）将极大降低使用门槛。\n\n---\n\n### **推荐读者**\n- 开发者、运维工程师：学习 `perf` + `perf-tools`，掌握火焰图。\n- 性能与内核工程师：深入理解 `ftrace`、`perf`、`eBPF`，按需选用 `SystemTap` / `LTTng`。\n\n\u003e ✅ **一句话总结**：  \n\u003e **“用 `perf` 入门，懂 `eBPF` 未来；普通人看火焰图，专家造工具链。”**","published_at":"2015-07-08T00:00:00Z"}
{"domain":"brendangregg","path":"https://www.brendangregg.com//blog/2015-07-03/hacking-linux-usdt-ftrace.html","title":"Hacking Linux USDT with Ftrace","summary":"该博客探讨了在未修改的 Linux 内核上利用原生 ftrace 和 uprobes 调试用户态静态探针（USDT）的可行性，尽管作者明确警告此方法**不推荐用于生产环境**。\n\n### 核心观点\n虽然 Linux 内建的 ftrace 和 perf_events 不直接支持 USDT，但通过分析二进制文件中的 USDT 探针位置（如 `readelf` 显示的 `nop` 指令地址），可借助 uprobes 进行间接追踪。关键在于：\n- 从 `readelf` 获取探针虚拟地址（如 `0xbf44b4`）\n- 减去基址（如 `0x400000`）得到相对地址（如 `0x7f44b4`）\n- 使用 `uprobe` 工具在该地址设置探针\n\n### 关键技术细节\n1. **探针触发**：将 `nop` 指令作为探针点，因它无副作用且易于定位。\n2. **is-enabled 机制**：部分探针依赖内存中的“信号量”标志位。若未置位，则探针不会触发。可通过写入 `/proc/PID/mem` 手动开启（高风险操作）。\n3. **参数提取**：根据 `readelf` 提供的寄存器/栈偏移信息（如 `8@%rax`、`-136(%rbp)`），使用复杂语法（如 `+0(+0(%ax)):string`）捕获函数参数。\n\n### 安全与替代方案\n作者强调此方法危险性极高，可能引发崩溃或内存损坏。建议采用更安全的方式：\n- 使用 **SystemTap** 或 **LTTng**（官方支持 USDT）\n- 利用 `perf probe` 通过函数偏移追踪（较安全）\n- 追踪父函数或中间“哨兵”函数（动态探针）\n- 等待 perf/events 原生支持（已有进展）\n\n### 总结\n该文展示了在无额外工具情况下，利用内核原生能力“黑箱”访问 USDT 的可能性，是技术探索的证明。但其核心结论是：**应优先使用成熟的工具（如 SystemTap、LTTng、perf）而非手动黑客手法**。未来内核对 USDT 支持将更加完善，无需自行冒险。","published_at":"2015-07-03T00:00:00Z"}
{"domain":"brendangregg","path":"https://www.brendangregg.com//blog/2015-06-28/linux-ftrace-uprobe.html","title":"Linux uprobe: User-Level Dynamic Tracing","summary":"**总结：**\n\n本文介绍了 Linux 内核中的 **uprobes** 功能（自 3.5 版本引入，3.14 优化），这是一种用户态动态追踪技术，允许在不重启程序的情况下实时监控用户空间函数的调用与返回。作者 Brendan Gregg 开发了 `uprobe` 工具（属 `perf-tools` 系列），用于便捷地通过 ftrace 使用 uprobes。\n\n**核心要点：**\n- 可追踪任意运行中进程的函数调用，如 `bash` 的 `readline()` 返回值（命令行输入）或 `libc` 的 `sleep()` 参数。\n- 支持函数入口（`p:`）和返回（`r:`）钩子，可读取寄存器参数（如 `%di`）或返回值（`$retval`）并格式化输出（如字符串）。\n- 提供多种使用方式，包括按进程、路径、符号名或内存地址指定目标，支持条件过滤（如 `file == 0`）。\n- 高风险警告：旧内核（\u003c4.0）可能因 uprobes 导致进程崩溃或死锁；直接使用内存地址时需确保指令对齐，否则会破坏程序执行。\n\n**对比与建议：**\n- `perf probe` 功能更强大、更安全（自动检查对齐、支持 debuginfo），但配置较繁琐。\n- `uprobe` 适合快速实验和探索，而 `perf` 更适合生产环境下的稳定追踪。\n- 推荐先在测试环境尝试，避免影响生产系统。\n\n**适用人群：** 系统性能分析员、内核开发者、运维工程师、调试高手。  \n**价值所在：** 展示了现代 Linux 内核强大的动态追踪能力，是深入理解应用行为、排查疑难问题的利器。","published_at":"2015-06-28T00:00:00Z"}
{"domain":"brendangregg","path":"https://www.brendangregg.com//blog/2015-06-23/netflix-instance-analysis-requirements.html","title":"Netflix Instance Analysis Requirements","summary":"当前大多数实例分析与监控工具仍停留在20年前的水平，仅提供如sar命令中的基础指标（如负载平均、CPU使用率、磁盘IOPS和延迟），以折线图形式展示，缺乏创新。作者指出，尽管这些指标仍有价值，但已成标配，行业亟需更先进的系统级监控能力。\n\n在Monitorama 2015大会上，Netflix分享了其对实例分析工具的真正需求：超越传统指标，引入如**延迟热力图、火焰图（Flame Graphs）、系统调用追踪、性能瓶颈可视化**等前沿分析手段。这些能力能揭示深层次性能问题，而非仅显示“表象数据”。\n\n作者强调，客户不应被动接受现有产品，而应主动提出更高要求。他本人及团队已将火焰图等技术整合进自研工具Vector，并开源perf-tools用于深度系统分析。\n\n总结：  \n- **核心观点**：监控工具需从“展示旧指标”转向“发现新问题”，实现质变。  \n- **关键洞察**：企业应推动厂商开发如延迟热图、火焰图等高级可视化工具。  \n- **实践建议**：可借鉴Netflix经验，采用火焰图、向量分析等方法提升运维效率。  \n- **推荐人群**：云平台工程师、SRE、系统架构师及关注性能优化的技术决策者。","published_at":"2015-06-23T00:00:00Z"}
{"domain":"brendangregg","path":"https://www.brendangregg.com//blog/2015-05-15/ebpf-one-small-step.html","title":"eBPF: One Small Step","summary":"本文介绍了 eBPF（扩展伯克利数据包过滤器）在 Linux 性能追踪中的突破性应用，作者通过自制工具 `bitehist` 和 `bitesize` 展示了如何利用 eBPF 实现高效、低开销的磁盘 I/O 活动分析。\n\n**核心要点：**\n- **eBPF 是一项革命性技术**：它允许在内核中安全运行用户定义的字节码程序（如 kprobe），实现动态、低延迟的性能追踪，且不会导致系统崩溃或干扰。\n- **关键组件：eBPF maps**：这些映射结构可在内核中存储数据（如直方图、计数、延迟统计），并由用户空间程序异步读取。文中使用数组和哈希表分别实现按大小和 PID 分组的 I/O 分布统计。\n- **实际效果**：`bitehist` 显示大部分磁盘 I/O 为 4–7 KB，小部分为 32–63 KB；`bitesize` 进一步按进程显示数据，揭示特定进程（如 `cksum`）存在大块 I/O。\n- **代码复杂度与未来趋势**：当前需用 C 编写数百行代码，但已有模板化趋势，未来可能通过高级语言前端（如类似 DTrace）简化开发。\n- **前景广阔**：eBPF 将推动性能分析工具升级，支持热力图、实时延迟监控等高级功能，并有望集成到 perf、ktap、shark 等主流工具中。\n\n**总结**：虽然单个工具看似微小，但 eBPF 所带来的内核级可观测能力是一次“巨人般的飞跃”，标志着 Linux 性能分析进入新纪元。","published_at":"2015-05-15T00:00:00Z"}
{"domain":"brendangregg","path":"https://www.brendangregg.com//blog/2015-05-15/dtracetoolkit-has-ended.html","title":"The DTraceToolkit Project Has Ended","summary":"Brendan Gregg 宣布停止维护 DTraceToolkit 项目，该项目始于2005年，曾为 Solaris、OS X、FreeBSD 等系统提供强大的性能分析工具。尽管其脚本仍被广泛集成在多个系统中，但因各操作系统内核频繁变化（尤其是 syscall provider 的变动），原230个脚本已难以跨版本稳定运行。\n\n他指出，项目的失败根源在于试图用一套工具适配所有平台和内核版本，这在现实中不切实际。2013年起，他提出“双轨”方案：**轻量级工具集**（供普通用户使用）与**工具棚**（供性能工程师参考和开发）。然而，2014年他转投 Linux 性能领域，专注于 eBPF、perf_events 等新技术，不再有精力维护 DTraceToolkit。\n\n他已在 FreeBSD 上发布新工具集 [DTrace-tools]，并基于 Linux ftrace 和 perf 工具创建了 [perf-tools]，延续了 DTraceToolkit 的精神。他认为《DTrace Book》是该项目的真正升级版（2.0）。\n\n最终，他将项目归档至个人存档库，并关闭旧博客，迁往新博客。他感谢社区支持，也明确表示：**不应再继续推进 DTraceToolkit 项目**。","published_at":"2015-05-15T00:00:00Z"}
{"domain":"brendangregg","path":"https://www.brendangregg.com//blog/2015-04-30/se-radio-systems-performance.html","title":"SE-Radio Episode 225: Systems Performance","summary":"作者布伦丹·格雷格（Brendan Gregg）分享了自己在加州通勤期间，利用长时间交通时间收听《Software Engineering Radio》播客的经历，并借此机会受邀录制了第225期节目，主题为“系统性能”（Systems Performance）。节目中，他与主持人罗伯特·布卢门（Robert Blumen）深入探讨了系统性能的本质、分析方法及云环境下的挑战，内容源自其著作《系统性能优化》（Sysperfbook）。作者强调播客形式的优势：口语化表达、语调强调和即时互动问答，更易于理解复杂概念。\n\n他还推荐了其他几期值得收听的优质播客，涵盖埃拉姆语言（Erlang）、机械同感（Mechanical Sympathy）、Go语言、分布式系统以及现代云平台等前沿技术话题。\n\n**总结要点：**  \n- 通勤时通过播客学习系统性能知识，促成受邀录制节目。  \n- 节目核心：系统性能定义、分析方法与云环境挑战。  \n- 播客优势：对话式讲解，更具表现力与互动性。  \n- 推荐系列：涵盖高性能编程、分布式系统与云架构的深度访谈。  \n\n**适合读者：** 系统工程师、开发者、运维人员及对性能优化感兴趣的科技从业者。","published_at":"2015-04-30T00:00:00Z"}
{"domain":"brendangregg","path":"https://www.brendangregg.com//blog/2015-03-17/usenix-lisa-2014-linux-ftrace-perf-tools.html","title":"USENIX/LISA 2014 New Tools and Old Secrets (perf-tools)","summary":"**总结：**\n\n作者在USENIX/LISA大会上介绍了其开源工具集 **perf-tools**，该工具基于Linux内核内置的 `ftrace` 和 `perf_events` 框架，用于高效分析系统性能。这些工具无需额外安装，已默认包含在主流Linux发行版（如Netflix云实例）中。\n\n核心亮点包括：\n- **ftrace 被视为“被遗忘的宝藏”**：由Steven Rostedt开发，功能强大但宣传不足，perf-tools旨在通过实际案例提升其可见度。\n- **典型工具示例**：\n  - `iosnoop`：类似tcpdump的磁盘I/O追踪器，可发现异常延迟（如14.9ms的元数据读取），帮助定位性能瓶颈。\n  - `funccount 'ip*'`：统计以“ip”开头的内核函数调用次数，揭示网络栈行为。\n  - `kprobe`：可捕获函数调用栈（如从`write()`到`ip_output`的路径），支持参数查看与低开销追踪。\n- **设计理念**：遵循Unix哲学——单一职责、简洁高效；部分高级工具需一定专业知识，但能力更强。\n- **未来展望**：期待eBPF技术成熟后，将重构工具以实现内核级计算（如I/O延迟），降低开销并提升性能。\n- **会议体验**：虽因与AWS re:Invent冲突迟到，但仍参与了多场精彩演讲，并与社区互动，计划2015年重返LISA。\n\n**适用人群**：系统管理员、DevOps工程师、性能调优专家及对Linux内核级监控感兴趣的开发者。","published_at":"2015-03-17T00:00:00Z"}
{"domain":"brendangregg","path":"https://www.brendangregg.com//blog/2015-03-12/freebsd-offcpu-flame-graphs.html","title":"FreeBSD Off-CPU Flame Graphs","summary":"**摘要：**\n\n本文介绍了如何利用 FreeBSD 的 `procstat -ka` 命令收集线程睡眠时的调用栈，进而生成 **off-CPU 火焰图**，用于分析系统性能瓶颈。与传统基于事件追踪（如 perf_events）的方法相比，该方法通过定时采样所有睡眠线程的栈信息，显著降低开销——仅依赖线程数量而非调度事件频率，适合生产环境使用。\n\n关键点包括：\n- **原理**：每秒定时采集 `procstat -ka` 输出的内核栈信息，经文本处理后输入 FlameGraph 工具生成可视化火焰图，展示线程在等待 I/O、锁、队列等阻塞状态下的调用路径。\n- **优势**：相比全量事件追踪，采样开销更低（约 4,500 次/秒，8核系统），更适用于高负载场景。\n- **增强功能**：可通过 `awk` 提取进程名和线程名，生成带细粒度标识的火焰图，识别线程池行为（如 ZFS、nginx 多线程）。\n- **局限性**：当前 `procstat -ka` 仅支持内核栈，无用户态帧；且符号查找效率低（串行遍历符号表），导致单次执行耗时达 1.27 秒，难以高频采样。\n- **优化建议**：引入二叉树索引、提前终止匹配或在内核中实现采样聚合机制，可大幅提升性能。\n\n**结论**：FreeBSD 已具备实用的 off-CPU 性能分析能力，值得推广至 Linux 等其他系统。未来应改进 `procstat` 实现，使其成为轻量级、高效的阻塞时间剖析工具。","published_at":"2015-03-12T00:00:00Z"}
{"domain":"brendangregg","path":"https://www.brendangregg.com//blog/2015-03-10/freebsd-flame-graphs.html","title":"FreeBSD Flame Graphs","summary":"本文介绍了在 FreeBSD 开发者与供应商峰会上关于“FreeBSD 上的火焰图（Flame Graphs）”的演讲，重点展示如何使用火焰图分析 CPU、内存、磁盘 I/O、离 CPU 等性能数据，并通过实时演示说明其应用。作者 Brendan Gregg 强调火焰图是高效定位性能瓶颈的强大工具，尤其适用于 Netflix Open Connect Appliance（OCAs）中的优化分析。\n\n文中提供了生成火焰图的具体命令：  \n- 使用 DTrace 采集内核栈信息，生成 CPU 火焰图；  \n- 使用 pmcstat 采集资源停顿（如内存延迟），生成停顿周期火焰图（如 CPI 火焰图），直观反映处理器是执行指令还是因等待而停滞。\n\n火焰图可自动化部署于 OCAs，支持非回归性能分析。作者认为本次 50 分钟演讲比之前的 90 分钟长篇讲座更高效，适合技术深度用户。后续还将分享基于 `procstat` 的离 CPU 火焰图新方法。\n\n**核心价值**：火焰图是系统性能分析的可视化利器，尤其适合深入排查复杂性能问题，且可在 FreeBSD 上轻松实现。推荐给系统工程师、性能调优人员及对底层优化感兴趣的开发者。","published_at":"2015-03-10T00:00:00Z"}
{"domain":"brendangregg","path":"https://www.brendangregg.com//blog/2015-03-06/performance-analysis-bsd.html","title":"MeetBSD CA: Performance Analysis of BSD","summary":"本文作者在MeetBSD CA大会上分享了题为《性能分析》的演讲，系统梳理了性能分析的五大核心维度：可观测性工具、方法论、基准测试、剖析（profiling）与跟踪（tracing）。重点介绍了FreeBSD在性能分析方面的领先优势，尤其是其强大的工具链：`pmcstat(8)`用于CPU性能监控计数器分析，以及DTrace支持静态与动态追踪。\n\n作者展示了自制的FreeBSD可观测性工具图谱和PMC分组图，强调其比Linux的`perf_events`更完整、易用，而后者常需查阅英特尔手册手动配置计数器，效率较低。文中还通过DTrace动态追踪GEOM模块，演示了如何绕过DTrace `io`提供者中的结构体转换缺陷，精准测量存储I/O大小，结果显示大多数I/O集中在1-2MB，解释了低延迟表现，适用于流媒体场景。\n\n此外，作者开源了为Netflix Open Connect Appliances编写的DTrace脚本集（[DTrace-tools](https://github.com/brendangregg/DTrace-tools)），并感叹BSD社区氛围友好、放松，远胜于部分紧张的Linux社群。最后预告将发布关于FreeBSD火焰图的后续内容。  \n\n**推荐人群**：系统工程师、性能调优开发者、自由软件爱好者，尤其关注BSD系统性能分析者。","published_at":"2015-03-06T00:00:00Z"}
{"domain":"brendangregg","path":"https://www.brendangregg.com//blog/2015-03-03/performance-tuning-linux-instances-on-ec2.html","title":"Performance Tuning Linux Instances on EC2","summary":"本文分享了Netflix性能与可靠性工程团队在AWS re:Invent上关于“EC2实例性能调优”的演讲内容，涵盖实例选型、EC2特性、Linux内核调优及可观测性实践。作者强调，调优应基于可观测性发现瓶颈，而非盲目操作。\n\n文中列出了针对Ubuntu Trusty（2014年环境）的多项内核参数调优配置，包括CPU调度、虚拟内存、大页、文件系统、存储I/O、网络和Xen虚拟化层（如切换时钟源为TSC，实现30% CPU降低和43%延迟减少）。但作者特别警告：这些设置已过时，仅作历史参考，不建议直接复制使用。\n\n核心观点：调优是持续过程，需结合具体场景和环境，如同“药柜”，不能照搬他人旧方。推荐观众观看视频获取完整上下文，并关注后续更新（如OpenJDK火焰图修复方案）。\n\n适合对象：运行Linux云服务的工程师，尤其关注性能优化与系统调优者。","published_at":"2015-03-03T00:00:00Z"}
{"domain":"brendangregg","path":"https://www.brendangregg.com//blog/2015-02-28/from-dtrace-to-linux.html","title":"Tracing Summit 2014: From DTrace To Linux","summary":"**总结：**\n\n本文作者布伦丹·格雷格（Brendan Gregg）在2014年杜塞尔多夫追踪峰会上的演讲中，探讨了DTrace为何能在系统可观测性领域取得成功，以及Linux可从中吸取的经验教训。尽管如今Linux的ftrace和perf_events已具备与DTrace相似的功能，但其普及程度远不及DTrace，原因不仅在于技术本身，更在于**营销、社区建设和推广策略**。\n\n关键洞察：\n- **DTrace的成功不仅是技术优势**，更是得益于Sun Microsystems投入大量资源进行市场推广、培训、撰写易用脚本、培养技术布道者，并建立活跃社区。\n- 相比之下，Linux的追踪工具长期缺乏企业级推广，主要依赖开发者自发传播，导致许多用户甚至不知其存在。\n- 作者强调：**技术再好，若无人知晓，也难被采用**。因此，开源社区应主动通过博客、会议演讲、社交媒体分享使用案例，推动技术传播。\n\n实践建议：\n- 开发者和贡献者应积极参与社区（如linux-perf-users邮件列表）、发布工具（如perf-tools）、撰写文档和博客，提升可见度。\n- 虽无大公司背书，但可通过个人影响力构建生态。\n\n结语：Linux要追赶并超越DTrace，需补上“非技术”短板——即**传播力与社区建设**。技术是基础，但传播才是扩散的关键。","published_at":"2015-02-28T00:00:00Z"}
{"domain":"brendangregg","path":"https://www.brendangregg.com//blog/2015-02-27/linux-profiling-at-netflix.html","title":"SCALE13x: Linux Profiling at Netflix","summary":"本文介绍了在南方加州Linux博览会（SCALE 13x）上关于使用`perf_events`（简称`perf`）进行Linux性能分析的演讲内容。核心要点如下：\n\n- **目标**：实现高效、完整的CPU性能分析，尤其针对Java和Node.js等复杂运行时环境。\n- **关键挑战**：栈帧和符号解析问题，需对OpenJDK进行补丁以修复帧指针，相关补丁已提交至JDK-8068945，并呼吁未来版本支持`-XX:MoreFramePointer`选项。\n- **强大功能**：`perf`可异步采样，覆盖从内核到JVM内部、系统库及应用代码的完整调用栈，能发现传统工具无法检测的问题（如JVM编译器耗时过高）。\n- **亮点展示**：嵌入式混合模式火焰图（flame graph）清晰呈现Java程序的全栈CPU占用情况，极具洞察力。\n- **实用命令**：提供一系列`perf`常用命令，涵盖事件计数、堆栈采样、静态与动态追踪等场景。\n- **资源推荐**：演讲视频（双机位）、幻灯片（SlideShare）、官方文档与`perf` Wiki。\n\n适用人群：系统工程师、性能优化开发者、运维人员，特别是使用Java服务的团队。即使不关注Java，该演讲也对理解底层性能分析有重要价值。","published_at":"2015-02-27T00:00:00Z"}
{"domain":"brendangregg","path":"https://www.brendangregg.com//blog/2015-02-26/linux-perf-off-cpu-flame-graph.html","title":"Linux perf_events Off-CPU Time Flame Graph","summary":"**摘要：**\n\n本文介绍了如何使用 Linux `perf_events` 工具生成**Off-CPU 时间火焰图**，用于分析程序因阻塞（如等待 I/O、锁、睡眠）导致的性能瓶颈，这是传统 CPU 火焰图无法覆盖的场景。关键点如下：\n\n- **核心概念**：Off-CPU 分析通过追踪线程被调度器阻塞和唤醒的时间点，统计其“休眠”时间，从而定位延迟根源。\n- **实现方法**：利用 `perf record` 记录 `sched:sched_stat_sleep` 等事件，配合 `perf inject` 与 `perf script` 提取数据，经 `stackcollapse.pl` 和 `flamegraph.pl` 处理生成火焰图。\n- **简化流程**：自内核 3.17 起，`perf script -f period` 可直接输出周期信息，减少处理步骤。\n- **注意事项**：\n  - 高频调度事件可能带来显著性能开销，不适用于生产环境，建议仅用于调试或限制目标 PID。\n  - 内核需开启 `CONFIG_SCHEDSTATS`，且从 4.5 起需启用 `/proc/sys/kernel/sched_schedstats`。\n- **进阶方案**：自 Linux 4.6 起，可通过 eBPF（如 BCC 工具集中的 `offcputime`）在内核中聚合栈信息，大幅降低开销，效率更高。\n\n**适用人群**：系统性能调优工程师、内核开发者、运维人员。  \n**推荐工具**：优先使用 eBPF 版本（如 `offcputime`）以获得高效、低侵入的监控能力。","published_at":"2015-02-26T00:00:00Z"}
{"domain":"brendangregg","path":"https://www.brendangregg.com//blog/2015-01-20/working-at-netflix.html","title":"Working at Netflix","summary":"本文是一位在Netflix工作数月的性能架构师对公司的深度体验分享，核心内容如下：\n\n**核心观点**：Netflix的文化真实且高效，远超多数公司“口号式”的文化宣传，其“自由与责任”原则真正落地，驱动创新与高绩效。\n\n**关键亮点**：\n- **招聘严谨透明**：流程快速、匹配精准，强调双向适配；薪酬公开透明，基于市场数据制定“行业顶尖”薪资，鼓励员工了解自身价值。\n- **文化真实可信**：公司文化并非空谈，而是通过《文化手册》（Culture Deck）提前传递理念。核心是“自由与责任”——员工有自主权做正确的事，但必须承担后果。拒绝“愚蠢问题无法解决”的惯性思维，杜绝官僚内斗、问责缺失、救火文化等常见问题。\n- **人才标准极高**：只招聘成熟、自律、高绩效的专业人士，明确排斥“天才型混蛋”（brilliant jerks），强调协作与责任感。\n- **高性能工程实践**：在超大规模云环境（5000万用户、全球1/3夜间流量）中推动前沿技术，涉及AWS、Linux、FreeBSD、eBPF、Java优化、自研工具（如Atlas、rxNetty、Vector）及硬件性能分析。工程师拥有高度自主权，可探索短期与长期技术突破。\n- **使命清晰正直**：目标是打造用户主动选择的产品，而非利用隐私或营销手段获利，强调商业诚信。\n\n**总结**：Netflix的成功不仅源于技术挑战，更在于其可复制的正向文化设计——用专业、透明与信任构建高效组织。适合追求自主、成长与影响力的工程师，但不适合习惯管控与安逸环境的人。作者呼吁行业反思并借鉴这种“工程化文化”的可能性。","published_at":"2015-01-20T00:00:00Z"}
{"domain":"brendangregg","path":"https://www.brendangregg.com//blog/2014-12-31/linux-page-cache-hit-ratio.html","title":"Linux Page Cache Hit Ratio","summary":"**总结：**\n\n本文介绍了一个用于监控 Linux 系统页缓存命中率的工具 `cachestat`，由 Brendan Gregg 开发并集成至其 [perf-tools](https://github.com/brendangregg/perf-tools) 项目中。该工具通过动态追踪内核函数（如 `mark_page_accessed`、`add_to_page_cache_lru` 等）来统计缓存命中、未命中和脏页情况，实时输出缓存命中率、缓冲区与页缓存大小等指标。\n\n关键点包括：\n- **核心用途**：解决性能问题时发现页缓存命中率下降是根本原因，传统方法（如 iostat、drop_caches）不够精准或有副作用。\n- **工作原理**：利用 ftrace 跟踪四个关键内核函数，区分读写操作，计算命中率（命中数 / 总访问数），并结合页面插入与脏页信息提高准确性。\n- **使用示例**：通过 `echo 1 \u003e /proc/sys/vm/drop_caches; cksum 80m` 模拟缓存清空后读取大文件，可清晰观察到命中率从 3.6% 跳升至 100%。\n- **局限性**：存在约 2% 的性能开销，可能引发内核冻结；对不同内核版本兼容性差，需调整函数名；结果为近似值，依赖测试验证。\n- **替代方案对比**：相比 SystemTap 脚本（如 cache-hit-rate.stp）或 sar/iostat，`cachestat` 更直接、低延迟，但覆盖范围受限。\n- **未来期望**：呼吁内核原生支持页缓存统计（如 `/proc/meminfo` 扩展或 tracepoints），以实现更可靠、易用的监控能力。\n\n**推荐人群**：系统性能调优工程师、内核开发者、运维人员及对底层系统行为感兴趣的开发者。  \n**一句话总结**：`cachestat` 是一个基于 ftrace 的轻量级工具，可有效测量页缓存命中率，帮助诊断性能瓶颈，但当前版本依赖特定内核，适合技术深度使用者。","published_at":"2014-12-31T00:00:00Z"}
{"domain":"brendangregg","path":"https://www.brendangregg.com//blog/2014-11-22/linux-perf-tools-2014.html","title":"Linux Performance Tools 2014","summary":"本文是Brendan Gregg在2014年LinuxCon Europe大会上关于Linux性能工具的演讲总结。他更新了其广受认可的“性能可观测性工具”图谱，新增了`rdmsr(1)`命令，源于他对EC2中MSR（Model-Specific Registers）用途的研究发现。本次演讲重点介绍了四大类性能工具：可观测性、基准测试、调优及新增的**静态性能调优工具**。\n\n静态调优关注系统在无负载情况下的配置状态，如文件系统使用率、路由表、网络接口自动协商等，这类问题通常难以通过动态监控发现。这一补充使性能分析框架更完整。\n\n他还分享了会场其他精彩演讲：Ben Maurer（Facebook）关于用户空间扩展的深度实践；Steven Rostedt（Red Hat）关于ftrace内核钩子的高技术含量演讲；以及Rikki Endsley关于开源社区社交媒体传播的见解。尽管部分演讲未录影，但整体内容极具价值。\n\n演讲幻灯片与视频已发布于SlideShare和YouTube，相关资料可访问作者个人网站和linuxperf页面。文章强调：通过系统化了解现有工具，将“未知的未知”变为“已知的未知”，提升性能问题排查效率。","published_at":"2014-11-22T00:00:00Z"}
{"domain":"brendangregg","path":"https://www.brendangregg.com//blog/2014-11-09/differential-flame-graphs.html","title":"Differential Flame Graphs","summary":"**总结：**\n\n本文介绍了一种高效定位CPU性能回归问题的工具——**红蓝差分火焰图（Red/Blue Differential Flame Graphs）**，由Brendan Gregg提出。传统方法需手动对比前后两个火焰图，效率低且易遗漏细节；而差分火焰图通过颜色直观展示两次采样之间的变化：\n\n- **红色**表示函数在“之后”样本中占比上升（性能恶化），  \n- **蓝色**表示占比下降（性能改善），  \n- 图形宽度基于“之后”样本，保留当前热点结构，便于快速定位。\n\n该方法适用于代码变更、系统更新后的性能回归分析。作者提供了一个开源工具链（`difffolded.pl` + `flamegraph.pl`），支持`perf`等性能分析工具，实现自动化生成。关键特性包括：\n- `-n`选项可归一化负载差异，避免因整体负载变化导致误判；\n- `-x`选项去除地址符号差异干扰；\n- 支持**反向差分**（`--negate`），用于显示“若未改变会怎样”，帮助发现被移除的代码路径；\n- 可选显示“已消失函数”的比例（“X% elided”），点击后查看详细信息，提升可读性与性能。\n\n此外，文章还提及类似技术如CPI火焰图（区分指令与停顿周期）、其他差分方案（如仅显示差异的着色法、三视图对比法），并建议未来可融合多种方式。\n\n**适用场景**：持续集成中的非回归测试、复杂系统性能调优、快速诊断性能波动。  \n**推荐人群**：系统工程师、性能优化开发者、运维团队。","published_at":"2014-11-09T00:00:00Z"}
{"domain":"brendangregg","path":"https://www.brendangregg.com//blog/2014-10-31/cpi-flame-graphs.html","title":"CPI Flame Graphs: Catching Your CPUs Napping","summary":"**摘要：**\n\n本文介绍了一种通过**CPI火焰图（Cycles-Per-Instruction Flame Graph）**可视化CPU实际工作状态的新方法，突破了传统高CPU使用率误导性认知——即高占用不等于高效执行，可能只是等待资源的“停顿”。\n\n- **核心洞察**：仅看CPU利用率无法判断性能瓶颈。真正关键的是**平均每条指令所需周期数（CPI）**，CPI越高，说明CPU在等待内存等资源（“停顿周期”）的时间越长。\n- **创新可视化**：基于差分火焰图技术，将函数调用栈按时间宽度显示，颜色反映其执行效率：**蓝色表示高CPI（大量停顿），红色表示低CPI（高效执行）**。\n- **实现方式**：\n  - 使用FreeBSD的`pmcstat(8)`工具采集两个计数器数据：`CPU_CLK_UNHALTED.THREAD_P`（总周期）和`RESOURCE_STALLS.ANY`（停顿周期）。\n  - 通过`stackcollapse-pmc.pl`和`difffolded.pl`处理数据，生成带颜色的差分火焰图。\n- **实战示例**：展示FreeBSD内核的CPI火焰图，发现`vm_page_alloc`等虚拟内存函数为高停顿热点，而`__mtx_lock_sleep`为高效自旋锁，提示优化方向。\n- **实用价值**：帮助开发者与系统管理员精准定位性能瓶颈（是计算密集还是内存延迟），实现更有效的性能调优。\n- **工具链**：全部基于开源的[FlameGraph](https://github.com/brendangregg/FlameGraph)工具集，支持Linux/FreeBSD。\n\n\u003e ✅ **推荐人群**：系统性能分析员、内核开发者、高并发应用工程师。  \n\u003e 🔍 **关键收获**：别再被“高CPU”吓到，学会看“颜色”，才能看清真实瓶颈。","published_at":"2014-10-31T00:00:00Z"}
{"domain":"brendangregg","path":"https://www.brendangregg.com//blog/2014-09-27/from-clouds-to-roots.html","title":"From Clouds to Roots: Performance Analysis at Netflix","summary":"Netflix、Google 和 Facebook 等公司通过系统性方法进行云环境下的根因性能分析，尽管它们大量使用 Linux，但并未依赖 SystemTap 等传统追踪工具。在 EC2 的 Xen 虚拟化环境中，由于无法直接访问 CPU 计数器，他们采用间接手段实现低层级性能剖析，如利用内核级工具（如 `perf`）结合云端监控数据，配合火焰图（flame graphs）和延迟热力图（latency heat maps）等可视化技术定位瓶颈。\n\n该博客总结了 Netflix 在“从云到根因”层面的性能分析框架：  \n- **云层工具**：通过集中式监控识别异常实例；  \n- **实例层工具**：在虚拟机内部使用 `perf`、`eBPF` 等技术进行低延迟、高精度的性能采样与分析，即使在受限环境下也能获取关键指标。\n\n关键洞察：  \n- 并非所有团队都需亲自做底层分析，但应意识到其可行性；  \n- 可通过三类路径实现：专业性能团队（A）、自身具备能力（B），或选用支持低层分析的监控产品（如 Circonus、AppNeta），Netflix 自研的 Vector 也正致力于此。\n\n核心建议：推动监控产品向“易用的低层分析”演进，让性能问题可被精准诊断。  \n推荐读者参考 Brendan Gregg 的 [perf-tools](https://github.com/brendangregg/perf-tools) 和 [msr-cloud-tools](https://github.com/brendangregg/msr-cloud-tools) 项目，以及前一年的优秀演讲（Coburn Watson）以深化理解。","published_at":"2014-09-27T00:00:00Z"}
{"domain":"brendangregg","path":"https://www.brendangregg.com//blog/2014-09-17/node-flame-graphs-on-linux.html","title":"node.js Flame Graphs on Linux","summary":"该博客介绍了如何在 Linux 环境下为 Node.js 应用生成性能火焰图（Flame Graph），以定位性能瓶颈。核心要点如下：\n\n- **问题**：传统 `perf_events` 虽能采集堆栈信息，但无法解析 V8 引擎的 JIT 编译代码，导致 JavaScript 层符号缺失（显示为空白）。\n- **解决方案**：\n  - 利用 Linux `perf_events` 的 JIT 符号支持，通过在 `/tmp/perf-PID.map` 中写入符号映射文件实现符号解析。\n  - 使用 V8 的 `--perf-basic-prof` 参数（已集成于 Node.js v0.11.13+），自动输出 JIT 符号信息到 map 文件。\n- **使用流程**：\n  1. 启动 Node.js 进程并启用 `--perf-basic-prof`。\n  2. 用 `perf record` 采样堆栈。\n  3. 用 `stackcollapse-perf.pl` 和 `flamegraph.pl` 生成可视化火焰图。\n- **关键成果**：火焰图可清晰显示 JavaScript 函数调用栈，便于分析性能热点。\n- **警告**：原始 `--perf-basic-prof` 会导致 map 文件无限增长（因符号地址变动），存在内存风险。\n- **改进方案**：2016 年引入 `--perf-basic-prof-only-functions`，仅记录关键函数符号，显著减少文件体积。\n\n**适用人群**：运维、后端开发、性能优化工程师。  \n**推荐工具**：[FlameGraph](http://github.com/brendangregg/FlameGraph)、[stackvis](https://www.npmjs.org/package/stackvis)。","published_at":"2014-09-17T00:00:00Z"}
{"domain":"brendangregg","path":"https://www.brendangregg.com//blog/2014-09-15/the-msrs-of-ec2.html","title":"The MSRs of EC2","summary":"**摘要：**\n\n本文作者通过实验验证了在 AWS EC2（Xen 虚拟机）中可访问 Intel 处理器的 **模型特定寄存器（MSRs）**，并成功检测到 **Turbo Boost 正在运行**——其主频从标称的 2.5 GHz 提升至 2.9 GHz。  \n\n关键发现：\n- 使用 `rdmsr` 工具读取 `MSR_TURBO_RATIO_LIMIT1`（0x1ae）可获取当前核心数下的动态加速比。\n- 通过 `./cputemp` 工具监测温度，显示 CPU 温度在 60–70°C 之间，属于较冷状态，支持持续超频。\n- 在未开启性能计数器（PMCs）的 EC2 环境下，这些 MSRs 是唯一能直接测量真实时钟频率的方法。\n\n为何重要？\n- Turbo Boost 可导致性能波动超过 10%，严重影响性能对比结果。\n- 传统方法如关闭 BIOS Turbo Boost 无法在云环境中实现；而通过 MSRs 测量，可精准还原真实运行频率，提升分析准确性。\n\n安全警示：\n- 作者公开分享后，意外触发了 **AWS 全球重启事件（2014 年 9 月）**，原因是其披露内容与当时曝光的 Xen 安全漏洞（CVE-2014-7188）相关。\n- 之后 AWS 限制了部分 MSRs 的访问权限，包括温度读取功能。\n\n结论：\n- 少量关键 MSRs（如温度、加速比）在 AWS EC2 中仍可用，可用于精确性能分析。\n- 工具已开源至 [msr-cloud-tools](https://github.com/brendangregg/msr-cloud-tools)，但需根据具体处理器型号调整寄存器地址。\n- 建议未来发现类似底层机制时，优先联系 AWS 安全团队，避免意外影响系统稳定性。\n\n\u003e ✅ **适用人群**：云性能调优工程师、系统架构师、云计算开发者、安全研究人员。","published_at":"2014-09-15T00:00:00Z"}
{"domain":"brendangregg","path":"https://www.brendangregg.com//blog/2014-09-11/perf-kernel-line-tracing.html","title":"Kernel Line Tracing: Linux perf Rides the Rocket","summary":"**总结：**\n\n本文讲述了一个在AWS EC2云实例中因Ubuntu Trusty系统出现网络包丢失问题，触发“skb rides the rocket”内核警告的排查过程。该警告源于Xen虚拟网卡驱动`xennet`在处理数据包时，碎片页数超过限制（16页），导致包被丢弃。\n\n作者利用Linux `perf_events` 工具对内联函数 `xennet_count_skb_frag_slots` 进行动态追踪，即使该函数无符号信息（未导出）也能通过其入口点（`xennet_start_xmit+88`）成功设点，并获取关键变量如 `pages`、`size`。为避免在生产实例中安装庞大的内核调试信息（debuginfo），作者提出“参考实例”策略：仅在一个带debuginfo的测试机上分析并提取探针配置，再将注册表达式复制到无debuginfo的生产环境使用。\n\n最终通过 `perf record` 和 `perf script` 捕获了大量数据包大小与页数信息，确认问题由TCP分段卸载（TSO）引发的大包导致。解决方案是关闭TSO：`ethtool -K eth0 tso off`。\n\n**核心要点：**\n- “skb rides the rocket” 是因数据包碎片过多导致丢包。\n- `perf probe` 可在无debuginfo环境下通过函数偏移和寄存器映射实现精准内核追踪。\n- 推荐使用“参考实例”方法规避调试包体积大、部署慢的问题。\n- 该技术适用于性能调优与复杂内核问题诊断，但需注意高开销和潜在稳定性风险。\n\n**适用人群：** 系统工程师、云平台运维、内核性能调优开发者。","published_at":"2014-09-11T00:00:00Z"}
{"domain":"brendangregg","path":"https://www.brendangregg.com//blog/2014-09-06/linux-ftrace-tcp-retransmit-tracing.html","title":"Linux ftrace TCP Retransmit Tracing","summary":"**总结：**\n\n本文介绍了一个名为 `tcpretrans` 的高效工具，用于诊断 Linux 系统中的 TCP 重传问题。该工具基于 ftrace 和 kprobes 动态追踪内核函数 `tcp_retransmit_skb()`，仅在发生重传时记录数据，**几乎无性能开销**，避免了传统抓包工具（如 tcpdump）在高流量下的性能瓶颈。\n\n关键亮点：\n- **精准定位**：可显示重传的源/目标地址、端口及连接状态（如 ESTABLISHED）。\n- **内核上下文**：通过 `-s` 选项获取触发重传的内核调用栈，区分“快速重传”（fast retransmit）与“定时器重传”（timer-based retransmit）。\n  - 快速重传由收到重复 ACK 触发，延迟低（通常为微秒级）。\n  - 定时器重传依赖 1 秒级超时，对应用响应影响更大。\n- **性能优化设计**：不实时读取 `/proc/net/tcp`，而是每秒读取一次，避免高频访问大连接表带来的高 CPU 消耗。\n- **生产环境友好**：无需内核调试符号（debuginfo），适合在 Netflix 云环境等生产系统中使用。\n\n局限性：\n- 仅支持 x86 架构（假设 skb 指针在 `%di` 寄存器）；\n- 暂不支持 IPv6；\n- 若需更复杂解析，建议使用 SystemTap 等可编程探针工具。\n\n**适用人群**：系统管理员、网络工程师、性能调优人员，尤其适用于排查慢请求、丢包或网络延迟问题。","published_at":"2014-09-06T00:00:00Z"}
{"domain":"brendangregg","path":"https://www.brendangregg.com//blog/2014-08-30/ftrace-the-hidden-light-switch.html","title":"ftrace: The Hidden Light Switch","summary":"本文介紹了作者在 Netflix 使用 Linux 內核追蹤工具 ftrace 實際驗證核心參數變更是否立即生效的經驗，並展示其強大功能。ftrace 因預設內建於所有 Linux 系統且無需額外安裝，極具實用性，但知名度較低。作者透過 `funccount` 工具觀察 `deadline` I/O 排程器函數呼叫次數，確認其目前正活躍運作，展現 ftrace 在調試與監控上的價值。\n\n文章強調 ftrace 可實現多項進階功能（如函數計數、即時追蹤），並推薦使用 Brendan Gregg 所開發的 `perf-tools` 封裝工具提升效率。對於更高階需求，可搭配 Steven Rostedt 開發的 `trace-cmd` 工具。儘管 ftrace 目前尚不支援自訂內核聚合等進階功能，但其能力已遠超預期。\n\n適合系統工程師、性能優化專家及對內核調試感興趣者閱讀。更多資源可參考作者先前文章與 lwn.net 上的相關連結。","published_at":"2014-08-30T00:00:00Z"}
{"domain":"brendangregg","path":"https://www.brendangregg.com//blog/2014-08-23/linux-perf-tools-linuxcon-na-2014.html","title":"Linux Performance Tools at LinuxCon North America 2014","summary":"本文作者在2014年LinuxCon North America大会上首次亮相，分享了关于Linux性能可观测性、基准测试与调优工具的最新进展。他更新并展示了其经典的性能工具图谱，并新增了涵盖可观测性、性能测试与系统调优的完整工具生态图示，帮助听众从监控到负载测试再到系统优化实现全面理解。\n\n作者特别介绍了ftrace在现有内核中实现追踪的能力，并推荐其LWN.net文章《Ftrace: The hidden light switch》作为深入阅读材料。他还提供了一张空白的可观测性工具模板（PNG），建议用户打印后根据自身环境填写实际使用的工具，可用于自研监控系统设计或评估商业产品功能覆盖度。\n\n该图谱在Netflix的实际应用中帮助识别监控盲区，指导后续开发。尽管演讲现场爆满且未录像，但反响热烈，作者表示未来可能再次分享并补录视频。感谢主办方Linux Foundation及与会者。","published_at":"2014-08-23T00:00:00Z"}
{"domain":"brendangregg","path":"https://www.brendangregg.com//blog/2014-07-28/execsnoop-for-linux.html","title":"execsnoop For Linux: See Short-Lived Processes","summary":"**总结：**\n\n本文介绍了作者将原本用于其他系统的 `execsnoop` 工具成功移植到 Linux 平台，用于追踪短生命周期进程（如脚本调用、命令执行等），帮助诊断因频繁创建/销毁进程导致的性能问题（如高 CPU 使用率）。该工具基于 `ftrace` 和 `kprobe` 机制，通过动态探测 `do_execve` 系统调用，实时捕获进程启动时的完整命令行参数。\n\n关键亮点：\n- **功能强大**：可清晰看到 `man ls`、Linux 构建过程等复杂命令链中调用的多个子进程，揭示隐藏的“进程爆炸”现象。\n- **实用场景**：识别不必要的 `sh/grep/awk` 调用，提示优化脚本逻辑；发现异常行为（如自动发起 `curl` 请求）。\n- **灵活选项**：支持时间戳（`-t`）、过滤进程名（正则匹配）、限制参数数量（`-a`）、设置跟踪时长（`-d`）。\n- **技术实现**：使用内核 `kprobe` 动态注入探针，通过寄存器 `%si` 解析参数数组，是一种针对旧内核（如 3.2）的巧妙“黑客”方案，无需调试符号。\n- **替代方案对比**：相比 SystemTap（需编译环境）或 `/proc` 读取（可能延迟），`execsnoop` 更轻量、兼容性好，适合云服务器和无 debuginfo 的环境。\n\n**适用人群**：系统管理员、性能调优工程师、运维开发者。  \n**推荐理由**：在无法用传统工具（如 top）捕捉瞬时进程时，`execsnoop` 是排查隐蔽性能瓶颈的利器，尤其适用于老旧或受限环境。  \n**风险提示**：动态追踪存在内核崩溃风险，使用需谨慎，建议先测试验证。","published_at":"2014-07-28T00:00:00Z"}
{"domain":"brendangregg","path":"https://www.brendangregg.com//blog/2014-07-25/opensnoop-for-linux.html","title":"opensnoop For Linux","summary":"**摘要：**\n\n本文介绍了一个名为 `opensnoop` 的 Linux 工具，用于实时追踪系统中所有进程打开的文件，帮助定位配置文件、日志文件及文件访问错误。该工具基于 ftrace 和 kprobes，无需安装内核调试符号（debuginfo），适用于 AWS EC2 等无 debuginfo 的生产环境。\n\n- **核心功能**：  \n  - 追踪 `open()` 系统调用，显示进程名（COMM）、PID、文件描述符（FD）和文件路径。\n  - 支持按文件名关键词过滤（如 `conf`、`log$`），快速定位特定类型文件。\n  - 可筛选失败的 `open()` 操作（`-x` 参数），发现缺失文件或路径问题。\n\n- **实用场景**：\n  - 找到应用配置文件位置（如 `/home/webapp/.../conf/`）。\n  - 定位日志文件实际存储路径（如 `/var/tmp/webapp.log`）。\n  - 排查程序因找不到依赖库或配置引发的异常。\n\n- **技术实现**：\n  - 通过动态探测内核函数 `getname()` 返回值获取文件名字符串，绕过对 debuginfo 的依赖。\n  - 提供 `-d`（定时输出）、`-p PID`、`-n name` 等选项提升效率与精准度。\n  - 附带替代方案：使用 `perf probe` + kernel debuginfo 的一行命令方式（需调试符号支持）。\n\n- **适用人群**：  \n  系统管理员、运维工程师、性能调优人员，尤其适合在无调试符号的云环境中排查文件访问问题。\n\n\u003e ⚠️ 注意：动态跟踪存在潜在内核崩溃风险，建议先测试再生产使用。  \n\u003e 工具开源地址：[https://github.com/brendangregg/perf-tools](https://github.com/brendangregg/perf-tools)","published_at":"2014-07-25T00:00:00Z"}
{"domain":"brendangregg","path":"https://www.brendangregg.com//blog/2014-07-23/linux-iosnoop-latency-heat-maps.html","title":"Linux iosnoop Latency Heat Maps","summary":"**摘要：**\n\n传统线图和平均值统计容易掩盖 I/O 延迟的异常模式，而使用**延迟热图（latency heat map）** 和 **直方图** 能清晰揭示隐藏的性能问题。作者通过 `iosnoop` 工具捕获块设备 I/O 的时间戳与延迟数据，并用 `trace2heatmap.pl` 转换为热图。\n\n关键发现：\n- 大部分 I/O 延迟极低（0–2ms），表现为底部深红色条带。\n- 每约 9 秒出现一次高延迟“云团”（约 70ms），形成多峰分布，仅靠平均值无法察觉。\n- 该问题由特定磁盘（如 `202,1`）引起，通过降低其队列深度（`nr_requests` 从 128 改为 4）可显著缓解延迟峰值。\n\n结论：  \n**延迟热图是诊断复杂 I/O 性能问题的强大工具**，尤其适合识别周期性、突发性或异常延迟。建议系统管理员在排查磁盘瓶颈时采用此类可视化方法。","published_at":"2014-07-23T00:00:00Z"}
{"domain":"brendangregg","path":"https://www.brendangregg.com//blog/2014-07-16/iosnoop-for-linux.html","title":"iosnoop For Linux","summary":"**总结：**\n\n作者将原本用于 macOS 的 `iosnoop` 工具移植到 Linux，实现了一个轻量级的块设备 I/O 追踪工具，功能类似“磁盘版 tcpdump”。该工具基于内核的 ftrace 框架，仅使用 bash、awk 和 `/sys` 文件系统，无需 SystemTap、perf_events 等复杂工具，即可在 3.2+ 内核上运行。\n\n**核心功能：**\n- 实时显示每条块设备 I/O 的进程（COMM）、PID、类型（读/写）、设备、区块号、字节数和延迟（LATms）。\n- 支持过滤（按设备、类型、PID、进程名）和时间戳输出（`-s`、`-t`），便于分析性能瓶颈。\n- 新增 `-Q` 选项，以“队列插入”时间作为起点，可追踪队列等待时间，提升 PID/COMM 准确性。\n\n**关键洞察：**\n- 在 SSD 上随机读取延迟通常 \u003c0.2ms，但偶有高达 20ms 的异常延迟。\n- 通过时间排序发现，这些慢读发生在大量写入之后，即使写入设备不同，也可能因共享队列导致延迟激增（如 Xen 虚拟化环境）。\n- `COMM`/`PID` 列为“最佳尝试”，可能不准确（如 `awk`、`sshd` 显示为发起者，实为内存扩展触发的异步 I/O），因中断上下文切换导致。`-Q` 可改善此问题。\n\n**性能与限制：**\n- **低开销**：5 秒缓冲模式仅消耗约 0.5 秒 CPU，适合一般场景。\n- **高负载受限**：未缓冲模式下最多支持约 15,000 IOPS，超过则易丢事件。\n- 当前版本为实验性“黑客工具”，依赖 ftrace，非长期稳定方案。\n\n**未来方向：**\n- 建议迁移到更强大的框架（如 perf_events、SystemTap），以支持更高吞吐、更可靠缓冲和并发。\n- 作者感叹：一个纯 shell 脚本能跨多版本内核工作，宛如梦境，但也意识到其局限性。\n\n**适用人群：** 系统管理员、性能调优工程师、开发者，尤其适合排查磁盘延迟异常、理解 I/O 路径行为。  \n**推荐使用场景：** 快速诊断延迟突增、验证 I/O 分布、分析虚拟机/容器中的磁盘争用问题。","published_at":"2014-07-16T00:00:00Z"}
{"domain":"brendangregg","path":"https://www.brendangregg.com//blog/2014-07-13/linux-ftrace-function-counting.html","title":"Linux ftrace Function Counting","summary":"本文展示了如何使用 `funccount` 脚本结合 Linux 内核的 ftrace 功能，动态追踪和统计内核函数调用频率，无需依赖 perf_events、SystemTap 等复杂工具。\n\n**核心要点：**\n- 使用 `funccount 'bio_*'` 可快速识别块设备 I/O 子系统中活跃的函数（如 `bio_alloc`, `bio_add_page`），帮助定位性能瓶颈。\n- 通过 `funccount -i 1 -t 5 'tcp_*'` 每秒输出前 5 个最频繁调用的 TCP 相关函数，实时观察网络栈行为。\n- 工具基于 ftrace（内核内置动态跟踪机制），利用每 CPU 计数聚合，高效且低开销。\n- `funccount` 是一个轻量级脚本，支持时间间隔统计、顶部函数筛选、通配符匹配等功能，适合探索陌生内核子系统。\n- 建议先用 `perf-events` 风格火焰图进行初步分析，再用函数计数深入排查。\n- 注意：部分函数可能因未导出符号而不可见，可检查 `/proc/kallsyms` 或 `/sys/kernel/debug/tracing/available_filter_functions`。\n- 警告：动态追踪有潜在内核崩溃风险，建议在测试机上先行验证。\n\n**适用人群：** 系统性能调优工程师、内核开发者、运维与 SRE 人员。  \n**推荐场景：** 内核子系统诊断、性能问题根因分析、学习内核运行机制。","published_at":"2014-07-13T00:00:00Z"}
{"domain":"brendangregg","path":"https://www.brendangregg.com//blog/2014-07-10/perf-hacktogram.html","title":"perf Hacktogram","summary":"该博客通过 `perf` 工具分析了 Linux 系统中网络数据包大小和 `read()` 系统调用请求大小的分布情况，揭示了典型工作负载特征：\n\n- **网络数据包大小分布**：约一半数据包在 64–255 字节之间，其余集中在 256–4095 字节，表明小包为主，符合常见网络通信模式。\n- **`read()` 系统调用请求大小**：绝大多数（约 193 万次）请求在 256–1023 字节范围内，说明应用读取行为以小块数据为主。\n\n作者展示了两种分析方法：\n1. **用户空间处理**：使用 `perf record` + `perf script` 虽功能完整，但生成海量数据（\u003e500万条），导致高内存与CPU占用，甚至系统卡顿。\n2. **内核级直方图（“hacktogram”）**：利用 `perf stat` 的多过滤器机制，对同一事件按不同范围计数，实现轻量级直方图统计，虽有效但有性能开销（可高达50%），属于临时方案。\n\n作者指出，理想方案是 `perf stat` 原生支持 `--hist` 选项（如 `--hist \"pow2 count\"`），可直接在内核中完成分桶统计。当前虽无此功能，但随着内核发展，未来有望实现。\n\n**总结**：  \n- 实际场景中，小包和小读请求占主导。  \n- 当前工具链需权衡精度与性能；推荐使用 `perf-stat-hist` 进行快速、低开销的分布分析。  \n- 期待 `perf` 未来原生支持内核直方图功能。  \n\n**适用人群**：系统性能调优工程师、内核开发者、网络/存储优化人员。","published_at":"2014-07-10T00:00:00Z"}
{"domain":"brendangregg","path":"https://www.brendangregg.com//blog/2014-07-03/perf-counting.html","title":"perf Counting","summary":"本文介绍了如何使用 Linux `perf stat` 工具高效统计内核、设备和应用事件的调用次数，特别适用于快速回答“某事件被调用了多少次”这类问题。\n\n**核心要点：**\n- `perf stat` 的“计数模式”比采样模式更高效，仅在内核中汇总数据，减少 CPU 与存储开销。\n- 可通过 `-e` 指定任意静态或动态跟踪点（tracepoint），如 `sched:sched_process_*`、`syscalls:sys_enter_*` 等。\n- 使用 `-a` 统计全系统事件，`-p PID` 限定特定进程，`sleep N` 控制采样时长。\n- 支持按秒输出间隔统计（`-I 1000`），查看事件速率变化。\n- 可按 CPU 分解统计结果（`-A`）。\n- 通过 `--filter` 实现条件过滤，例如只统计 `read()` 中请求大小 \u003e 4KB 的调用。\n\n**实用技巧：**\n- 用 `awk '$1'` 过滤掉零计数项。\n- 旧版本可能需增加文件描述符限制（`ulimit -n`）。\n- 查看 `format` 文件（如 `/sys/kernel/debug/tracing/events/.../format`）可获取可用变量（如 `count`）。\n\n**适用场景：**\n- 快速诊断系统行为（如频繁创建/销毁进程、高频率系统调用）。\n- 作为深入分析前的快速探查手段，替代复杂采样。\n\n**推荐人群：** 系统性能调优工程师、开发者、运维人员。","published_at":"2014-07-03T00:00:00Z"}
{"domain":"brendangregg","path":"https://www.brendangregg.com//blog/2014-07-01/perf-heat-maps.html","title":"perf Heat Maps","summary":"本文通过分析 AWS EC2 c3.large 实例（Ubuntu）的磁盘延迟热图，揭示了看似“SSD”的云服务器中仍存在显著延迟问题的根源。尽管实例使用 SSD，但实际观测到的高延迟（如 63 秒处超过 237 毫秒）和持续延迟云（43 秒后达 30 毫秒）令人惊讶。\n\n作者使用 `perf` 工具捕获 `block:block_rq_issue` 与 `block:block_rq_complete` 事件，结合 `awk` 计算 I/O 延迟，并用自研工具 `trace2heatmap.pl` 生成延迟、大小、偏移热图。关键发现如下：\n\n- **延迟异常源于旋转磁盘**：原始数据包含系统启动盘（202,1），为传统机械硬盘。过滤该设备后，仅保留 SSD 的延迟热图，发现延迟问题消失。\n- **写入突发导致延迟峰值**：读取延迟热图显示，延迟高峰已消失，说明是写入操作（如文件系统刷新）所致。这在现代磁盘中常见，且通常不影响同步读取性能。\n- **I/O 大小与偏移分析**：虽然 43 秒后读写大小变小（应更快），但延迟反而上升，进一步佐证了非 SSD 设备的影响；偏移热图显示后期访问更趋顺序，可能是文件系统对磁盘类型误判所致。\n\n**核心结论**：  \n即使实例主存储为 SSD，若工作负载涉及旋转磁盘（如系统盘），其延迟会严重拖累整体表现。使用 `perf` + `awk` + 自定义热图工具可精准定位性能瓶颈，帮助识别隐藏的存储层级问题。\n\n**适用人群**：系统管理员、性能调优工程师、云平台运维人员。  \n**推荐实践**：在监控存储性能时，务必区分设备类型，避免被混合存储环境误导。","published_at":"2014-07-01T00:00:00Z"}
{"domain":"brendangregg","path":"https://www.brendangregg.com//blog/2014-06-29/perf-static-tracepoints.html","title":"perf Static Tracepoints","summary":"本文演示了如何使用 Linux `perf_events` 工具的静态跟踪点（static tracepoints）来追踪块设备 I/O 活动，重点以 `block:block_rq_complete` 为例。通过运行 `perf record -e block:block_rq_complete -a sleep 10` 可收集 10 秒内所有块设备 I/O 完成事件，并用 `perf script` 输出详细信息。\n\n每条记录包含关键字段：时间戳、进程名与 PID、CPU 编号、设备主次号（202,1）、I/O 类型（如 W=写入）、偏移量、请求大小（8 扇区）、错误状态等。这些数据可用于分析 I/O 性能瓶颈，尤其在虚拟化环境（如 AWS EC2）中，因虚拟化开销和邻居干扰导致性能波动更大，监控更显重要。\n\n文中还展示了如何查看 tracepoint 的结构定义（来自内核源码 `include/trace/events/block.h`）和格式文件 `/sys/kernel/debug/tracing/events/block/block_rq_complete/format`，帮助理解输出字段的来源。\n\n此外，`perf_events` 支持捕获调用栈、自定义过滤，还可用于动态跟踪（dynamic tracing）。文章最后推荐参考作者其他关于 `perf_events` 的博客内容，涵盖 CPU 采样等更多用例。","published_at":"2014-06-29T00:00:00Z"}
{"domain":"brendangregg","path":"https://www.brendangregg.com//blog/2014-06-22/perf-cpu-sample.html","title":"perf CPU Sampling","summary":"**总结：**\n\n当 `top` 显示某个进程高占用 CPU 时，最通用且适用于任何应用（包括内核）的排查方法是使用 Linux 系统级性能分析工具 `perf`。本文以 `fio` 进程为例，演示如何用 `perf` 定位高 CPU 消耗的根本原因。\n\n**核心步骤：**\n1. **确认 `perf` 已安装**：通过 `perf` 命令查看帮助，若缺失可安装 `linux-tools-common` 包。\n2. **采集性能数据**：运行 `sudo perf record -F 99 -a -g -- sleep 20`，以 99Hz 频率对所有 CPU 采样并记录调用栈，持续 20 秒。\n3. **分析结果**：使用 `sudo perf report -n --stdio` 查看采样报告，识别热点函数。例如，发现 `hypercall_page`、`copy_user_generic_string`、`clock_gettime` 被频繁调用，表明 `fio` 可能因频繁获取时间或系统调用导致高负载。\n\n**关键洞察：**\n- `perf` 能穿透用户态与内核态，提供完整调用栈分析。\n- 即使符号信息不全（如无 debug symbols），部分分析仍可定位问题。\n- 使用 `-g graph` 可自动计算累积占比；结合火焰图（Flame Graphs）可更直观可视化热点。\n\n**实用建议：**\n- 编译时避免 `-fomit-frame-pointer`，确保堆栈完整性。\n- 若需调试 JIT 代码或已剥离符号的程序，可尝试安装 `dbgsym` 包或启用内核 `CONFIG_KALLSYMS`。\n- 推荐使用 `perf script` + 火焰图进行高效分析。\n\n**适用人群：** 系统管理员、开发者、性能调优工程师。  \n**推荐理由：** `perf` 是无需依赖应用特定工具的“万能”诊断手段，尤其适合无法访问源码或日志的场景。","published_at":"2014-06-22T00:00:00Z"}
{"domain":"brendangregg","path":"https://www.brendangregg.com//blog/2014-06-12/java-flame-graphs.html","title":"Java Flame Graphs","summary":"**总结：**\n\n本文介绍如何使用开源工具创建Java火焰图（Flame Graphs），以直观分析CPU使用情况。火焰图通过栈帧的宽度和层级展示代码执行路径，帮助快速识别性能瓶颈。\n\n- **核心工具**：Google的轻量级Java分析器（lightweight-java-profiler） + Brendan Gregg的火焰图生成工具（FlameGraph）。\n- **工作流程**：\n  1. 使用`lightweight-java-profiler`采集运行时堆栈样本，输出为`traces.txt`；\n  2. 用`stackcollapse-ljp.awk`转换格式；\n  3. 用`flamegraph.pl`生成SVG/HTML交互式火焰图。\n- **关键洞察**：图中宽大的柱状区域代表高消耗代码。例如，示例中Mozilla Rhino引擎占42.7% CPU，移除后可显著提升性能；而`write0()`的持续高占比是正常且理想的。\n- **优化建议**：可调整采样频率（默认100Hz）、最大栈深度等参数以降低开销。\n- **进阶方法**：更新推荐使用Netflix提出的`perf_events`方案，能同时显示Java与系统内核代码路径，实现更全面的分析。\n- **适用场景**：适用于性能调优、版本对比、长期监控，是比传统调用树更高效的性能诊断工具。\n\n\u003e ✅ 推荐给开发人员、运维工程师及性能优化团队，尤其适合需要深入理解应用CPU消耗细节的技术人员。","published_at":"2014-06-12T00:00:00Z"}
{"domain":"brendangregg","path":"https://www.brendangregg.com//blog/2014-06-09/java-cpu-sampling-using-hprof.html","title":"Java CPU Sampling Using hprof","summary":"**摘要：**\n\nJava 自带的 `hprof` 工具虽功能强大，但其 CPU 采样模式（`cpu=samples`）存在严重缺陷，**无法准确反映真实 CPU 占用情况**。问题核心在于：\n\n1. **采样基于 Java `RUNNABLE` 状态，而非实际运行在 CPU 上**：即使线程在等待系统调用（如 `epollWait`），只要处于 `RUNNABLE` 状态，就会被采样，导致看似“高消耗”的方法（如 `epollWait`）被错误归因于 CPU 消耗。\n2. **采样时机依赖“安全点”（safepoints）**：并非按设定间隔精确采样，而是仅在程序执行到特定点时才采样，造成结果失真。\n3. **输出误导性高**：在应用完全空闲时，仍显示大量“CPU 使用”，误导开发者误判性能瓶颈。\n\n尽管 `hprof` 有低开销（20ms 间隔下仅增加约 4% JVM CPU），且可借助 `SIGQUIT` 实现部分区间采样，但其**结果不可靠**，已不适用于生产级性能分析。\n\n**替代方案推荐**：\n- **Google 轻量级采样器**（Lightweight Java Profiler）和 **Honest Profiler**（基于 Hotspot AsyncGetCallTrace 接口）采用异步、系统级采样，能更准确捕获实际运行中的栈轨迹，是目前最可靠的免费开源选项。\n- 商业工具（如 YourKit、JProfiler）或 IDE 内置分析器也更可靠。\n\n**结论**：不要盲目信任内置工具。`hprof` 的 CPU 采样结果可能严重误导，建议使用基于系统级采样的现代开源工具进行真实性能分析。","published_at":"2014-06-09T00:00:00Z"}
{"domain":"brendangregg","path":"https://www.brendangregg.com//blog/2014-05-23/osx-10.9.3-is-toxic.html","title":"OS X 10.9.3 Recurring Panics","summary":"**总结：**\n\n作者在升级至 macOS 10.9.3 后遭遇频繁内核崩溃（16次/4天），尤其在连接外接显示器时。通过分析诊断日志发现，崩溃均与虚拟内存（VM）子系统相关，具体表现为 `VM_PAGE_QUEUES_REMOVE: unmarked page on Q` 错误，疑似内存管理冲突或双重释放问题。进一步分析显示，问题可能源于硬件加速功能（如 GPU 内存分配）导致的内存越界或破坏。\n\n作者使用自制脚本 `kernel_diagreport2text.ksh` 成功解析了崩溃栈，确认问题与 `IOAcceleratorFamily2` 及 `WindowServer` 等组件有关。最终在 **macOS 10.9.2** 上验证出有效临时解决方案：**关闭 Firefox 的硬件加速功能**，即可彻底消除崩溃。推测 10.9.3 的更新因改进 4K 显示支持而引入了相关代码缺陷，加剧了该问题。\n\n尽管苹果未及时修复，但作者建议用户若遇到类似崩溃，可尝试关闭浏览器或系统级硬件加速来规避风险。同时呼吁苹果应恢复内核崩溃报告中的函数参数信息，以提升调试效率。","published_at":"2014-05-23T00:00:00Z"}
{"domain":"brendangregg","path":"https://www.brendangregg.com//blog/2014-05-17/free-as-in-we-own-your-ip.html","title":"Free, as in, We Own Your IP","summary":"**摘要：**\n\n许多性能监控公司通过免费试用和奖品吸引用户，但其服务条款中隐藏着严重风险——部分条款要求用户将试用期间提出的任何创意、建议或反馈的知识产权（IP）无偿转让给公司。作者以某公司（NiftyMon）为例，指出其条款第（iii）项规定“所有与创意相关的权利归公司所有”，这可能意味着用户在试用中提出的技术想法将被永久剥夺。\n\n尽管平均阅读速度为每分钟250字，但完整条款长达6082字，需至少24分钟才能读完，几乎无人会认真阅读。作者咨询了公司律师，对方明确表示不会接受此类条款。尤其对于资深工程师而言，试用中可能无意间透露有价值的创新思路，一旦未被采纳，便失去全部知识产权，极为不公。\n\n相较之下，另一家公司条款仅授予“免版税、全球性、可转让、永久性”的使用许可，较为合理。作者呼吁用户在试用前务必仔细阅读条款，若发现不合理内容，应寻求法律意见。该文发布后引发关注，已有公司修改条款，作者表示将重新尝试这些服务。\n\n**核心要点：**\n- 免费试用背后可能隐藏“知识产权让渡”陷阱。\n- 企业应警惕条款中对创意成果的过度索取。\n- 建议用户审慎阅读并咨询法律专业人士。\n- 透明、公平的条款更值得信赖。","published_at":"2014-05-17T00:00:00Z"}
{"domain":"brendangregg","path":"https://www.brendangregg.com//blog/2014-05-16/usenix-lisa-2013-metrics-workshop.html","title":"USENIX/LISA 2013 Metrics Workshop","summary":"本文总结了在USENIX LISA'13大会上由Brendan Gregg等人主持的“性能度量研讨会”的核心内容。会议聚焦于现有监控指标的局限性，倡导更创新、更有效的性能度量方法，强调跳出传统指标框架，以解决实际问题。\n\n**核心观点：**  \n- 推广使用“USE方法”等系统化框架，帮助设计简洁、实用的监控指标。  \n- 通过分组讨论，针对网络基础设施、配置管理、分布式系统、消息队列、Web服务器、应用服务器、数据库及资源设备等关键领域，提出理想化的性能指标。\n\n**关键发现与建议：**  \n- **网络层**：关注链路带宽、利用率、协议健康度、端口流量、延迟对称性等。  \n- **配置管理**：应追踪版本、部署时间、资源消耗、合规率及失败回滚情况。  \n- **分布式系统**：重视感知延迟、请求/错误率、服务间通信可视化（如火焰图、热力图）。  \n- **消息队列**：需监控消息延迟分布、吞吐量、队列饱和度、丢弃与重传。  \n- **数据库**：重点指标包括查询速率、缓存命中率、平均I/O延迟、锁数量、检查点时间等。  \n- **通用原则**：强调利用统计分析与可视化手段，实现对系统行为的深入洞察。\n\n**实践价值：**  \n所有提出的指标已整理并提交至GitHub的`monitoringsucks/metrics-catalog`项目，供业界参考与持续改进。\n\n**适合人群：** 系统工程师、运维专家、SRE及关注可观测性提升的技术决策者。","published_at":"2014-05-16T00:00:00Z"}
{"domain":"brendangregg","path":"https://www.brendangregg.com//blog/2014-05-11/strace-wow-much-syscall.html","title":"strace Wow Much Syscall","summary":"**摘要：**\n\n`strace` 是一个强大的 Linux 系统调用追踪工具，能帮助诊断程序行为，但存在严重性能开销。它基于 `ptrace` 接口，每次系统调用都会暂停目标进程两次（调用前和返回时），导致上下文切换频繁，最坏情况下可使程序变慢 **442倍**（如 `dd` 测试所示），严重影响生产环境。\n\n### 关键要点：\n- **高延迟风险**：`strace` 会显著拖慢应用，可能触发超时、故障转移或服务中断。\n- **使用场景限制**：仅适合测试环境或快速排查问题，生产环境需谨慎，建议优先使用低开销替代方案。\n- **替代工具推荐**：`perf_events`、`sysdig`、`SystemTap`、`ktap` 等提供更低延迟、更深层可观测性。\n- **实战价值**：可发现隐藏性能问题（如 `ls` 因未设 `TZ` 变量反复调用 `stat(/etc/localtime)`，优化后提速23%）。\n- **警告提示**：历史上曾有 `strace` 导致进程卡死的案例，可能引发严重事故。\n\n### 实用建议：\n- 学习12个核心系统调用（如 `open`, `read`, `write`, `fork`, `execve`, `connect`, `stat` 等）。\n- 掌握常用命令行技巧（如 `-eopen,stat` 过滤、`-T` 查看耗时、`-cp` 统计）。\n- 深入理解输出含义，结合 `man` 手册分析。\n- 长期来看，`strace` 可能被 `perf trace`、`sysdig` 等工具取代。\n\n\u003e ✅ **总结**：`strace` 是“调试显微镜”，功能强大但代价高昂；**非必要不用于生产**，应优先采用 `perf`、`sysdig` 等现代观测工具以实现高效、低干扰的问题定位。","published_at":"2014-05-11T00:00:00Z"}
{"domain":"brendangregg","path":"https://www.brendangregg.com//blog/2014-05-09/xen-feature-detection.html","title":"Xen Feature Detection","summary":"本文介紹如何在 Xen 虛擬機中判斷當前運行的模式（如 HVM、PV、PVHVM 等），並提供實用命令工具協助驗證。核心重點如下：\n\n- **主要目標**：透過 `dmesg`、`/sys/hypervisor` 等方法，判斷虛擬機是否使用 PV、HVM 或混合模式（如 PVHVM）。\n- **關鍵辨識方式**：\n  - `dmesg | grep -i xen` 可見「Booting paravirtualized kernel on Xen」表示為 PV 模式；若出現「Xen HVM」且有「callback vector」則為 PVHVM。\n  - 「HVM callback vector」表示使用高效能的 PV 中斷機制，避免硬體模擬開銷。\n  - 「Xen timer」與「xen_netfront」等訊息顯示已啟用 PV 時鐘與網路驅動。\n- **/sys/hypervisor/properties/features** 提供二進位特徵碼，可用腳本轉換為可讀內容（如 `xen-features.pl`）。\n- **設備名稱辨識**：`xvd` 開頭的磁碟與 `vif` 驅動代表使用 PV 模式，性能優於傳統 HVM。\n- **誤導性資訊提醒**：\n  - `/proc/cpuinfo` 的 `vmx/smvm` 只反映宿主支援，無法確認客體是否啟用。\n  - 内核編譯選項（如 `CONFIG_XEN_PVHVM=y`）僅表示支援，不代表實際啟用。\n\n✅ **實用建議**：  \n對於 EC2 等無法直接查看配置的環境，應結合 `dmesg`、`ethtool -i`、`/sys/bus/xen/devices/` 等工具綜合判斷。推薦使用 [xen-features.pl](https://github.com/brendangregg/Misc/blob/master/xen/xen-features.pl) 腳本解析特性碼。\n\n📌 **適用對象**：系統管理員、雲端開發者、性能調優工程師，特別是需要優化虛擬機效能者。","published_at":"2014-05-09T00:00:00Z"}
{"domain":"brendangregg","path":"https://www.brendangregg.com//blog/2014-05-07/what-color-is-your-xen.html","title":"Xen Modes: What Color Is Your Xen?","summary":"**总结：**\n\n在Xen虚拟化环境中，性能最优的模式并非简单的“PV”或“HVM”，而是随技术演进而不断优化的混合模式。当前最佳选择是 **PVHVM**（即支持半虚拟化驱动的全硬件虚拟化），它结合了HVM的硬件加速与PV的高效I/O接口，已在AWS EC2中通过“HVM”实例实现（实际运行的是PVHVM）。未来，**PVH**（Paravirtualized Hardware）将成为最快模式，但目前尚未在主流云平台普及。\n\n关键要点：\n- **旧观点过时**：过去认为“PV更快”的结论已不适用，因现代虚拟化已高度融合。\n- **模式本质是演进**：PV、HVM、PVHVM、PVH并非独立选择，而是技术发展的不同阶段，应视为“版本迭代”而非“模式切换”。\n- **现实建议**：在AWS上，选择 **HVM实例** 即可自动启用PVHVM，获得最佳性能；若支持，开启 **SR-IOV** 可进一步提升网络性能。\n- **未来趋势**：随着Xen 4.4+及内核支持，PVH将逐步成为标准，而传统纯PV/HVM模式将逐渐淘汰。\n\n\u003e ✅ **推荐做法**：优先选择支持PVHVM的HVM实例，避免纠结于“PV vs HVM”等过时分类，关注底层是否启用最新混合特性。","published_at":"2014-05-07T00:00:00Z"}
{"domain":"brendangregg","path":"https://www.brendangregg.com//blog/2014-05-03/the-benchmark-paradox.html","title":"The Benchmark Paradox","summary":"**摘要：**\n\n文章指出，许多性能基准测试（benchmarks）结果不可靠，甚至如同掷硬币般随机。作者以销售案例为例说明：即使基准测试“出错”的概率为50%，但若客户要求在多个基准中全部胜出，实际成功概率会急剧下降——例如三个基准全胜的概率仅为12.5%。这种“全赢”要求使得产品即使表现优秀，也极易因一次失败而被否定，导致高绩效产品反而“输掉”评估。\n\n文章批评了“厨房水槽式”（kitchen-sink）基准测试的滥用，并强调错误的测试设计会让真实性能被掩盖。最终结论是：依赖此类基准进行产品评估无异于“赌徒游戏”，建议采用更科学的**主动基准测试**（active benchmarking）来真实反映系统性能。","published_at":"2014-05-03T00:00:00Z"}
{"domain":"brendangregg","path":"https://www.brendangregg.com//blog/2014-05-02/compilers-love-messing-with-benchmarks.html","title":"Compilers Love Messing With Benchmarks","summary":"**总结：**\n\n使用 UnixBench 等基准测试工具时，**编译器选项和版本会显著影响结果**，导致跨系统比较失真。尽管 UnixBench 被广泛用于云服务器性能对比（如 ServerBear 的排行榜），其默认编译配置（`OPTON = -O2 -fomit-frame-pointer -fforce-addr -ffast-math -Wall`）源自 1997 年的 Solaris 2，而非现代 Linux 环境。这导致：\n\n- 同一台服务器使用不同优化级别（如 `-O0` vs `Solaris2 OPTON`），Dhrystone 2 分数可差 64%；\n- 即使使用相同编译选项，不同 GCC 版本（如 4.1.2 与 4.6.3）也会带来明显差异；\n- 当前云平台（如 AWS EC2）上运行的系统可能使用多个不同版本的 GCC，使结果不可比。\n\n**关键结论：**\n\u003e **要获得可信的基准数据，必须确保所有测试系统使用完全相同的编译器版本和选项**，否则“性能差异”可能只是编译器造成的假象。\n\n**建议：**\n- 采用“主动基准测试”（Active Benchmarking）方法，深入理解测试过程；\n- 若需公平比较，应固定编译器或直接分发预编译二进制文件；\n- 建议将 `-O0` 设为默认选项以减少编译器干扰；\n- 使用结果时务必注明操作系统、编译器版本与优化选项。\n\n**警示：** 不加控制地依赖“单一指数得分”（如 UnixBench Index Score）进行服务器选型，可能误导决策——**升级编译器本身，可能比换服务器带来更大性能提升。**","published_at":"2014-05-02T00:00:00Z"}
{"domain":"brendangregg","path":"https://www.brendangregg.com//blog/2014-04-27/let-me-obfuscate-that-for-you.html","title":"Compilers: Let Me Obfuscate That For You","summary":"**摘要：**\n\n编译器在 `-O0` 优化级别下将 C 语言中的 `\u003c 10000000` 转换为 `jle 9999999`，是为了减少常数大小以节省指令字节（如从 `0xf4240` 变为 `0xf423f`），理论上可提升缓存效率。然而实测发现，在 10000000 这个值上并未节省字节数，说明该优化在此场景无效。\n\n尽管如此，编译器仍执行此操作，导致调试困难——开发者难以通过搜索原始常数（如 1000000）定位代码。该行为由 GCC 的 `simplify_compare_const()` 函数实现，其逻辑是：若常数大于 0，将 `\u003c C` 转为 `\u003c= (C-1)` 以尝试压缩编码。\n\n虽然该优化在某些小常数（如 128）时可节省 3 字节，但对大常数无效，且牺牲了可读性和调试便利性。尽管 `-Og` 标志旨在不干扰调试，但此优化依然存在，令人遗憾。\n\n**关键点：**\n- 优化动机：减小常数以缩短指令编码。\n- 实际效果：大常数下无字节节省。\n- 缺点：干扰调试，常数被“隐藏”。\n- 适用场景：仅在小常数时有效，整体收益有限。\n\n**建议：** 若需可预测的汇编输出用于调试，应避免依赖编译器此类“隐式”优化。","published_at":"2014-04-27T00:00:00Z"}
{"domain":"brendangregg","path":"https://www.brendangregg.com//blog/2014-04-26/the-noploop-cpu-benchmark.html","title":"The noploop CPU Benchmark","summary":"**摘要：**\n\n作者分享了一种通过自定义汇编代码测量CPU实际时钟频率的实用方法，尤其适用于虚拟化环境（如AWS EC2）中无法可靠使用`/proc/cpuinfo`或性能计数器的情况。核心思路是：编写一个包含大量无操作指令（NOP）的循环，通过精确计时其执行时间来推算CPU实际运行频率。\n\n具体步骤如下：\n1. 用C语言编写一个简单循环（如1000万次迭代），编译成汇编。\n2. 在循环体内插入2000个NOP指令，使程序主要消耗在执行空操作上，从而最小化分支预测、缓存缺失等干扰因素。\n3. 编译并验证生成的机器码（使用`objdump`确认）。\n4. 运行程序并记录用户态耗时（`time ./noploop`），计算出执行的总指令数（200亿个NOP）。\n5. 假设每个NOP需1个周期，得出理论频率（约12.285 GHz）。\n6. 考虑现代处理器的超标量架构（可同时执行多条指令），将结果除以并行度（此处估算为4），得到真实主频约为3.071 GHz。\n7. 结果与`lmbench`的`mhz`工具（测得3097 MHz）和`/proc/cpuinfo`（显示2.80 GHz）基本一致，符合英特尔睿频加速（Turbo Boost）特性。\n\n**关键洞察：**\n- 此方法能有效规避虚拟化层对硬件信息的伪装，提供更可信的底层性能数据。\n- 高度依赖于对汇编代码的理解和手动调整，确保测量精度。\n- 可作为复杂基准测试前的“基线”参考，帮助识别系统性能瓶颈。\n\n**适用人群：**\n系统工程师、性能调优专家、云计算开发者及对底层硬件行为有深入研究需求的技术人员。","published_at":"2014-04-26T00:00:00Z"}
{"domain":"brendangregg","path":"https://www.brendangregg.com//blog/2014-04-20/a-new-static-blog.html","title":"A New, Static, Blog","summary":"该博客作者分享了使用静态博客引擎 Jekyll 构建个人博客的体验。与传统动态博客（如 WordPress）不同，Jekyll 预先生成静态 HTML 文件，无需运行时数据库或服务器端脚本，因此具有高性能、低延迟和易缓存的优势。作者对比了自己调试一位朋友崩溃的 WordPress 站点的经历：由于云服务商在极短时间内（毫秒级）强制终止耗时过长的 PHP 进程，导致页面无法加载，反映出动态系统在资源限制下的脆弱性。尽管这种“CPU OOM 杀手”机制看似激进，但若阈值合理设置（如几分钟），仍可有效防止资源滥用。\n\n作者是资深性能工程师，曾运营多个技术博客，现就职于 Netflix，未来将通过 Netflix 技术博客分享工作成果，尤其侧重性能优化与协作项目。本文风格随性，内容聚焦计算机性能、技术趣闻与个人探索，旨在为未来搜索者提供实用信息。","published_at":"2014-04-20T00:00:00Z"}
