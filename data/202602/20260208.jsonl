{"domain":"engineeringfb","path":"https://engineering.fb.com/2026/02/04/security/cross-device-passkey-authentication-for-xr-devices-meta-quest/","title":"No Display? No Problem: Cross-Device Passkey Authentication for XR Devices","summary":"Meta发布了一种新型跨设备无屏幕密码验证方案，用于XR设备等无显示设备。该方案基于FIDO联盟的WebAuthn协议和CTAP协议，通过手机App作为“伴侣应用”完成身份验证：当XR设备发起登录时，其浏览器生成包含QR码的FIDO URL；手机App接收通知后，通过BLE/NFC与设备建立安全通道，执行认证并返回结果。此方法无需QR码扫描或物理屏幕，解决了无显示设备的身份验证难题，同时保持了FIDO的安全性和用户友好性，适用于可穿戴设备、物联网及工业硬件等场景。","published_at":"2026-02-04T00:00:00Z"}
{"domain":"arpitbhayani","path":"https://arpitbhayani.me/blogs/multi-paxos","title":"Multi-Paxos - Consensus in Distributed Databases","summary":"本文深入探讨了分布式数据库中的一致性协议——Multi-Paxos，涵盖其理论基础、两阶段协议流程（准备与承诺）、与Paxos的关系、实际应用中的挑战（如领导者选举、故障检测、日志恢复）以及在数据库事务中的实现。文章还对比了其他一致性方案，讨论了性能优化、容错机制、与数据库事务的集成、多分区事务处理等关键议题，并提供了调试和可观测性的建议。","published_at":"2026-01-27T00:00:00Z"}
{"domain":"brooker","path":"https://brooker.co.za/blog/2026/02/07/you-are-here.html","title":"You Are Here","summary":"作者Marc Brooker在博客中探讨了技术行业的转型：传统编程技能的价值正在下降，但新工具带来了前所未有的经济与技术机会。他将行业变迁分为两条路——第一条是旧有技能（如模拟电路设计）的衰退，虽令人失落但仍可获得稳定收益；第二条是面向新系统构建、整合与创新的未来，需解决复杂现实问题，价值更高且更具挑战性。作者认为软件开发已进入“第二幕”，更注重系统集成、解决真实世界难题和创造新价值，而非单纯写代码。他鼓励读者拥抱变化，参与这一更具创造力和经济潜力的新时代。","published_at":"2026-02-07T00:00:00Z"}
{"domain":"cloudflareblog","path":"https://blog.cloudflare.com/ddos-threat-report-2025-q4/","title":"2025 Q4 DDoS threat report: A record-setting 31.4 Tbps attack caps a year of massive DDoS assaults","summary":"Cloudflare 2025年Q4 DDoS威胁报告指出，全球DDoS攻击创纪录，峰值达每秒31.4 Tbps。攻击主要由Aisuru-Kimwolf僵尸网络发动的“平安夜”战役引发，其中HTTP体积型攻击增长40%。网络层攻击增长三倍以上，占总攻击78%。电信、服务提供商和游戏行业成主要目标，中国、德国、巴西为最常受攻击国家。攻击源以印度尼西亚为首，其次是厄瓜多尔和阿根廷。Cloudflare通过其全球网络和AI防护系统应对攻击，并呼吁加强互联网防御。","published_at":"2026-02-05T00:00:00Z"}
{"domain":"thegreenplace","path":"https://eli.thegreenplace.net/2026/compiling-scheme-to-webassembly/","title":"Compiling Scheme to WebAssembly","summary":"本文作者Eli Bendersky分享了其开源项目Bob（Scheme语言的Python实现）将Scheme编译为WebAssembly的过程。项目目标包括：1）实验将高级语言（如Scheme）降至WebAssembly；2）获得WASM GC扩展的实际操作经验。文章详细描述了新加入的WASM编译器模块如何将Scheme表达式转换为WASM文本，并通过标准工具链编译执行。重点介绍了如何用WASM GC表示Scheme对象（如PAIR、BOOL、SYMBOL），以及如何处理字符串和递归数据结构。作者还讨论了实现细节，如通过导入主机函数简化write等内置函数的实现，并指出该项目包含超过1000行LOC代码，其中大部分是WASM文本片段。总结称这是一次有趣且富有收获的实践，推荐读者查看源码学习WASM编译技术。","published_at":"2026-01-17T00:00:00Z"}
{"domain":"thinkingmachines","path":"https://thinkingmachines.ai/blog/tinker-general-availability/","title":"","summary":"Tinker发布四项更新：取消等待列表、新增Kimi K2推理模型、支持OpenAI API接口、集成Qwen3-VL视觉输入。Kimi K2为当前最大模型，适用于长链推理与工具调用；OpenAI兼容采样接口支持即插即用；新增Qwen3-VL-30B-A3B-Instruct与Qwen3-VL-235B-A22B-Instruct两个视觉模型，支持图像、截图和图表处理。通过在Caltech 101、Stanford Cars等数据集上微调，Qwen3-VL在少样本场景下表现优于DINOv2，具备语言+视觉双重能力，可直接用于分类及其他视觉任务。","published_at":"2025-12-12T00:00:00Z"}
{"domain":"simonwillison","path":"https://simonwillison.net/2026/Feb/7/software-factory/","title":"How StrongDM's AI team build serious software without even looking at the code","summary":"本文探讨了StrongDM的AI团队如何在不人工审查代码的情况下构建可靠软件。他们采用“无手写代码”策略，依赖LLM生成代码、测试并自动验证其正确性。核心方法包括：使用Scenario（用户故事）模拟真实场景进行验证；构建Digital Twin Universe（数字孪生宇宙），克隆第三方服务以实现无限制测试；引入Gene Transfusion和Pyramid Summaries等技术加速开发。作者认为这代表了未来软件开发范式——从编写代码转向构建和监控系统，大幅降低对人类工程师的依赖，但需权衡成本与可行性。","published_at":"2026-02-07T00:00:00Z"}
{"domain":"brendangregg","path":"https://www.brendangregg.com//blog/2026-02-07/why-i-joined-openai.html","title":"Why I joined OpenAI","summary":"Brendan Gregg在博客中分享了他加入OpenAI的原因与经历。他认为AI数据中心的性能工程不仅是成本问题，更是拯救地球的关键挑战。通过采访多位行业专家和实际体验ChatGPT，他意识到AI已深入日常生活，并成为不可或缺的工具。他强调性能工程需要突破规模限制、优化系统效率，以应对海量数据与复杂计算需求。此外，他对OpenAI的工程师团队印象深刻，认为其高度专业且富有远见。他还回顾了自己对“Orac”这一科幻计算机的童年梦想，并分享了将ChatGPT个性化为“Orac”风格的趣味实验。目前，他在OpenAI担任技术员工，专注于ChatGPT性能工程，致力于推动高效、低成本的数据中心解决方案。","published_at":"2026-02-07T00:00:00Z"}
{"domain":"muratbuffalo","path":"https://muratbuffalo.blogspot.com/2026/02/ostep-chapters-67.html","title":"OSTEP Chapters 6,7","summary":"该博客文章总结了《OSTEP》教材第6、7章内容，主要探讨操作系统如何通过CPU虚拟化实现多任务并发。第6章介绍“有限直接执行”（LDE）机制，通过硬件支持（如用户/内核模式切换、定时器中断）让操作系统在程序陷入无限循环或需要I/O时接管CPU控制权；并以x86上下文切换代码为例说明进程切换过程。第7章讨论CPU调度策略，包括FIFO、SJF、STCF等批处理调度算法及响应时间（Response Time）概念，并分析Round Robin调度的优缺点。最后指出调度策略需结合工作负载实际，没有万能方案，强调“观察过去预测未来”的设计哲学。","published_at":"2026-02-05T00:00:00Z"}
{"domain":"uberblog","path":"https://www.uber.com/en-SG/blog/scaled-data-replication/","title":"How Uber Scaled Data Replication to Move Petabytes Every Day","summary":"本文探讨了Uber如何通过优化Distcp工具，实现每日处理PB级数据的高效复制。重点介绍了在HiveSync架构下，通过并行化Copy Listing、Copy Committer和Mapper任务，显著提升数据复制效率与YARN资源利用率。文章分析了早期版本的性能瓶颈（如单线程复制、资源争用），并展示了通过多线程、异步IO、批处理等技术改进后，系统吞吐量提升5倍以上，同时降低对集群资源的占用。最终，Uber实现了无缝数据迁移至云端的能力，并为未来扩展提供了可伸缩的架构基础。","published_at":"0001-01-01T00:00:00Z"}
{"domain":"sebastianraschka","path":"https://sebastianraschka.com/blog/2026/state-of-ai-interview.html","title":"","summary":"本文为Sebastian Raschka与Lex Fridman、Nathan Lambert的4.5小时深度访谈，探讨2026年AI发展现状与前景。内容涵盖大语言模型（LLM）的地缘政治、训练与微调方式、开源与闭源模型对比、编码助手、工具链、前沿研究方向，以及AGI时间线、计算资源、行业与社会长期影响。视频版本包含图表与动画，提供更直观理解。访谈涵盖从AI竞赛（中美）、主流模型比较（ChatGPT/ Claude/Gemini/Grok）、开源 vs 闭源、Transformer演进、Scaling Laws、训练流程、后训练技术、入门建议、工作文化、硅谷泡沫、扩散模型、持续学习、长上下文、机器人、AGI时间线、AI替代程序员、AGI是否消亡、盈利模式、2026年大并购、OpenAI等公司未来、曼哈顿计划式AI、NVIDIA/GPU/计算集群未来，直至人类文明的未来。","published_at":"2026-02-01T00:00:00Z"}
{"domain":"googleblog","path":"https://developers.googleblog.com/en/introducing-the-developer-knowledge-api-and-mcp-server/","title":"Introducing the Developer Knowledge API and MCP Server","summary":"Google发布Developer Knowledge API与MCP服务器，为AI开发者提供官方文档的程序化访问接口。该API可直接检索Firebase、Android等官方文档的Markdown内容，确保信息最新且结构清晰。配合MCP服务器，AI助手能安全访问外部数据源，实现如实现Firebase推送通知指南、故障排查及云服务对比分析等功能。开发者可通过创建API密钥、启用MCP服务器并配置工具完成接入。未来将支持结构化内容和代码示例，提升文档可用性。","published_at":"2026-02-04T00:00:00Z"}
{"domain":"amazonscience","path":"https://www.amazon.science/blog/a-decade-of-nfl-next-gen-stats-innovation","title":"A decade of NFL Next Gen Stats innovation","summary":"本文介绍了NFL如何通过Next Gen Stats（NGS）系统，利用RFID芯片和机器学习技术，在十年间实现比赛数据的革命性创新。该系统每秒捕捉25次球员位置数据，用于分析比赛策略、球员表现与安全。文章重点阐述了NGS如何推动“大数据碗”竞赛、构建关键指标（如擒抱概率、防守评估）、提升球员安全与规则变化，并通过光学追踪技术实现三维定位。NGS不仅优化了教练决策和球迷体验，还为未来体育科技发展提供了范式。","published_at":"2026-02-02T00:00:00Z"}
{"domain":"kaiwaehner","path":"https://www.kai-waehner.de/blog/2026/02/04/the-ultimate-data-streaming-guide-book-second-edition-and-industry-editions-now-available/","title":"The Ultimate Data Streaming Guide is Back – Second Edition of the Book and Industry Editions Now Available","summary":"本文宣传Kai Waehner的《终极数据流指南》第二版，新增70个用例、20个行业版（如金融、制造、电信等），聚焦AI、GenAI、Apache Kafka、Flink及Confluent平台。新版包含72个跨行业案例、300多页内容、扩展客户案例与长期企业级应用策略，强调实时解决方案在金融、制造、汽车、电信、媒体及数字原生领域的价值。文章同时提供免费下载链接，并推荐相关技术博客和订阅服务。","published_at":"2026-02-04T00:00:00Z"}
{"domain":"cloudflareblog","path":"https://blog.cloudflare.com/r2-local-uploads/","title":"Improve global upload performance with R2 Local Uploads","summary":"Cloudflare 推出 R2 Local Uploads 功能，旨在提升全球上传性能。该功能通过在客户端本地缓存对象数据，减少跨区域传输延迟，实现75%的请求时延降低，且无额外费用。其核心是解决“距离问题”——当客户端与存储桶位于不同地理区域时，Local Uploads 会将数据先写入本地，再异步复制到目标区域，避免了传统方式中等待跨区域复制完成才能读取的问题。该功能适用于全球分布、对性能和可靠性要求高的应用，尤其适合读写请求地理分布不一致的场景。技术实现上，采用异步复制模型（Pull model），通过队列系统调度任务，并保证数据一致性与失败重试机制。用户可通过 Cloudflare Dashboard 或 Wrangler 命令行启用。","published_at":"2026-02-03T00:00:00Z"}
{"domain":"thinkingmachines","path":"https://thinkingmachines.ai/blog/call-for-community-projects/","title":"","summary":"Thinking Machines Lab 发布 Tinker 平台，鼓励研究者和开发者用其训练、定制模型。文章邀请社区提交项目至博客展示，并提供 Featured Projects 的具体方向，如复现研究、新算法探索、非AI领域应用、产品原型、新数据集、库与基础设施等。同时列出多个研究建议，例如复现 Constitutional AI、RLVR 与 Noisy Student 结合、On-Policy Context Distillation、RL memory test、Direct RL on pairwise judge、Replicate Open Character Training、GAN for jokes 等。最后给出高质量 ML 实验的实践建议：多分析结果、多样化模型与评估、对比基线方法、验证敏感超参（如学习率）、强调透明性与可视化。投稿邮箱：tinker@thinkingmachines.ai。","published_at":"2025-11-07T00:00:00Z"}
{"domain":"muratbuffalo","path":"https://muratbuffalo.blogspot.com/2026/02/friction.html","title":"The F word","summary":"本文以作者在SUNY Buffalo计算机系的经历为引子，讲述了一个从高效顺畅的报销流程（Joann时代）如何因系统设计缺陷和过度审计而演变为繁琐低效的过程。核心观点是：当组织或个人的目标从‘解决问题’转向‘寻找错误’时，摩擦力就会取代生产力，成为系统的核心产物。作者强调，意图决定过程——若目标聚焦于成长与流动，系统会自然优化；若聚焦于审查与惩罚，则会制造内耗。文章呼吁重新审视工作流程中的“意图设定”，避免将精力浪费在找茬上，而应致力于推动进展、积累动量（momentum），并以此作为衡量成功的关键标准。","published_at":"2026-02-03T00:00:00Z"}
{"domain":"uberblog","path":"https://www.uber.com/en-SG/blog/apache-hudi-at-uber/","title":"Apache Hudi™ at Uber: Engineering for Trillion-Record-Scale Data Lake Operations","summary":"本文介绍了Uber如何通过Apache Hudi构建其大规模数据生态系统，重点阐述了Hudi在数据湖架构中的核心作用。文章从Hudi的设计理念、与开源社区的协作（如6300个GitHub星标项目）、数据处理能力（支持万亿级记录、每日数十亿数据更新）等方面展开，详细说明了Hudi如何解决传统数据湖的痛点，例如增量处理、事务性写入和高效查询。同时，文章还探讨了Uber的数据技术栈、Hudi在实际生产环境中的应用案例（如实时注入、批处理优化），以及未来发展方向，强调Hudi作为Uber数据基础设施的核心组件，支撑着其业务的持续增长与技术创新。","published_at":"0001-01-01T00:00:00Z"}
{"domain":"uberblog","path":"https://www.uber.com/en-SG/blog/from-static-rate-limiting-to-intelligent-load-management/","title":"How Uber Conquered Database Overload: The Journey from Static Rate-Limiting to Intelligent Load Management","summary":"本文详细介绍了Uber如何通过构建统一的负载管理器（Unified Load Manager）来应对分布式数据库系统中的高负载挑战，核心是用Cedal（Controlled Delay）替代CoDel，实现更智能的队列调度与资源控制。文章重点阐述了在Quota-Based Rate Limiting、Balancing Resilience and Fairness、Performance and Stability等场景下的优化方案，包括引入Scored Engine进行优先级调度、Regulators控制资源使用、以及通过Cinnamon替换CoDel提升系统稳定性。最终，Uber实现了更可预测、更高效的负载管理架构，显著提升了系统吞吐量和稳定性，并降低了运维复杂度。","published_at":"0001-01-01T00:00:00Z"}
{"domain":"googleblog","path":"https://developers.googleblog.com/en/easy-functiongemma-finetuning-with-tunix-on-google-tpus/","title":"Easy FunctionGemma finetuning with Tunix on Google TPUs","summary":"本文介绍了如何使用 Tunix 在 Google TPU 上对 FunctionGemma 模型进行 LoRA 微调。文章详细说明了从下载模型权重和数据集、配置 LoRA 适配器、定义自定义数据集与数据生成器，到启动训练并监控性能的完整流程。实验结果显示，微调后模型准确率显著提升，TPU 利用率高（90.9%），且训练耗时短。最后，作者建议将微调后的模型导出为 safetensors 格式以供下游部署，并指出 Tunix 是连接研究原型与生产系统的实用工具，未来还将增强其训练能力。","published_at":"2026-02-03T00:00:00Z"}
{"domain":"simonwillison","path":"https://simonwillison.net/2026/Feb/6/pydantic-monty/","title":"Running Pydantic's Monty Rust sandboxed Python subset in WebAssembly","summary":"本文介绍了Pydantic推出的Monty项目，它是一个轻量级的Python子集，可在WebAssembly环境中运行LLM生成的代码，避免传统容器沙箱的成本与延迟。Monty支持有限的Python语法（不支持类声明），但能安全执行LLM生成的代码，通过外部函数控制主机访问权限。作者在浏览器中通过Claude Code和Pyodide实现编译与运行，并构建了WASM文件与HTML演示页，支持在浏览器和Pyodide中调用。文章还提供了两个GitHub Pages演示：Monty WASM UI（JavaScript调用）和Monty Pyodide界面（Pyodide加载WASM）。Monty具有内存、CPU和网络限制，适合快速迭代调试，是将C/Rust等编译语言转换为WebAssembly并在浏览器与Pyodide中运行的优秀工具。","published_at":"2026-02-06T00:00:00Z"}
{"domain":"kaiwaehner","path":"https://www.kai-waehner.de/blog/2026/01/28/when-to-use-queues-for-kafka/","title":"When (Not) to Use Queues for Kafka?","summary":"本文探讨了Kafka如何通过消息队列实现流式数据处理与系统集成，对比了传统MQ（如IBM MQ、RabbitMQ）与Kafka的差异。Kafka作为下一代中间件，擅长高吞吐、低延迟的实时数据流处理，适用于云原生、微服务架构。文章介绍了Kafka的核心概念（如Message Queue、Producer/Consumer模型）、与传统MQ的优劣对比（如可靠性、历史访问支持、轻量级等），并阐述了其在现代集成生态系统中的角色——不仅是消息队列，更是数据流平台和事件驱动架构的基础。适合对分布式系统、实时数据处理、云架构感兴趣的开发者与架构师阅读。","published_at":"2026-01-28T00:00:00Z"}
{"domain":"thinkingmachines","path":"https://thinkingmachines.ai/blog/tinker-research-and-teaching-grants/","title":"","summary":"Thinking Machines Lab 宣布推出 Tinker 研究与教学资助计划，旨在支持学术界和非营利组织使用 Tinker 训练开放权重大语言模型（LLMs）。提供两类资助：教学资助（每名学生250美元信用额度）和研究资助（起始金额5000美元）。已授予的早期资助案例包括斯坦福大学的“以人为中心的LLMs”课程、CMU的“深度强化学习”课程以及斯坦福Grant Rotskoff实验室在分子化学模型上的研究。申请采用滚动审核，预计一周内回复。","published_at":"2025-10-29T00:00:00Z"}
{"domain":"simonwillison","path":"https://simonwillison.net/2026/Feb/4/distributing-go-binaries/","title":"Distributing Go binaries like sqlite-scanner through PyPI using go-to-wheel","summary":"本文介绍了作者开发的Go二进制文件分发工具`sqlite-scanner`，它通过PyPI发布，允许用户以简单包名调用Go二进制文件。该工具扫描文件系统中的SQLite数据库文件，支持多种输出格式（文本/JSON），并能递归搜索多目录。文章详细说明了其工作原理（基于文件名匹配和PyPI打包机制）、Python包实现细节（`__init__.py`与`main()`函数）、作为依赖项在其他Go项目中使用的可行性，并演示了如何用`go-to-wheel`构建和分发Python包。作者还分享了使用此模式的实践经验，强调Go与Python结合在构建自包含、高性能工具方面的优势，尤其适合WebAssembly或无依赖运行环境。","published_at":"2026-02-04T00:00:00Z"}
{"domain":"kaiwaehner","path":"https://www.kai-waehner.de/blog/2026/01/22/diskless-kafka-at-fintech-robinhood-for-cost-efficient-log-analytics-and-observability/","title":"Diskless Kafka at FinTech Robinhood for Cost-Efficient Log Analytics and Observability","summary":"本文探讨了Diskless Kafka如何通过简化架构提升金融与科技服务领域的日志分析和可观测性能力。文章介绍了Robinhood如何利用Apache Kafka与Flink构建实时数据流平台，实现低延迟、高吞吐的数据处理，并在成本节约、系统简化方面取得显著成效。通过移除传统中间件，Diskless Kafka降低了运维复杂度与资源消耗，同时支持云原生部署。文章还提及了Kafka与WarpStream结合带来的性能提升，以及其在欺诈检测、实时交易、加密货币等场景的应用。最终，该技术推动了FinTech行业向实时数据驱动转型，成为新一代流处理标准。","published_at":"2026-01-22T00:00:00Z"}
{"domain":"cloudflareblog","path":"https://blog.cloudflare.com/vertical-microfrontends/","title":"Building vertical microfrontends on Cloudflare’s platform","summary":"本文介绍Cloudflare如何通过垂直微前端（Vertical Microfrontends）架构解决团队协作与技术栈碎片化问题。文章定义了垂直微前端的概念，强调其按业务功能划分而非技术模块，支持独立开发、部署和体验一致性。重点介绍了视觉统一、视图过渡、预加载、零配置路由、服务绑定和HTML重写等关键技术实践，并提供实际代码示例和配置指南。最后引导读者如何在Cloudflare Dashboard中快速搭建微前端项目，适用于希望提升团队协作效率和用户体验的开发者与架构师。","published_at":"2026-01-30T00:00:00Z"}
{"domain":"thinkingmachines","path":"https://thinkingmachines.ai/blog/on-policy-distillation/","title":"","summary":"本文探讨了政策蒸馏（On-Policy Distillation）在强化学习与教学模型中的应用，旨在通过教师模型指导学生模型训练，提升效率与性能。文章对比了离策略蒸馏（Off-policy）与政策蒸馏（On-policy）的优劣，指出政策蒸馏在保持高精度的同时显著降低计算成本（如GPU小时数减少30%）。实验表明，基于Qwen3-8B的政策蒸馏模型在数学推理任务上表现优异，甚至超越了传统强化学习方法。此外，文章还讨论了其在个性化教学、知识迁移和资源受限场景下的实用价值，并提出未来可结合SFT进行更高效微调。整体而言，该方法兼具学术创新性与工程实用性，为大模型训练提供了低成本、高效率的新路径。","published_at":"2025-10-27T00:00:00Z"}
{"domain":"kaiwaehner","path":"https://www.kai-waehner.de/blog/2026/01/16/shift-left-in-automotive-real-time-intelligence-from-vehicle-telemetry-with-data-streaming-at-rivian/","title":"Shift Left in Automotive: Real-Time Intelligence from Vehicle Telemetry with Data Streaming at Rivian","summary":"本文探讨了Rivian与RV Tech如何通过实时数据流技术，助力大众汽车集团（Volkswagen Group）实现电动车辆的智能化转型。文章重点介绍了Rivian的“Shift Left”架构如何将数据处理提前至车辆端，使数据延迟从5秒降至0.5秒，并减少88%的云端数据量。同时，文章分析了在汽车行业中应用Kafka、Flink和Druid等技术构建实时数据管道的挑战与解决方案，强调了从原始遥测数据到实时业务洞察的价值转化。此外，还提及了Rivian如何利用这些技术提升车辆维护、安全监控、能源管理及用户体验，并展示了其在自动驾驶和车联网领域的创新实践。","published_at":"2026-01-16T00:00:00Z"}
{"domain":"thinkingmachines","path":"https://thinkingmachines.ai/blog/announcing-tinker/","title":"","summary":"Thinking Machines Lab 宣布推出 Tinker，一个灵活的 API，用于微调语言模型。它让研究人员和开发者能控制算法与数据，同时处理分布式训练的复杂性。Tinker 支持微调多种大模型（如 Qwen-235B-A22B），并提供托管服务，自动管理资源、调度与故障恢复。其 API 提供底层原语（如 forward_backward 和 sample），并配套开源库 Tinker Cookbook 以简化实现。已有 Princeton、Stanford、Berkeley 和 Redwood Research 等机构使用。目前 Tinker 处于私有测试阶段，免费启动，未来将推出按用量计费模式。","published_at":"2025-10-01T00:00:00Z"}
{"domain":"cloudflareblog","path":"https://blog.cloudflare.com/moltworker-self-hosted-ai-agent/","title":"Introducing Moltworker: a self-hosted personal AI agent, minus the minis","summary":"本文介绍Moltbot——一个自托管的个人AI代理，可替代传统AI助手（如Mac mini）。它通过Cloudflare Workers运行，支持Node.js，兼容主流NPM包，无需专用硬件。文章详细说明了如何在Cloudflare环境中部署Moltbot，包括AI Gateway、Sandboxes、R2持久化存储、浏览器渲染及零信任认证等核心功能。作者分享了实际应用案例，如用Moltbot在浏览器中导航Google地图、生成视频教程，并强调其开源特性与Cloudflare平台的集成优势。最后呼吁开发者参与贡献，共同推动下一代AI产品生态。","published_at":"2026-01-29T00:00:00Z"}
{"domain":"kaiwaehner","path":"https://www.kai-waehner.de/blog/2026/01/08/etihad-airways-makes-airline-operations-real-time-with-data-streaming/","title":"Etihad Airways Makes Airline Operations Real-Time with Data Streaming","summary":"本文探讨了阿提哈德航空如何通过实时数据流（结合 Apache Kafka 和 Flink）解决航空业的数据延迟问题，实现从‘数据滞后’到‘数据流畅’的转型。文章介绍了阿提哈德航空在迪拜数据流世界巡回展中的实践，重点展示了其基于事件驱动架构的实时决策系统，用于航班延误预警、乘客服务优化和运营效率提升。核心价值在于利用实时数据让航空运营更敏捷、决策更智能，并推动行业向 AI 驱动的未来迈进。","published_at":"2026-01-08T00:00:00Z"}
{"domain":"thinkingmachines","path":"https://thinkingmachines.ai/blog/lora/","title":"","summary":"本文探讨了LoRA（Low-Rank Adaptation）在大型语言模型微调中的表现，对比其与Full Fine-Tuning的效率和效果。研究发现：LoRA在保持性能接近Full Fine-Tuning的同时，显著降低计算资源需求；其效果受学习率、批次大小及模型结构影响；在不同任务和模型上，LoRA的最优超参数存在差异；实验表明LoRA对小规模数据集更有效，且能有效缓解过拟合；此外，文章分析了LoRA的理论基础，包括其在优化过程中的梯度更新机制和容量限制，并讨论了其在实际应用中的优势与局限。","published_at":"2025-09-29T00:00:00Z"}
{"domain":"googlepubs","path":"https://research.google/pubs/snpeek-side-channel-analysis-for-privacy-applications-on-confidential-vms/","title":"SNPeek: Side-Channel Analysis for Privacy Applications on Confidential VMs","summary":"该论文提出FARFETCH'D框架，用于评估可信执行环境（TEE）下的保密虚拟机（CVMs）面临的侧信道攻击。传统CVMs虽提供隐私保护，但易受侧信道攻击。FARFETCH'D通过可配置攻击原语和机器学习分析管道，在真实CVM硬件上执行评估，有效识别隐私应用中的漏洞，并帮助制定基于内存和差分隐私的缓解策略。","published_at":"0001-01-01T00:00:00Z"}
{"domain":"thinkingmachines","path":"https://thinkingmachines.ai/blog/modular-manifolds/","title":"","summary":"本文探讨了在神经网络训练中，如何通过约束权重矩阵的结构（如曼ifold约束）来替代传统归一化方法，以提升模型稳定性与训练效率。作者提出“模态流形”（Modular Manifolds）概念，将权重矩阵约束建模为流形空间中的优化问题，并引入“流形穆恩”（Manifold Muon）作为优化器，通过几何视角重新设计梯度下降过程。文章结合数学推导、可视化图示和实验结果，论证了该方法在避免数值溢出、提升收敛性方面的优势，并讨论其在现代深度学习架构中的扩展潜力与未来研究方向，如非黎曼几何、正则化、收敛性分析等。","published_at":"2025-09-26T00:00:00Z"}
{"domain":"googlepubs","path":"https://research.google/pubs/developer-productivity-in-the-age-of-generative-ai-a-psychological-perspective/","title":"Developer Productivity in the Age of Generative AI: A Psychological Perspective","summary":"该论文从心理学角度探讨生成式AI对开发者生产力的影响，基于对12名资深工程师的访谈研究。核心发现包括：（1）开发者角色从‘编码者’转向‘指导者’，AI作为认知伙伴；（2）生产力衡量标准从产出转向影响；（3）AI既增强自主性又引发技能焦虑的双重效应。建议在实施过程中优先考虑架构能力与元认知监督，以维持开发者动力与系统完整性。","published_at":"0001-01-01T00:00:00Z"}
{"domain":"thinkingmachines","path":"https://thinkingmachines.ai/blog/defeating-nondeterminism-in-llm-inference/","title":"","summary":"本文探讨了在LLM推理中面临的非确定性问题，特别是浮点运算的非结合性如何影响模型输出。作者通过实验和数学分析揭示了GPU并行计算、浮点精度损失及批处理不一致性等导致结果不可重现的根本原因，并提出通过固定随机种子、使用更高精度数据类型（如float64）、避免并行化操作、以及在训练和推理时保持一致的批处理策略来缓解该问题。文章还介绍了RMSNorm层在批处理中的不稳定性，以及如何通过调整批大小或启用“分裂并行”策略实现批处理不变性。最后，作者总结指出，现代系统对数值稳定性的要求日益提高，需从底层硬件到上层算法全面优化以提升可复现性。","published_at":"2025-09-10T00:00:00Z"}
{"domain":"sebastianraschka","path":"https://sebastianraschka.com/blog/2025/coding-the-kv-cache-in-llms.html","title":"","summary":"本文深入解析了在大型语言模型（LLM）中实现KV缓存（Key-Value Cache）的技术原理与实践，旨在提升推理效率。文章首先解释了KV缓存如何通过存储先前生成的键值对来避免重复计算，从而加速文本生成。接着，作者详细介绍了从零开始在PyTorch中构建一个简易KV缓存系统，包括注册缓冲区、使用缓存标志、清理缓存和在完整模型中传播缓存等步骤。文章还提供了性能对比数据，展示了启用KV缓存后推理速度的显著提升（如从27 tokens/sec提升至144 tokens/sec）。最后，讨论了KV缓存的优势（如减少计算开销）与潜在问题（如内存占用），并给出了优化建议（如预分配内存、滑动窗口机制）。整体而言，这是一篇兼具理论深度与工程实践的教程，适合希望深入了解LLM优化技术的开发者。","published_at":"2025-06-17T00:00:00Z"}
{"domain":"googlepubs","path":"https://research.google/pubs/who-am-i-talking-to-a-large-scale-measurement-of-surface-attribution-across-real-world-security-and-privacy-interfaces/","title":"Who am I Talking to? A Large-Scale Measurement of Surface Attribution Across Real-World Security and Privacy Interfaces","summary":"该研究通过两项大规模视觉调查（桌面端N=4,400，移动端N=3,057）首次实证测量用户对界面元素来源的‘表面归属’能力。结果显示，用户仅能在55%（桌面）和53%（移动端）的情况下正确识别UI元素来源；熟悉度与强品牌提示可显著提升准确性，而UI布局或‘安全与隐私’品牌提示则无明显帮助。研究指出，当前依赖用户心理模型区分可信UI的设计存在根本性缺陷，构成脆弱的安全范式。","published_at":"0001-01-01T00:00:00Z"}
{"domain":"sebastianraschka","path":"https://sebastianraschka.com/blog/2025/understanding-reasoning-llms.html","title":"","summary":"本文系统介绍了构建和优化推理模型（Reasoning Models）的四种主要方法：1) 推理时间缩放（Inference-time scaling），通过提示工程或思维链提升模型推理能力；2) 纯强化学习（Pure reinforcement learning），如DeepSeek-R1通过RLHF训练提升推理性能；3) 监督微调与蒸馏（SFT + RL），结合监督微调与强化学习提升模型表现，例如DeepSeek-R1在多个基准测试中超越GPT-4；4) 纯监督微调与蒸馏（Pure supervised finetuning and distillation），通过数据蒸馏降低计算成本。文章还探讨了在预算有限条件下开发推理模型的策略，包括使用更小模型、知识蒸馏及分阶段训练等，并分析了不同方法在性能、成本和效率上的权衡。最后指出当前大模型虽强大，但仍有优化空间，未来需在推理效率与成本之间寻找平衡。","published_at":"2025-02-05T00:00:00Z"}
{"domain":"cloudflareblog","path":"https://blog.cloudflare.com/iran-protests-internet-shutdown/","title":"What we know about Iran’s Internet shutdown","summary":"该博客文章详细记录了2026年1月伊朗因国内抗议活动引发的互联网断网事件。文章指出，自1月8日起，伊朗网络流量骤降98.5%，IPv6地址空间被大规模宣告，导致全球互联网无法连接至伊朗IP地址。随后在1月9日，尽管出现短暂恢复窗口（如大学和部分城市），但整体流量仍维持极低水平，接近零。HTTP流量也同步下降，显示用户访问行为受明显抑制。文章强调，此次断网是伊朗政府长期限制网络自由的延续，且目前仍处于持续状态，仅剩极少量内部数据流通。Cloudflare通过其雷达系统监测并分析了此次事件的技术细节与影响范围。","published_at":"2026-01-13T00:00:00Z"}
{"domain":"googlepubs","path":"https://research.google/pubs/adcanvas-accessible-and-conversational-audio-description-authoring-for-blind-and-low-vision-creators/","title":"ADCanvas: Accessible and Conversational Audio Description  Authoring for Blind and Low Vision Creators","summary":"ADCanvas 是一个为盲人和低视力创作者设计的无障碍对话式音频描述写作系统，结合了对话交互、键盘控制播放、纯文本屏幕阅读器和视觉问答（VQA）功能。通过与多模态大语言模型合作，支持实时VQA、脚本生成和音频描述修改。用户研究显示，创作者将该工具作为信息助手和写作助理，同时保持内容的自主性。研究为无障碍媒体工具设计提供启示，包括精准编辑控件、创作创意支持及人机协作规则。","published_at":"0001-01-01T00:00:00Z"}
{"domain":"sebastianraschka","path":"https://sebastianraschka.com/blog/2024/llm-research-insights-instruction.html","title":"","summary":"本文总结了2024年5月大语言模型（LLM）领域的最新研究进展，重点探讨了指令微调（Instruction Tuning）中的提示词掩码（Instruction Masking）技术、LoRA的遗忘特性及其在参数高效微调中的应用，以及MoRA等新型参数高效微调方法。文章还列出了当月值得关注的其他研究论文，并提供了相关讨论和订阅建议。","published_at":"2024-06-02T00:00:00Z"}
{"domain":"sebastianraschka","path":"https://sebastianraschka.com/blog/2024/using-finetuning-transformers.html","title":"","summary":"本文系统介绍了使用和微调预训练Transformer模型的多种方法，包括特征提取、微调（Fine-tuning）、提示词学习（Prompt Learning）以及参数高效微调（Parameter-Efficient Finetuning）。文章详细解释了不同方法的原理、适用场景与优缺点，并通过图示和代码示例说明了如LoRA、Adapter、Prefix Tuning等技术。此外，还探讨了强化学习与人类反馈结合的训练方式，以及预训练语言模型的未来发展方向。最后提供了相关资源链接和练习题，帮助读者深入理解。","published_at":"2024-04-20T00:00:00Z"}
{"domain":"sebastianraschka","path":"https://sebastianraschka.com/blog/2024/lora-dora.html","title":"","summary":"本文介绍了LoRA（Low-Rank Adaptation）及其改进版DoRA（Weight-Decomposed Low-Rank Adaptation），一种用于微调大语言模型的高效方法。LoRA通过在预训练权重中添加低秩矩阵来实现参数高效微调，而DoRA进一步将权重矩阵分解为方向向量和幅度向量，从而更精确地调整模型。文章详细阐述了两种方法的数学原理、PyTorch实现步骤，并通过实验对比展示了DoRA在性能上的提升（如在LLaMA-7B上提升1.5%）。作者还提供了完整代码和训练示例，适合对模型微调感兴趣的开发者。","published_at":"2024-02-18T00:00:00Z"}
{"domain":"sebastianraschka","path":"https://sebastianraschka.com/blog/2023/optimizing-LLMs-dataset-perspective.html","title":"","summary":"本文从数据集视角探讨优化大语言模型（LLM）的方法，重点介绍监督指令微调（SFT）与LLM生成数据的结合策略。文章涵盖：1）LLM生成数据的优缺点及构建流程；2）高质量数据未必更有效，需关注数据质量而非单纯数量；3）在LIMA等开源数据集上微调LLM的实践步骤；4）可用模型与数据集（如GPT、Llama 2、Falcon等）；5）如何准备新数据集及考虑其他开源数据集（如Open Assistant、P3、Plan 2021）；6）未来研究方向，包括数据合并、排序、多任务训练和自动质量过滤。结论建议开发者结合现有资源，参与NeurIPS挑战，并持续探索高效微调方法。","published_at":"2023-09-15T00:00:00Z"}
{"domain":"sebastianraschka","path":"https://sebastianraschka.com/blog/2023/pytorch-memory-optimization.html","title":"","summary":"本文总结了在PyTorch中优化LLMs和视觉Transformer内存使用的10种实用技术，包括：1）微调视觉Transformer；2）自动混合精度训练；3）低精度训练（如FP16/INT8）；4）减小批大小；5）梯度累积；6）使用更优的优化器（如AdamW）；7）在目标设备上创建模型；8）分布式训练与张量切分；9）参数卸载；10）整合所有技术并训练LLM。每项技术均附有代码示例、性能对比图表及适用场景说明，旨在降低显存占用、提升训练效率，特别适用于资源受限环境下的大模型训练。","published_at":"2023-07-01T00:00:00Z"}
{"domain":"sebastianraschka","path":"https://sebastianraschka.com/blog/2023/llm-mixed-precision-copy.html","title":"","summary":"本文探讨了使用混合精度训练（Mixed-Precision Training）加速大语言模型（LLM）的方法。文章首先解释了32位浮点数（float32）与16位浮点数（float16）的结构差异及其在计算中的精度和内存效率问题。接着介绍了混合精度训练的核心机制：模型权重以FP32存储，但在前向和反向传播中使用FP16进行计算，通过自动混合精度（AMP）或手动调整实现。文章通过实验对比了不同精度设置下的训练速度、显存占用和模型准确率，发现float16能显著提升速度并降低显存消耗，而bf16（Brain Floating Point）则在精度上更接近float32。此外，文章还介绍了LLaMA等模型如何通过量化（Quantization）进一步优化推理性能，并总结了混合精度训练对提升训练效率和模型性能的实际价值。","published_at":"2023-05-11T00:00:00Z"}
{"domain":"sebastianraschka","path":"https://sebastianraschka.com/blog/2023/llm-finetuning-llama-adapter.html","title":"","summary":"本文深入探讨了参数高效微调（Parameter-Efficient Fine-tuning, PEFT）技术，特别是针对大语言模型（LLM）的微调方法，涵盖从预训练模型到LLaMA适配器（LLAMA-Adapters）的演进。文章介绍了三种主流微调范式：基于特征的方法（Feature-Based）、仅更新输出层（Finetuning I）和更新所有层（Finetuning II），并对比了它们在准确率与计算效率上的表现。重点介绍了参数高效微调的核心思想——通过只调整少量参数实现模型性能提升，并详细解析了提示词微调（Prompt Tuning）、前缀微调（Prefix Tuning）以及LLaMA适配器（LLAMA-Adapter）等关键技术。文章还通过图表和伪代码展示了不同架构（如常规Transformer、带适配器的Transformer、带前缀的Transformer）的工作原理，强调LLaMA-Adapter通过在每一层插入小型适配器模块，在保持模型性能的同时显著降低计算开销。最后，作者总结PEFT是当前高效微调LLM的前沿方法，推荐读者尝试书中介绍的技术，并鼓励提供反馈。","published_at":"2023-04-12T00:00:00Z"}
{"domain":"sebastianraschka","path":"https://sebastianraschka.com/blog/2023/self-attention-from-scratch.html","title":"","summary":"本文深入解析了大型语言模型（LLM）中自注意力机制的原理与实现，从零开始逐步讲解其数学基础、编码过程及多头注意力结构。作者通过PyTorch代码示例，详细演示了如何计算查询/键/值向量、未归一化注意力权重、归一化注意力权重以及多头注意力的并行计算。文章还对比了自注意力与交叉注意力的区别，并探讨了其在Transformer架构中的作用。最终总结指出，理解自注意力是掌握LLM的关键，建议读者动手实践以加深理解。","published_at":"2023-02-09T00:00:00Z"}
{"domain":"sebastianraschka","path":"https://sebastianraschka.com/blog/2022/lightning-app-srgan-2.html","title":"","summary":"本文是Sebastian Raschka撰写的《共享深度学习研究模型：利用闪电App第二部分》的博客，主要介绍如何使用Lightning App在云端共享和运行深度学习模型。文章详细讲解了Lightning App的架构（Root Flow与Work组件）、如何在云端配置资源（如选择硬件、设置依赖）、通过Python脚本训练模型、保存与下载文件输出（包括本地与云存储路径差异），以及如何创建更复杂的PyTorch应用。作者还提供了实用技巧，如调试方法、模型权重保存策略，并推荐读者尝试构建自定义组件以扩展功能。整体目标是帮助研究人员轻松将模型部署到云端，实现跨平台协作与共享。","published_at":"2022-06-30T00:00:00Z"}
{"domain":"sebastianraschka","path":"https://sebastianraschka.com/blog/2022/lightning-app-srgan-1.html","title":"","summary":"本文是《分享深度学习研究模型与 Lightning Part 1：构建超分辨率应用》系列的第一部分，旨在引导读者从零开始使用 Lightning Framework 构建一个超分辨率图像处理的深度学习应用。文章首先介绍 Lightning 的核心概念（LightningApp、LightningWork、LightningFlow），接着通过“Hello World”示例演示如何搭建最小化应用，然后深入讲解如何开发一个完整的超分辨率应用，包括文件结构、组件配置、模型加载与推理逻辑。最后，文章指导如何运行和部署该应用，并预告下一部分将讨论云端部署。全文结合代码示例、架构图和界面截图，适合希望快速上手 Lightning 框架并构建可部署深度学习应用的开发者。","published_at":"2022-06-17T00:00:00Z"}
{"domain":"sebastianraschka","path":"https://sebastianraschka.com/blog/2022/losses-learned-part1.html","title":"","summary":"本文是《在PyTorch中优化负对数似然与交叉熵损失（第一部分）》的技术博客，深入探讨了二分类任务中负对数似然损失和交叉熵损失的数学原理、实现方式及在PyTorch中的具体应用。文章从基础概念入手，解释了逻辑回归、sigmoid函数与交叉熵损失的关系，并通过代码示例演示了如何从零开始实现这些损失函数。同时，对比了PyTorch内置的两种交叉熵实现（`nn.CrossEntropyLoss` 与 `F.cross_entropy`），分析了它们在数值稳定性和计算效率上的差异。最后，文章提供了PyTorch损失函数的速查表，并预告下一部分将讨论多分类场景下的相关问题。","published_at":"2022-04-04T00:00:00Z"}
{"domain":"sebastianraschka","path":"https://sebastianraschka.com/blog/2021/dl-course.html","title":"","summary":"该博客文章是Sebastian Raschka撰写的《深度学习入门》系列，包含170个视频讲座，系统介绍了从基础线性神经元到零样本分类的Transformer模型。内容分为五个部分：第一部分为深度学习导论与历史；第二部分涵盖数学与计算基础（如线性代数、梯度下降、自动微分）；第三部分讲解神经网络核心概念（逻辑回归、多层感知机、正则化、初始化、优化算法）；第四部分聚焦计算机视觉与自然语言处理（CNN、RNN、Transformer架构）；第五部分介绍生成模型（自编码器、变分自编码器、生成对抗网络）。每个章节均配有视频和材料链接，适合希望系统学习深度学习理论与实践的读者。","published_at":"2021-07-09T00:00:00Z"}
{"domain":"sebastianraschka","path":"https://sebastianraschka.com/blog/2015/writing-pymle.html","title":"","summary":"本文是Sebastian Raschka撰写的博客，主题为《编写Python机器学习》（Writing 'Python Machine Learning'）的创作历程与思考。作者分享了写作此书的动机、过程中的挑战与收获，以及对机器学习教育和实践的见解。文章强调了通过动手实践学习的重要性，并介绍了书中涵盖的核心内容，如数据预处理、模型选择、超参数调优、神经网络等。同时，作者还探讨了生产力技巧、写作习惯、学术诚信等问题，鼓励读者在学习机器学习时保持批判性思维和持续探索精神。","published_at":"2015-09-24T00:00:00Z"}
{"domain":"sebastianraschka","path":"https://sebastianraschka.com/blog/2015/why-python.html","title":"","summary":"本文为一篇关于Python、机器学习与语言选择的主观观点文章，作者从个人经验出发探讨为何选择Python作为主要编程语言。文章分析了Python在科学计算、机器学习和数据处理方面的优势，对比了MATLAB、R、Julia等其他语言，并回应了“Python是否正在消亡”的争议。作者认为Python因其易用性、丰富的库生态和社区支持，仍是当前最主流的选择，尤其适合初学者和快速原型开发。同时文章也讨论了其他语言如Julia、R、Perl等在特定场景下的适用性，并最终得出结论：Python不会消亡，它依然是当前最实用且灵活的工具。","published_at":"2015-08-24T00:00:00Z"}
{"domain":"sebastianraschka","path":"https://sebastianraschka.com/Articles/2015_pca_in_3_steps.html","title":"","summary":"本文详细介绍主成分分析（PCA）的三个核心步骤：1. 数据标准化与协方差/相关矩阵计算；2. 通过特征值分解或奇异值分解选择主成分；3. 将原始数据投影到低维新特征空间。文章以鸢尾花数据集为例，结合Python代码演示了从数据加载、可视化、标准化、计算协方差矩阵、求解特征向量、解释方差贡献率，到最终投影和可视化的完整流程，并对比了手动实现与scikit-learn库的快捷方法，适合机器学习初学者理解PCA原理与实践。","published_at":"2015-01-27T00:00:00Z"}
{"domain":"sebastianraschka","path":"https://sebastianraschka.com/Articles/2014_naive_bayes_1.html","title":"","summary":"本文系统介绍了朴素贝叶斯分类器在文本分类中的理论基础与实际应用。内容涵盖朴素贝叶斯的基本原理（包括先验概率、后验概率、类条件概率）、其在文本分类中的适配方法（如词袋模型、停用词过滤、词干提取、N-gram）、以及多种变体模型（如多项式朴素贝叶斯、多项式伯努利朴素贝叶斯、连续变量版本）。文章还讨论了模型的优缺点，如假设特征独立性带来的局限，以及通过平滑技术（拉普拉斯平滑）和算法优化（如Eager/Lazy学习）提升性能的方法。最后提供了参考文献和作者联系方式。","published_at":"2014-10-04T00:00:00Z"}
{"domain":"sebastianraschka","path":"https://sebastianraschka.com/Articles/2014_dixon_test.html","title":"","summary":"本文探讨Dixon's Q检验在识别数据集异常值中的应用与争议。作者指出，尽管该方法在化学等领域被广泛使用，但其假设数据服从正态分布，且对小样本敏感，存在统计学上的局限性。文章详细介绍了Q检验的计算步骤、临界值表，并通过Python代码实现了一个简单的Q检验函数。此外，作者用实际CSV数据演示了如何应用该检验并可视化结果（如箱线图），同时讨论了其在科学实验中可能带来的误判风险。最后，作者呼吁读者审慎使用此方法，尤其在非正态分布或小样本情况下应谨慎评估。","published_at":"2014-07-19T00:00:00Z"}
{"domain":"sebastianraschka","path":"https://sebastianraschka.com/Articles/2014_about_feature_scaling.html","title":"","summary":"本文探讨了机器学习中特征缩放与标准化的效果，重点对比了Z-score标准化和Min-Max缩放。文章通过葡萄酒数据集（Wine Dataset）演示了标准化如何改善PCA降维效果及分类器（如朴素贝叶斯）的性能。作者使用Python的scikit-learn、NumPy和Matplotlib库实现并可视化了不同缩放方法对数据分布、协方差矩阵和分类准确率的影响，并在附录中详细解释了标准化对PCA结果的数学影响。","published_at":"2014-07-11T00:00:00Z"}
{"domain":"sebastianraschka","path":"https://sebastianraschka.com/Articles/2014_autodock_energycomps.html","title":"","summary":"本文详细介绍如何使用AutoDock 4.2进行分子对接，估算结合自由能，并介绍其半经验力场。内容涵盖蛋白质和配体的准备、网格参数文件生成、对接参数文件创建及运行AutoDock流程。文章还比较了不同评分函数（如AutoDock Vina、DrugScoreX、LigScore）的效果，并附有实际操作命令和结果图表，适合需要进行分子对接研究的科研人员参考。","published_at":"2014-06-26T00:00:00Z"}
{"domain":"sebastianraschka","path":"https://sebastianraschka.com/Articles/2014_multiprocessing.html","title":"","summary":"本文介绍如何使用Python的multiprocessing模块进行并行编程，重点讲解Process类、Pool类及其apply/apply_async/map等方法。通过多进程生成随机字符串、执行核密度估计（Parzen窗法）并进行性能对比测试，展示了并行化在CPU密集型任务中的加速效果。文章还包含代码示例、结果图表（如串行与并行速度对比），并指出在多核CPU上并行能显著提升性能，但在I/O密集型任务或数据量小时可能因进程开销导致效率下降。","published_at":"2014-06-20T00:00:00Z"}
{"domain":"sebastianraschka","path":"https://sebastianraschka.com/Articles/2014_python_2_3_key_diff.html","title":"","summary":"本文详细对比了Python 2.7.x与Python 3.x的主要差异，涵盖print函数、整数除法、Unicode支持、range函数、异常处理、next()函数、for循环变量作用域、可迭代对象返回值、浮点数四舍五入等多个核心主题，并通过代码示例说明不同版本的行为变化，帮助开发者理解升级至Python 3时需注意的兼容性问题。","published_at":"2014-06-01T00:00:00Z"}
{"domain":"sebastianraschka","path":"https://sebastianraschka.com/Articles/2014_python_scope_and_namespaces.html","title":"","summary":"本文是Python命名空间、作用域与LEGB规则的入门指南，系统讲解变量名在不同作用域（Local、Enclosed、Global、Built-in）中的查找顺序。文章通过代码示例说明命名冲突、变量赋值与作用域的影响，并强调避免在函数内直接修改全局变量，推荐使用返回值或参数传递。还特别指出for循环变量在Python 3中不会“泄漏”到全局作用域，而在Python 2中会。最后提供自测练习和解决方案，帮助初学者掌握作用域机制。","published_at":"2014-05-12T00:00:00Z"}
{"domain":"sebastianraschka","path":"https://sebastianraschka.com/Articles/2014_pca_step_by_step.html","title":"","summary":"本文详细介绍了在Python中逐步实现主成分分析（PCA）的过程，包括生成三维样本数据、计算均值向量与协方差矩阵、求解特征值与特征向量、排序特征向量以选择前k个最大特征值对应的分量、将原始样本投影到新坐标系。同时对比了手动实现与使用sklearn库的PCA类结果，并验证了两种方法的一致性。文章通过代码示例和可视化图表，清晰展示了PCA降维的核心步骤与实践效果，适合希望理解PCA原理及动手实现的读者。","published_at":"2014-04-13T00:00:00Z"}
{"domain":"sebastianraschka","path":"https://sebastianraschka.com/Articles/2014_sqlite_in_python_tutorial.html","title":"","summary":"本文是一篇关于使用Python操作SQLite数据库的全面指南，涵盖连接数据库、创建数据库与表、添加新列、插入与更新数据、创建唯一索引、查询数据（包括筛选和排序）、安全防护（防止SQL注入）、日期时间操作以及检索列名等核心内容。文章通过代码示例和截图，详细讲解了SQLite的基本语法和Python sqlite3模块的用法，并提供了实用技巧和最佳实践，适合初学者快速掌握SQLite数据库操作。","published_at":"2014-03-07T00:00:00Z"}
